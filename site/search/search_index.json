{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"TON DEV KNOWLEDGE-BASE TON DEV Product Guides SDK Compilers Contract Developer Guides With Solidity Compiler Compiling to .tvc and .boc With the SDK Node.js Rust","title":"Home"},{"location":"#ton-dev-knowledge-base","text":"","title":"TON DEV KNOWLEDGE-BASE"},{"location":"#ton-dev-product-guides","text":"SDK Compilers","title":"TON DEV Product Guides"},{"location":"#contract-developer-guides","text":"","title":"Contract Developer Guides"},{"location":"#with-solidity-compiler","text":"Compiling to .tvc and .boc","title":"With Solidity Compiler"},{"location":"#with-the-sdk","text":"Node.js Rust","title":"With the SDK"},{"location":"Glossary/","text":"The Moonspeak This brief set of terms and definitions is in no way exhaustive or final. It is based on personal experience with blockchain or related concepts and aims at making complex things a little more clear. What makes blockchain talk complicated, is that this rapidly evolving phenomenon pools together multiple concepts, methodologies and ideas from numerous areas and domains from math to behaviorist studies. Considered separately, each item may be clear and logical, but once pooled together and interwoven, they are not easy to define and describe in plain well-structured phrases. For example, explanation of the root term - Blockchain - can start from the basic notion of database, but just as well we can choose P2P networks as the starting place. Bringing both together within a single definition makes it long and more confusing. But we keep on trying. Hope you will have a good time reading it. Feedback and suggestions are welcome. B Blockchain Blockchain is basically a database for storing transactions packed in blocks. Blockchain has some technical particularities that make it ideal for fintech services but quite awkward for general DB uses: data in blockchain cannot be changed (i.e. transactions are unchangeable), all data is linked to its owner, all data meets some mandatory rules (i.e. it is consistent) and, ta-da, its decentralized. Blockchains rely on peer-to-peer interaction and require no third-party regulation, control or coordination. To ensure fairness, there is consensus (validation procedures that enable mining) and encryption technologies. Another, broader, term for this type of databases is Distributed Ledger. Tip : for further reading we would suggesting articles about peer-to-peer networks, sharding, workchains, multi-chain models. C Cold Wallet Cold wallet (aka hardware wallet) is a physical appliance (an nfc-card, a usb drive) where wallet private keys are stored. Cold wallets are considered more secure, as there is no way to hack them. Also, in some cases a cold wallet enables easier and faster access to transactions. For example, with an nfc-card you only have to hover it over the back side of your device to start transactions. No more mess with passwords and pin-codes. Consensus Consensus is a protocol implemented within a blochchain to make sure that its nodes (engines that maintain the blockchain and may process transactions, depending on the architecture) agree on requirements to transactions to validate them. Interestingly, validation enabled crypto-currency mining, as newly mined coins are the reward for validating a transaction. With consensus in place, no centralized regulation is needed to prevent frauds. There are several popular consensus protocols: Proof of Work (PoW), Proof of Stake, Delegated Proof of Stake, etc. New consensus mechanisms evolve to reduce energy consumption associated with the PoW and optimize overall performance. Moreover, consensus without mining is being developed and researched. Crypto-currency Surprise, surprise, but crypto-currency is not necessarily blockchain and blockchain is not necessarily crypto-currency. Technically speaking, to generate crypto-currency one needs a distributed ledger meeting two core requirements: decentralized storage and encryption technology. Yet, blockchain remains the most popular, because it enables mining (i.e. generating new currency units) as a reward for transaction validation thus reducing commissions imposed on the parties. Tip : to dig deeper, you might want to research the related concepts: fiat money, token, burning, mining vs. minting, Byzantine Generals Problem, TenderMint. D Dapp, Decentralized application In short, it is an application (usually fintech) with a blockchain smart-contract behind it to ensure fairness and decentralization. An extended definition though has to cover the infrastructure a bit. A standard app either operates locally (e.g. a single-player game) or uses some standard server-client architecture (e.g. a bank app). In blockchain, every Dapp is basically a smart contract that describes transactions and rules applied to them. Roughly speaking, each smart contract has a server side that is stored in the blockchain and executed by the virtual machine (back-end for machine-to-machine interaction) and the client-side that is available to a user and has a GUI for human to machine interaction (front-end). The two parts interact via messaging (basically, requests to the contract and its responses). The front-end part can be implement in many popular programming languages, most popular are .js and .ts, Python is on the rise. Decentralized economy In the real world anarchy turns out to be a disaster and everybody's business is known to be nobody's business. Communism failed and is dabbed a Utopian concept forever. In the digital world, however, blockchain is the game-changer when it comes to equal rights, fair play, data security, privacy, decentralization, democracy, transparency. You can have it all without any central authority, regulations and dictatorship. Hmm, is it as good as it sounds? Let's see. Booming peer to peer networks with consensus methods allow parties to safely and transparently carry out financial (or other) transactions without any regulator. Being just a technical thing, P2P solutions (in particular, blockchain) have no geographical, social, political or gender bias. N Node Basically, Node is a blockchain server that has a working instance of a virtual machine (VM) and a set of relevant instruments that ensure VM interaction with clients (i.e. for example, with customer applications). Every blockchain platform has its own messaging standards and protocols, let alone VM's, so node architectures differ across platforms. What's more even within a single platform variations may exist, although all nodes have to be compatible within a platform. Visit TON Dev for its Node SE offer. S Smart contract Smart contract is not a legal document, rather, it is a piece of code deployed in blockchain. This code contains an executable sequence of operations. Each operation manipulates some available data (e.g. an account balance), retrieves it and\\or changes it (e.g. transfers an amount). Each instance of smart contract execution is a blockchain transaction with block generation. Smart contract is the core part of each Dapp (roughly speaking, it is its back end). Smart contracts may interact with each other. There are several types of standard smart contracts that implement tokens. The most famous is ERC20. T Tokenomics This concept does not take blockchain beyond crypto-currencies, but rather it expands the idea of crypto-currencies beyond money the way we have known it. In a solid ecosystem a token becomes more than a means of transaction settlement (buy, pay, transfer, invoice, etc.), it is an attitude, a vote, a stake. For example, you can use tokens to vote for some initiative. If it gets enough votes in tokens, your contribution will be written off your account and used to finance the initiative. This is a basic case, of course, many more can be invented. What makes tokenomics attractive, is the blockchain and smart-contract technology behind. These ensure decentralization, security, fairness, privacy and transparency at the same time. V Virtual machine A VM is a blockchain core or engine that takes smart contracts compiled to a blockchain-specific bytecode and executes them (performs transactions). Between transactions smart contracts are stored in the blockchain with persistent data (i.e. the data that remains in the contract). TON VM is called TVM, Ethereum VM is EVM. You can find detailed specification of each in the Internet. W Web 3.0 The original concept suggested as far back as in 2007 by Jason Calacanis implies a switch from Web 2.0's powerful services and tools to a whole new interaction and work culture. Then it was proposed to define Web 3.0 as the Internet interaction with the physical world. The latter idea, although criticized and over-used, resonates with our vision and with the decentralized economy concept. Indeed, blockchain has the potential to foster penetration of the Internet into the real world. Fintech services can be used to manage daily chores and bills, devices (IoT) and many more.","title":"The Moonspeak"},{"location":"Glossary/#the-moonspeak","text":"This brief set of terms and definitions is in no way exhaustive or final. It is based on personal experience with blockchain or related concepts and aims at making complex things a little more clear. What makes blockchain talk complicated, is that this rapidly evolving phenomenon pools together multiple concepts, methodologies and ideas from numerous areas and domains from math to behaviorist studies. Considered separately, each item may be clear and logical, but once pooled together and interwoven, they are not easy to define and describe in plain well-structured phrases. For example, explanation of the root term - Blockchain - can start from the basic notion of database, but just as well we can choose P2P networks as the starting place. Bringing both together within a single definition makes it long and more confusing. But we keep on trying. Hope you will have a good time reading it. Feedback and suggestions are welcome.","title":"The Moonspeak"},{"location":"Glossary/#b","text":"","title":"B"},{"location":"Glossary/#blockchain","text":"Blockchain is basically a database for storing transactions packed in blocks. Blockchain has some technical particularities that make it ideal for fintech services but quite awkward for general DB uses: data in blockchain cannot be changed (i.e. transactions are unchangeable), all data is linked to its owner, all data meets some mandatory rules (i.e. it is consistent) and, ta-da, its decentralized. Blockchains rely on peer-to-peer interaction and require no third-party regulation, control or coordination. To ensure fairness, there is consensus (validation procedures that enable mining) and encryption technologies. Another, broader, term for this type of databases is Distributed Ledger. Tip : for further reading we would suggesting articles about peer-to-peer networks, sharding, workchains, multi-chain models.","title":"Blockchain"},{"location":"Glossary/#c","text":"","title":"C"},{"location":"Glossary/#cold-wallet","text":"Cold wallet (aka hardware wallet) is a physical appliance (an nfc-card, a usb drive) where wallet private keys are stored. Cold wallets are considered more secure, as there is no way to hack them. Also, in some cases a cold wallet enables easier and faster access to transactions. For example, with an nfc-card you only have to hover it over the back side of your device to start transactions. No more mess with passwords and pin-codes.","title":"Cold Wallet"},{"location":"Glossary/#consensus","text":"Consensus is a protocol implemented within a blochchain to make sure that its nodes (engines that maintain the blockchain and may process transactions, depending on the architecture) agree on requirements to transactions to validate them. Interestingly, validation enabled crypto-currency mining, as newly mined coins are the reward for validating a transaction. With consensus in place, no centralized regulation is needed to prevent frauds. There are several popular consensus protocols: Proof of Work (PoW), Proof of Stake, Delegated Proof of Stake, etc. New consensus mechanisms evolve to reduce energy consumption associated with the PoW and optimize overall performance. Moreover, consensus without mining is being developed and researched.","title":"Consensus"},{"location":"Glossary/#crypto-currency","text":"Surprise, surprise, but crypto-currency is not necessarily blockchain and blockchain is not necessarily crypto-currency. Technically speaking, to generate crypto-currency one needs a distributed ledger meeting two core requirements: decentralized storage and encryption technology. Yet, blockchain remains the most popular, because it enables mining (i.e. generating new currency units) as a reward for transaction validation thus reducing commissions imposed on the parties. Tip : to dig deeper, you might want to research the related concepts: fiat money, token, burning, mining vs. minting, Byzantine Generals Problem, TenderMint.","title":"Crypto-currency"},{"location":"Glossary/#d","text":"","title":"D"},{"location":"Glossary/#dapp-decentralized-application","text":"In short, it is an application (usually fintech) with a blockchain smart-contract behind it to ensure fairness and decentralization. An extended definition though has to cover the infrastructure a bit. A standard app either operates locally (e.g. a single-player game) or uses some standard server-client architecture (e.g. a bank app). In blockchain, every Dapp is basically a smart contract that describes transactions and rules applied to them. Roughly speaking, each smart contract has a server side that is stored in the blockchain and executed by the virtual machine (back-end for machine-to-machine interaction) and the client-side that is available to a user and has a GUI for human to machine interaction (front-end). The two parts interact via messaging (basically, requests to the contract and its responses). The front-end part can be implement in many popular programming languages, most popular are .js and .ts, Python is on the rise.","title":"Dapp, Decentralized application"},{"location":"Glossary/#decentralized-economy","text":"In the real world anarchy turns out to be a disaster and everybody's business is known to be nobody's business. Communism failed and is dabbed a Utopian concept forever. In the digital world, however, blockchain is the game-changer when it comes to equal rights, fair play, data security, privacy, decentralization, democracy, transparency. You can have it all without any central authority, regulations and dictatorship. Hmm, is it as good as it sounds? Let's see. Booming peer to peer networks with consensus methods allow parties to safely and transparently carry out financial (or other) transactions without any regulator. Being just a technical thing, P2P solutions (in particular, blockchain) have no geographical, social, political or gender bias.","title":"Decentralized economy"},{"location":"Glossary/#n","text":"","title":"N"},{"location":"Glossary/#node","text":"Basically, Node is a blockchain server that has a working instance of a virtual machine (VM) and a set of relevant instruments that ensure VM interaction with clients (i.e. for example, with customer applications). Every blockchain platform has its own messaging standards and protocols, let alone VM's, so node architectures differ across platforms. What's more even within a single platform variations may exist, although all nodes have to be compatible within a platform. Visit TON Dev for its Node SE offer.","title":"Node"},{"location":"Glossary/#s","text":"","title":"S"},{"location":"Glossary/#smart-contract","text":"Smart contract is not a legal document, rather, it is a piece of code deployed in blockchain. This code contains an executable sequence of operations. Each operation manipulates some available data (e.g. an account balance), retrieves it and\\or changes it (e.g. transfers an amount). Each instance of smart contract execution is a blockchain transaction with block generation. Smart contract is the core part of each Dapp (roughly speaking, it is its back end). Smart contracts may interact with each other. There are several types of standard smart contracts that implement tokens. The most famous is ERC20.","title":"Smart contract"},{"location":"Glossary/#t","text":"","title":"T"},{"location":"Glossary/#tokenomics","text":"This concept does not take blockchain beyond crypto-currencies, but rather it expands the idea of crypto-currencies beyond money the way we have known it. In a solid ecosystem a token becomes more than a means of transaction settlement (buy, pay, transfer, invoice, etc.), it is an attitude, a vote, a stake. For example, you can use tokens to vote for some initiative. If it gets enough votes in tokens, your contribution will be written off your account and used to finance the initiative. This is a basic case, of course, many more can be invented. What makes tokenomics attractive, is the blockchain and smart-contract technology behind. These ensure decentralization, security, fairness, privacy and transparency at the same time.","title":"Tokenomics"},{"location":"Glossary/#v","text":"","title":"V"},{"location":"Glossary/#virtual-machine","text":"A VM is a blockchain core or engine that takes smart contracts compiled to a blockchain-specific bytecode and executes them (performs transactions). Between transactions smart contracts are stored in the blockchain with persistent data (i.e. the data that remains in the contract). TON VM is called TVM, Ethereum VM is EVM. You can find detailed specification of each in the Internet.","title":"Virtual machine"},{"location":"Glossary/#w","text":"","title":"W"},{"location":"Glossary/#web-30","text":"The original concept suggested as far back as in 2007 by Jason Calacanis implies a switch from Web 2.0's powerful services and tools to a whole new interaction and work culture. Then it was proposed to define Web 3.0 as the Internet interaction with the physical world. The latter idea, although criticized and over-used, resonates with our vision and with the decentralized economy concept. Indeed, blockchain has the potential to foster penetration of the Internet into the real world. Fintech services can be used to manage daily chores and bills, devices (IoT) and many more.","title":"Web 3.0"},{"location":"Compilers/About/","text":"Intro The TON Labs Compiler Toolchain enables developers to compile source contract code in popular COP languages and GPLs into the TVM bytecode. The Toolchain includes a Solidity to TVM (Sol2TVM) compiler and an LLVM-based compiler that now is ready to take sources code in C (C2TVM). Support of other GPLs and COP languages is planned. The compiler Toolchain also includes the so-called tvm-linker that packs code into binary format. Read further for more details on components, their roles and usage. Also, visit TON Dev for more product, company and community info. Before your take the leap To ensure that smart-contract is TVM-ready it has to compile to the virtual machine language (we will call it TVM Assembly for the documentation purposes) and support its value types, data management methods and primitives (instructions implemented to manipulate these values and implement methods). In particular it is worth to mention TVM-specific primitives introduced to manipulate TVM persistent data storage containers or Cells , intermediate storage containers or Builders , and sub-cells ( Slices ) (tvm.pdf cl. 3.1 , A. 4.2 ). For example, NEWC and ENDC Cell-level primitives start and end the Cell creation process. TVM's key and most specific methods - Serialization and Deserialization - are, basically, construct cell (pack data) and extract cell data instructions. Note : For exhaustive descriptions of the TVM and TON please, refer to original specifications. To help developers, we developed high-level to low-level language compilers. Once fully implemented, our Toolchain will allow developers to reuse their current skills in our ecosystem. Visit TON Dev for additional product, company community info.","title":"Intro"},{"location":"Compilers/About/#intro","text":"The TON Labs Compiler Toolchain enables developers to compile source contract code in popular COP languages and GPLs into the TVM bytecode. The Toolchain includes a Solidity to TVM (Sol2TVM) compiler and an LLVM-based compiler that now is ready to take sources code in C (C2TVM). Support of other GPLs and COP languages is planned. The compiler Toolchain also includes the so-called tvm-linker that packs code into binary format. Read further for more details on components, their roles and usage. Also, visit TON Dev for more product, company and community info.","title":"Intro"},{"location":"Compilers/About/#before-your-take-the-leap","text":"To ensure that smart-contract is TVM-ready it has to compile to the virtual machine language (we will call it TVM Assembly for the documentation purposes) and support its value types, data management methods and primitives (instructions implemented to manipulate these values and implement methods). In particular it is worth to mention TVM-specific primitives introduced to manipulate TVM persistent data storage containers or Cells , intermediate storage containers or Builders , and sub-cells ( Slices ) (tvm.pdf cl. 3.1 , A. 4.2 ). For example, NEWC and ENDC Cell-level primitives start and end the Cell creation process. TVM's key and most specific methods - Serialization and Deserialization - are, basically, construct cell (pack data) and extract cell data instructions. Note : For exhaustive descriptions of the TVM and TON please, refer to original specifications. To help developers, we developed high-level to low-level language compilers. Once fully implemented, our Toolchain will allow developers to reuse their current skills in our ecosystem. Visit TON Dev for additional product, company community info.","title":"Before your take the leap"},{"location":"Compilers/Linker CLI/","text":"Key Use Cases The linker Toolchain tool is called the tvm_linker and can be used in one of the following modes: Compilation . In this mode the linker compiles several modules together and provides final contract (a .tvc file) for further running using TVM. Test run . In this mode the linker runs previously prepared compiled contract using TVM emulator. This may be used to check the correctness of some smart contract parts without running them on a node. Message preparation . In this mode, the linker prepares an inbound message for a contract in the .boc format. Compilation Following command line format should be used to compile several modules together: tvm_linker compile [--debug] [--lib STDLIB ] ASM_FILE ... where: *--* (first instance) stands for the path to an assembler file; there can be several assembler files for compilation; *--* (second instance) stands for the path a to standard library assembler file (for example, stdlib_c.tvm); --debug command line option enables debug output of linking; for example, it can be used to get addresses of global symbols (for example, of functions). After the above command is executed, the linker delivers a compiled contract in the .tvc format. Test Run After assembler files are linked together, you can use the linker to run a compiled contract. This command does not start the node and has a limited usage. Mainly, test runs are used for local debugging of code parts the do not require interaction between smart contracts (e.g.: unit tests). Command line format for test run is following: tvm_linker test CONTRACT_ADDRESS [--trace] [--decode-c6] --body 00 ENTRY_ADDRESS where: *--* (instance one) stands for the address of a contract that has to be run. Note that the .tvc extension is not included; -- (instance two) stands for the contract starting point; it can be extracted from the tvm_linker compile output in --debug mode; --trace option is used to trace VM execution; each time a VM command is executed, stack and registers are printed; --decode-c6 option is used to display output actions in a friendly format. Message Creation Messages can be sent to a contract in a .boc format. These messages use contract ABI and a list of input key-value pairs. In the command line a message has the following format: tvm_linker message contract-address [--init] [-w] --abi-json json-file-with-abi --abi-method method-name --abi-params json-string-with-params where: -- (instance one) stands for the address of a target contract; note that the .tvc extension is omitted; -- (instance two) stands for the workchain ID used with the contract address; -- (instance three) stands for the path to a relevant ABI file that defines methods and their input/output parameters (see description below); -- (instance four) stands for the contract method called via the message; -- (instance five) stands for contract method parameters in JSON format (for example, {\u201ca\u201d: \u201c0x123\u201d, \u201cb\u201d : \u201c456\u201d}); ABI File Format An ABI file defines available contract methods, input parameters and outputs. ABI has a JSON-based syntax with the following structure: \u201cABI version\u201d : the version of ABI file format (should be 0 for now); \u201cfunctions\u201d : array of contract methods. Each contract method has following format: *\"name\"* - the name of a method (the method requires the *_Impl* suffix ; for example, if an ABI file has a *\u2018fn1\u2019* method, then contract should have implementation of this method entitled *\u2018fn1_Impl\u2019* ); *\u201csigned\u201d* defines whether the method is signed or not (values are \u201ctrue\" or \u201cfalse\u201d ) *\u201cinputs\u201d* contains the list of input parameters; *\u201coutputs\u201d* stands for the list of output parameters. Each method parameter has the following format: \u201cname\u201d stands for name of a parameter; \u201ctype\u201d type of a parameter ( only \u201cuint64\u201d is supported now). For example: { ABI version : 0, functions : [ { name : fn1 , signed : false , inputs : [ { name : arg1 , type : uint64 } ], outputs : [ { name : result , type : uint64 } ] } ] } More Help Use tvm_linker --help for detailed description about all options, flags and sub-commands.","title":"Linker CLI"},{"location":"Compilers/Linker CLI/#key-use-cases","text":"The linker Toolchain tool is called the tvm_linker and can be used in one of the following modes: Compilation . In this mode the linker compiles several modules together and provides final contract (a .tvc file) for further running using TVM. Test run . In this mode the linker runs previously prepared compiled contract using TVM emulator. This may be used to check the correctness of some smart contract parts without running them on a node. Message preparation . In this mode, the linker prepares an inbound message for a contract in the .boc format.","title":"Key Use Cases"},{"location":"Compilers/Linker CLI/#compilation","text":"Following command line format should be used to compile several modules together: tvm_linker compile [--debug] [--lib STDLIB ] ASM_FILE ... where: *--* (first instance) stands for the path to an assembler file; there can be several assembler files for compilation; *--* (second instance) stands for the path a to standard library assembler file (for example, stdlib_c.tvm); --debug command line option enables debug output of linking; for example, it can be used to get addresses of global symbols (for example, of functions). After the above command is executed, the linker delivers a compiled contract in the .tvc format.","title":"Compilation"},{"location":"Compilers/Linker CLI/#test-run","text":"After assembler files are linked together, you can use the linker to run a compiled contract. This command does not start the node and has a limited usage. Mainly, test runs are used for local debugging of code parts the do not require interaction between smart contracts (e.g.: unit tests). Command line format for test run is following: tvm_linker test CONTRACT_ADDRESS [--trace] [--decode-c6] --body 00 ENTRY_ADDRESS where: *--* (instance one) stands for the address of a contract that has to be run. Note that the .tvc extension is not included; -- (instance two) stands for the contract starting point; it can be extracted from the tvm_linker compile output in --debug mode; --trace option is used to trace VM execution; each time a VM command is executed, stack and registers are printed; --decode-c6 option is used to display output actions in a friendly format.","title":"Test Run"},{"location":"Compilers/Linker CLI/#message-creation","text":"Messages can be sent to a contract in a .boc format. These messages use contract ABI and a list of input key-value pairs. In the command line a message has the following format: tvm_linker message contract-address [--init] [-w] --abi-json json-file-with-abi --abi-method method-name --abi-params json-string-with-params where: -- (instance one) stands for the address of a target contract; note that the .tvc extension is omitted; -- (instance two) stands for the workchain ID used with the contract address; -- (instance three) stands for the path to a relevant ABI file that defines methods and their input/output parameters (see description below); -- (instance four) stands for the contract method called via the message; -- (instance five) stands for contract method parameters in JSON format (for example, {\u201ca\u201d: \u201c0x123\u201d, \u201cb\u201d : \u201c456\u201d});","title":"Message Creation"},{"location":"Compilers/Linker CLI/#abi-file-format","text":"An ABI file defines available contract methods, input parameters and outputs. ABI has a JSON-based syntax with the following structure: \u201cABI version\u201d : the version of ABI file format (should be 0 for now); \u201cfunctions\u201d : array of contract methods. Each contract method has following format: *\"name\"* - the name of a method (the method requires the *_Impl* suffix ; for example, if an ABI file has a *\u2018fn1\u2019* method, then contract should have implementation of this method entitled *\u2018fn1_Impl\u2019* ); *\u201csigned\u201d* defines whether the method is signed or not (values are \u201ctrue\" or \u201cfalse\u201d ) *\u201cinputs\u201d* contains the list of input parameters; *\u201coutputs\u201d* stands for the list of output parameters. Each method parameter has the following format: \u201cname\u201d stands for name of a parameter; \u201ctype\u201d type of a parameter ( only \u201cuint64\u201d is supported now). For example: { ABI version : 0, functions : [ { name : fn1 , signed : false , inputs : [ { name : arg1 , type : uint64 } ], outputs : [ { name : result , type : uint64 } ] } ] }","title":"ABI File Format"},{"location":"Compilers/Linker CLI/#more-help","text":"Use tvm_linker --help for detailed description about all options, flags and sub-commands.","title":"More Help"},{"location":"Compilers/Specification of ABI/","text":"Message Body Structure The first 8 bits (1 byte) of the message body represent the contract ABI specification version. Next 32 bits of the message body identify which contract functions is called. The function ID comes within the first bits of the SHA256 hash of the function signature. The ABI version and the function ID are stored in the message body root cell. Then follow the function parameters. They are encoded in compliance with the present specification and stored either to the root cell or the next one in the chain. A serialized function call has the following format: Version` + `Function ID`+ `Enc(Arguments) Function return values are also encoded and put into the message response: Version` + `Function ID`+`Enc(Return values) Signing To identify user outside the blockchain the message body can be protected with a cryptographic signature. Then an External inbound message that calls the function is signed by the user private key . This requirement applies only to External inbound messages because Internal inbound messages are generated within the blockchain and src address can be used to identify the caller. The signature is stored to a separate cell referenced by index 0 from the message body root cell. If user doesn't want to sign message, empty signature cell must be attached to message body at reference index 0 of the body root cell. The message body signature is generated from the representation hash of the root cell before the reference to signature cell is appended to it. Signing Algorithm ABI serialization generates the message body as a bag of cells. One empty reference is reserved at the root cell. At this stage the signature cell is not yet created. Representation hash of the message body is signed using the Ed25519 algorithm. The signature is saved to the new cell. Public key is also placed to this cell after signature data. The Signature cell is added to the body root cell as reference at position 0 shifting existing references to the next positions. Function Signature To define a signature (Function ID) the following syntax is used: function name list of input parameter types (input list) in parenthesis list of return values types (output list) in parenthesis Single comma is used to divide each input parameter and return value type from one another. No spaces are used. Parameter and return value names are not included. The function name, input and output lists are not separated and immediately follow each other. If a function has no input parameters or does not return any values, the corresponding input or output lists are empty (empty parenthesis). Function Signature Syntax function_name(input_type1,input_type2,...,input_typeN)(output_type1,output_type2,...,output_typeM) Signature Calculation Syntax SHA256( function_name(input_type1,input_type2,...,input_typeN)(output_type1,output_type2,...,output_typeM) ) Sample Implementation Function func(int64 param1, bool param2) - uint32 Function Signature func(int64,bool)(uint32) Function Hash sha256( func(int64,bool)(uint32) ) = 0xA6BF22A36FD64ADD2A0EE012A2E137834E0609D24499A2CBFBACC8187C0D288F And the function ID then is 0xA6BF22A3 Types uint M : unsigned M bit integer. Big-endian encoded unsigned integer stored in the cell-data. int M : two\u2019s complement signed M bit integer. Big-endian encoded signed integer stored in the cell-data. dint : signed integer value with dynamic size. Encoded as Base 128 Varints proposed by Google in Protocol Buffers documentation . See further for more information. duint : two\u2019s complement dynamic sized usigned integer value. Encoded as Base 128 Varints proposed by Google in Protocol Buffers documentation . See further for more information. bool : equivalent to uint1. tuple (T1, T2, ..., Tn) : tuple that includes T1 , ..., Tn , n =0 types encoded in the following way: Enc(X(1)) Enc(X(2)) . . ., Enc(X(n)); where X(i) is type of T(i) for i in 1..n T[] : dynamic array of T type elements encoded in the following way: 2 bits stored in the cell-data define serialization algorithm. [00] - array is put into a separate cell. In case of array overflowing the maximum cell-data size it's split into multiple sequential cells. [10] - bits sequence is put in the cell-data. The next 8 bits (1 byte) define the number of elements of the array. It's followed by the sequence of encoded array elements. [01]/[11] - reserved. T[k] : static size array of T type elements encoded in the following way: 2 bits put in the cell-data define serialization algorithm. [00] - array is put into a separate cell. In case of array overflowing the maximum cell-data size it's split into multiple sequential cells. [10] - bits sequence is put in the cell-data. It's followed by the sequence of encoded array elements. [01]/[11] - reserved. bits M : static sized bits sequence. Encoding is equivalent to bool[M] bitsring : dynamic sized bits sequence. Encoding is equivalent to bool[] Base 128 for Varints Varints are used to serialize integers having one or more bytes (smaller numbers take a smaller number of bytes). Each byte in a varint except the last one has the most significant bit (msb) set; it indicates that there are more bytes to come. The lower 7 bits in each byte store the two's complement representation of the number in groups of 7 bits; least significant group first . For example, here is the number 1, it is a single byte, so no msb is set: 0000 0001 Syntax \u200b C, C++, C# CoffeeScript CSS Dockerfile diff Go Groovy HAML Handlebars HTML templates (Rails, ASP.NET) HTML HTTP Java JavaScript JSX (React) LESS Objective C Perl PHP Pug Puppet Python Ruby Rust Sass Scala SCSS Shell SQL Swift Vue.js XML YAML HTML In this example we handle the number 300, it is more complicated: 1010 1100 0000 0010 Syntax \u200b C, C++, C# CoffeeScript CSS Dockerfile diff Go Groovy HAML Handlebars HTML templates (Rails, ASP.NET) HTML HTTP Java JavaScript JSX (React) LESS Objective C Perl PHP Pug Puppet Python Ruby Rust Sass Scala SCSS Shell SQL Swift Vue.js XML YAML HTML Deserializing this number from the above binary string starts from dropping the msb from each byte including the byte with msb set to 0 (it is the set in the first byte, as there is more than one byte in the varint ): 1010 1100 0000 0010 \u2192 010 1100 000 0010 Syntax \u200b C, C++, C# CoffeeScript CSS Dockerfile diff Go Groovy HAML Handlebars HTML templates (Rails, ASP.NET) HTML HTTP Java JavaScript JSX (React) LESS Objective C Perl PHP Pug Puppet Python Ruby Rust Sass Scala SCSS Shell SQL Swift Vue.js XML YAML HTML Then, to get the final value, the two groups of 7 bits are put in the reverse order and concatenated: 000 0010 010 1100 \u2192 000 0010 ++ 010 1100 \u2192 100101100 \u2192 256 + 32 + 8 + 4 = 300 Syntax \u200b C, C++, C# CoffeeScript CSS Dockerfile diff Go Groovy HAML Handlebars HTML templates (Rails, ASP.NET) HTML HTTP Java JavaScript JSX (React) LESS Objective C Perl PHP Pug Puppet Python Ruby Rust Sass Scala SCSS Shell SQL Swift Vue.js XML YAML HTML Overflow Cell Data If the data does not fit into the available space of the current cell-data, it is split for maximum utilization of space in the current cell. A reference to a new cell is added to the current one and it continues with the remaining part, and a new cell as a current. Cell Reference Limit For the simplicity, this ABI version reserves the last cell-reference spot for the cell-data overflow case. If the cell-reference limit in the current cell is already reached (save for the reserved spot) and a new cell is required, the current cell is considered complete and a new one is created. The reference to a new cell is stored in the reserved spot and it continues with the new cell as a current one. Contract Interface Contract interface functions are specified in JSON format. The contract JSON description specified each interface function signature, including its name, input and output parameters. Functions specified in the contract interface can be called from other contracts or from outside the blockchain via ABI call. A function description is a JSON object with the following fields: name : function name; inputs : an array of objects, each containing: name : parameter name; type : the canonical parameter type. components : used for tuple types, optional. outputs : an array of objects similar to inputs , can be omitted if function does not return anything; signed : boolean indicating the need for message signing The list of interface function descriptions is included to contract interface specification as the functions field. The interface specification also specifies an ABI encoding format version: ABI version : x The whole JSON contract interface consists of the ABI version field and list of interface function descriptions. A contract specification example is provided below. Modification Support As specified above, the JSON contract interface description contains versions of the ABI encoding format and the contract interface. So, a JSON description in a contract defines the used version of ABI encoding algorithm and its own interface version. Having this data, a caller determines how to encode parameters for the current contract version. The first byte of encoded function parameters is reserved for the ABI format version, enabling the deserializer to check whether the caller uses the same version and parameters are encoded correctly. Rationale The present serialization method is selected to reduce messages represented as a tree of cells according to TON blockchain specification. Simple types are encoded \"in place\", i.e. encoded data is stored to the current cell data. For composite types with varying size ranges two serialization methods are provided: the same encoding \"in place\" and encoding in a chain of separate cells. The method selection takes place during the run time and depends on the array size. Thus, small arrays fitting into a 8 bit field are stored in the current cell, while larger ones that take several cells are stored into a chain of separate cells to simplify access to parameters that come next. Two bits are reserved for array encoding type definition, so that other two encoding types could be defined. Sample Code Contract interface specification example: { ABI version : 0, functions : [ { inputs : [ { name : recipient , type : bits256 }, { name : value , type : duint } ], name : sendTransaction , signed : true, outputs : [ { name : transaction , type : uint64 }, { name : error , type : int8 } ] }, { inputs : [ { name : type , type : uint8 }, { name : value , type : duint }, { name : meta , type : bitstring } ], name : createLimit , signed : true, outputs : [ { name : limitId , type : uint8 }, { name : error , type : int8 } ] }, { inputs : [ { name : limitId , type : uint8 }, { name : value , type : duint }, { name : meta , type : bitstring } ], name : changeLimitById , signed : true, outputs : [ { name : error , type : int8 } ] }, { inputs : [ { name : limitId , type : uint8 } ], name : removeLimit , signed : true, outputs : [ { name : error , type : int8 } ] }, { inputs : [ { name : limitId , type : uint8 } ], name : getLimitById , outputs : [ { name : limitInfo , type : tuple , components : [ { name : value , type : duint }, { name : type , type : uint8 }, { name : meta , type : bitstring } ] }, { name : error , type : int8 } ] }, { inputs : [], name : getLimits , outputs : [ { name : list , type : uint8[] , }, { name : error , type : int8 } ] }, { inputs : [], name : getVersion , outputs : [ { name : version , type : tuple , components : [ { name : major , type : uint16 }, { name : minor , type : uint16 } ] }, { name : error , type : int8 } ] }, { inputs : [], name : getBalance , outputs : [ { name : balance , type : uint64 } ] } ] }","title":"Specification of ABI"},{"location":"Compilers/Specification of ABI/#message-body","text":"","title":"Message Body"},{"location":"Compilers/Specification of ABI/#structure","text":"The first 8 bits (1 byte) of the message body represent the contract ABI specification version. Next 32 bits of the message body identify which contract functions is called. The function ID comes within the first bits of the SHA256 hash of the function signature. The ABI version and the function ID are stored in the message body root cell. Then follow the function parameters. They are encoded in compliance with the present specification and stored either to the root cell or the next one in the chain. A serialized function call has the following format: Version` + `Function ID`+ `Enc(Arguments) Function return values are also encoded and put into the message response: Version` + `Function ID`+`Enc(Return values)","title":"Structure"},{"location":"Compilers/Specification of ABI/#signing","text":"To identify user outside the blockchain the message body can be protected with a cryptographic signature. Then an External inbound message that calls the function is signed by the user private key . This requirement applies only to External inbound messages because Internal inbound messages are generated within the blockchain and src address can be used to identify the caller. The signature is stored to a separate cell referenced by index 0 from the message body root cell. If user doesn't want to sign message, empty signature cell must be attached to message body at reference index 0 of the body root cell. The message body signature is generated from the representation hash of the root cell before the reference to signature cell is appended to it. Signing Algorithm ABI serialization generates the message body as a bag of cells. One empty reference is reserved at the root cell. At this stage the signature cell is not yet created. Representation hash of the message body is signed using the Ed25519 algorithm. The signature is saved to the new cell. Public key is also placed to this cell after signature data. The Signature cell is added to the body root cell as reference at position 0 shifting existing references to the next positions.","title":"Signing"},{"location":"Compilers/Specification of ABI/#function-signature","text":"To define a signature (Function ID) the following syntax is used: function name list of input parameter types (input list) in parenthesis list of return values types (output list) in parenthesis Single comma is used to divide each input parameter and return value type from one another. No spaces are used. Parameter and return value names are not included. The function name, input and output lists are not separated and immediately follow each other. If a function has no input parameters or does not return any values, the corresponding input or output lists are empty (empty parenthesis).","title":"Function Signature"},{"location":"Compilers/Specification of ABI/#function-signature-syntax","text":"function_name(input_type1,input_type2,...,input_typeN)(output_type1,output_type2,...,output_typeM)","title":"Function Signature Syntax"},{"location":"Compilers/Specification of ABI/#signature-calculation-syntax","text":"SHA256( function_name(input_type1,input_type2,...,input_typeN)(output_type1,output_type2,...,output_typeM) )","title":"Signature Calculation Syntax"},{"location":"Compilers/Specification of ABI/#sample-implementation","text":"Function func(int64 param1, bool param2) - uint32 Function Signature func(int64,bool)(uint32) Function Hash sha256( func(int64,bool)(uint32) ) = 0xA6BF22A36FD64ADD2A0EE012A2E137834E0609D24499A2CBFBACC8187C0D288F And the function ID then is 0xA6BF22A3","title":"Sample Implementation"},{"location":"Compilers/Specification of ABI/#types","text":"uint M : unsigned M bit integer. Big-endian encoded unsigned integer stored in the cell-data. int M : two\u2019s complement signed M bit integer. Big-endian encoded signed integer stored in the cell-data. dint : signed integer value with dynamic size. Encoded as Base 128 Varints proposed by Google in Protocol Buffers documentation . See further for more information. duint : two\u2019s complement dynamic sized usigned integer value. Encoded as Base 128 Varints proposed by Google in Protocol Buffers documentation . See further for more information. bool : equivalent to uint1. tuple (T1, T2, ..., Tn) : tuple that includes T1 , ..., Tn , n =0 types encoded in the following way: Enc(X(1)) Enc(X(2)) . . ., Enc(X(n)); where X(i) is type of T(i) for i in 1..n T[] : dynamic array of T type elements encoded in the following way: 2 bits stored in the cell-data define serialization algorithm. [00] - array is put into a separate cell. In case of array overflowing the maximum cell-data size it's split into multiple sequential cells. [10] - bits sequence is put in the cell-data. The next 8 bits (1 byte) define the number of elements of the array. It's followed by the sequence of encoded array elements. [01]/[11] - reserved. T[k] : static size array of T type elements encoded in the following way: 2 bits put in the cell-data define serialization algorithm. [00] - array is put into a separate cell. In case of array overflowing the maximum cell-data size it's split into multiple sequential cells. [10] - bits sequence is put in the cell-data. It's followed by the sequence of encoded array elements. [01]/[11] - reserved. bits M : static sized bits sequence. Encoding is equivalent to bool[M] bitsring : dynamic sized bits sequence. Encoding is equivalent to bool[]","title":"Types"},{"location":"Compilers/Specification of ABI/#base-128-for-varints","text":"Varints are used to serialize integers having one or more bytes (smaller numbers take a smaller number of bytes). Each byte in a varint except the last one has the most significant bit (msb) set; it indicates that there are more bytes to come. The lower 7 bits in each byte store the two's complement representation of the number in groups of 7 bits; least significant group first . For example, here is the number 1, it is a single byte, so no msb is set: 0000 0001 Syntax \u200b C, C++, C# CoffeeScript CSS Dockerfile diff Go Groovy HAML Handlebars HTML templates (Rails, ASP.NET) HTML HTTP Java JavaScript JSX (React) LESS Objective C Perl PHP Pug Puppet Python Ruby Rust Sass Scala SCSS Shell SQL Swift Vue.js XML YAML HTML In this example we handle the number 300, it is more complicated: 1010 1100 0000 0010 Syntax \u200b C, C++, C# CoffeeScript CSS Dockerfile diff Go Groovy HAML Handlebars HTML templates (Rails, ASP.NET) HTML HTTP Java JavaScript JSX (React) LESS Objective C Perl PHP Pug Puppet Python Ruby Rust Sass Scala SCSS Shell SQL Swift Vue.js XML YAML HTML Deserializing this number from the above binary string starts from dropping the msb from each byte including the byte with msb set to 0 (it is the set in the first byte, as there is more than one byte in the varint ): 1010 1100 0000 0010 \u2192 010 1100 000 0010 Syntax \u200b C, C++, C# CoffeeScript CSS Dockerfile diff Go Groovy HAML Handlebars HTML templates (Rails, ASP.NET) HTML HTTP Java JavaScript JSX (React) LESS Objective C Perl PHP Pug Puppet Python Ruby Rust Sass Scala SCSS Shell SQL Swift Vue.js XML YAML HTML Then, to get the final value, the two groups of 7 bits are put in the reverse order and concatenated: 000 0010 010 1100 \u2192 000 0010 ++ 010 1100 \u2192 100101100 \u2192 256 + 32 + 8 + 4 = 300 Syntax \u200b C, C++, C# CoffeeScript CSS Dockerfile diff Go Groovy HAML Handlebars HTML templates (Rails, ASP.NET) HTML HTTP Java JavaScript JSX (React) LESS Objective C Perl PHP Pug Puppet Python Ruby Rust Sass Scala SCSS Shell SQL Swift Vue.js XML YAML HTML","title":"Base 128 for Varints"},{"location":"Compilers/Specification of ABI/#overflow","text":"","title":"Overflow"},{"location":"Compilers/Specification of ABI/#cell-data","text":"If the data does not fit into the available space of the current cell-data, it is split for maximum utilization of space in the current cell. A reference to a new cell is added to the current one and it continues with the remaining part, and a new cell as a current.","title":"Cell Data"},{"location":"Compilers/Specification of ABI/#cell-reference-limit","text":"For the simplicity, this ABI version reserves the last cell-reference spot for the cell-data overflow case. If the cell-reference limit in the current cell is already reached (save for the reserved spot) and a new cell is required, the current cell is considered complete and a new one is created. The reference to a new cell is stored in the reserved spot and it continues with the new cell as a current one.","title":"Cell Reference Limit"},{"location":"Compilers/Specification of ABI/#contract-interface","text":"Contract interface functions are specified in JSON format. The contract JSON description specified each interface function signature, including its name, input and output parameters. Functions specified in the contract interface can be called from other contracts or from outside the blockchain via ABI call. A function description is a JSON object with the following fields: name : function name; inputs : an array of objects, each containing: name : parameter name; type : the canonical parameter type. components : used for tuple types, optional. outputs : an array of objects similar to inputs , can be omitted if function does not return anything; signed : boolean indicating the need for message signing The list of interface function descriptions is included to contract interface specification as the functions field. The interface specification also specifies an ABI encoding format version: ABI version : x The whole JSON contract interface consists of the ABI version field and list of interface function descriptions. A contract specification example is provided below.","title":"Contract Interface"},{"location":"Compilers/Specification of ABI/#modification-support","text":"As specified above, the JSON contract interface description contains versions of the ABI encoding format and the contract interface. So, a JSON description in a contract defines the used version of ABI encoding algorithm and its own interface version. Having this data, a caller determines how to encode parameters for the current contract version. The first byte of encoded function parameters is reserved for the ABI format version, enabling the deserializer to check whether the caller uses the same version and parameters are encoded correctly.","title":"Modification Support"},{"location":"Compilers/Specification of ABI/#rationale","text":"The present serialization method is selected to reduce messages represented as a tree of cells according to TON blockchain specification. Simple types are encoded \"in place\", i.e. encoded data is stored to the current cell data. For composite types with varying size ranges two serialization methods are provided: the same encoding \"in place\" and encoding in a chain of separate cells. The method selection takes place during the run time and depends on the array size. Thus, small arrays fitting into a 8 bit field are stored in the current cell, while larger ones that take several cells are stored into a chain of separate cells to simplify access to parameters that come next. Two bits are reserved for array encoding type definition, so that other two encoding types could be defined.","title":"Rationale"},{"location":"Compilers/Specification of ABI/#sample-code","text":"Contract interface specification example: { ABI version : 0, functions : [ { inputs : [ { name : recipient , type : bits256 }, { name : value , type : duint } ], name : sendTransaction , signed : true, outputs : [ { name : transaction , type : uint64 }, { name : error , type : int8 } ] }, { inputs : [ { name : type , type : uint8 }, { name : value , type : duint }, { name : meta , type : bitstring } ], name : createLimit , signed : true, outputs : [ { name : limitId , type : uint8 }, { name : error , type : int8 } ] }, { inputs : [ { name : limitId , type : uint8 }, { name : value , type : duint }, { name : meta , type : bitstring } ], name : changeLimitById , signed : true, outputs : [ { name : error , type : int8 } ] }, { inputs : [ { name : limitId , type : uint8 } ], name : removeLimit , signed : true, outputs : [ { name : error , type : int8 } ] }, { inputs : [ { name : limitId , type : uint8 } ], name : getLimitById , outputs : [ { name : limitInfo , type : tuple , components : [ { name : value , type : duint }, { name : type , type : uint8 }, { name : meta , type : bitstring } ] }, { name : error , type : int8 } ] }, { inputs : [], name : getLimits , outputs : [ { name : list , type : uint8[] , }, { name : error , type : int8 } ] }, { inputs : [], name : getVersion , outputs : [ { name : version , type : tuple , components : [ { name : major , type : uint16 }, { name : minor , type : uint16 } ] }, { name : error , type : int8 } ] }, { inputs : [], name : getBalance , outputs : [ { name : balance , type : uint64 } ] } ] }","title":"Sample Code"},{"location":"Compilers/LLVM Compiler/C Support Status/","text":"Language Features FEATURE USAGE SUPPORT STATUS COMMENTS WORKAROUNDS 6.2.1 Scopes of identifiers Define scope and visibility rules Supported by LLVM 6.2.2 Linkages of identifiers Define linkage types: external, internal, no linkage Supported but not in the default pipeline. LLVM bitcode linkage is required The linker has to support linkage of multiple translation units.The workaround is to compile each translation unit into LLVM IR: clang -S -c -O3 input1.c -emit-llvm -o input1.ll clang -S -c -O3 input2.c -emit-llvm -o input2.ll Link the IR together: llvm-link input1.ll input2.ll -o input.bc And compiling the result: clang -O3 -S -c input.bc 6.2.3 Name spaces of identifiers Define classes of identifiers with disambiguation rules Supported by LLVM 6.2.4 Storage durations of objects Define automatic, static and other lifetimes Supported by LLVM 6.2.5 Types Define types in C Integer types _Bool, char, short, int, long, long long as well as their signed and unsigned counterparts Now a workaround is implemented, proper i257 is work in progress All integers are 257 bits wide Floating point types Not supported Floating point type does not exist in the TVM. It only works with 257-bit integers. Complex types Complex numbers Not supported Complex types do not exist in the TVM. It only works with 257-bit integers. Enumerations Supported by LLVM Void type Supported by LLVM Array type Supported, see notes Dynamic arrays not supported, optimizations pending. Arrays are currently implemented as general memory (via dictionaries), but tuples are considered. Also, additional testing is needed. Structure type Supported, see notes byval mishandling is a known issue. There are two types of transfer: by value and by reference. Byval is not supported, so the workaround is to use transfer by reference. Union type Supported Function type Supported Point type Supported Qualifiers const, volatile, restrict Supported by LLVM Persistent data handling needs coverage 6.2.5.9 Representation of unsigned types Specifies that overflow is not possible for unsigned integers Not supported Unsigned integers currently work the same way signed ones do. We have more testing in the pipeline and do not recommend using coding practices and tricks that rely on overflow values. 6.2.6 Representations of types Restrict binary representation of values Supported by LLVM We use SMR for signed numbers and it is in line with the specification (6.2.6.2). It also allow representing signed numbers with more bits than its unsigned counterpart. 6.2.7 Compatible type and composite type Define value conversion rules Supported by LLVM 6.3 Conversions Define type conversion rules Supported by LLVM All the conversions are supported, but testing is still in progress 6.4 Lexical elements Define C syntax Supported by LLVM The syntax was not changed 6.5 Expressions Define rules to build an expression in C and the relevant semantics Generally supported, additional checking may be required bitwise operations on signed integers contain implementation particularities. No SMR issues expected unless Clang assumes a different representation 6.6 Constant Expressions Defines expressions that are calculated in compile time, defines the sizeof semantics The feature itself is supported by LLVM, but we supply Clang with false integer type size information. i257 activities block the feature Full support requires correct operation of sizeof work making sure that (T*)((char *)a + sizeof(*a)) is the same as a[1] 6.7 Declarations, except 6.7.8 Initialization Define how syntax and semantics of declarations (and definitions in C) Supported by LLVM 6.7.8 Initialization Defines value initialization Pending, testing in progress Issues not supporting implicit 0 initialization for static data were tested. Now it is necessary to makes sure that all initialization cases from N1256 (C99) work correctly and that the linker supports all related sections. For example, the .comm directive is not supported now. 6.8 Statements and blocks Define constructs shaping control-flow in C: loops, if, switch, goto, return, etc Supported More optimization needed. Switch is currently lowered with LLVM lowerswitch pass, native support under consideration, as well as additional control-flow optimizations 6.9 External definitions Define how external function and objects are declared in C Not supported by the Linker, workaround to be provided 6.10 Preprocessing directives #define , #include , etc Supported by LLVM J.2 Undefined behavior Limited support Tests and feedback needed TVM builtins For each core, non-stack manipulation instruction in TVM there has to be an intrinsic-based way to generate it in the compiler. A low-level library developer has to be familiar with these intrinsics. For example an LDU instruction accessible via the llvm.tvm.ldu intrinsic. Partially supported, more effort needed Limitation related to the current runtime implementation TVM annotations Denote special meaning for functions (e.g. sign check, public method, etc.) and data (e.g. persistent data) Partially supported Naming rules used instead of annotations (not optimal) Persistent data semantic Supported More optimizations needed C Standard Library FEATURE USAGE SUPPORT STATUS COMMENTS WORKAROUNDS 7.1.3 Reserved identifiers Define the list of identifiers that have to be avoided in our libraries Reserved identifiers are used 7.2 Diagnostics Defines the assert macro: a standard debugging tool used by C / C++ developers Not supported 7.4 Character handling Character operations Not supported, low priority 7.57.10 Sizes of integer types Errors A low level method for handling errors in the library and in system calls Not supported Considered for support if required to achieve compatibility with other parts of the C standard library 7.8 Format conversion of integer types Used for printing, converting to/from strings and for some auxiliary functions Not supported, low priority 7.10 Sizes of integer types Integer type size definition Not supported, but considered for implementation 7.15 Variable arguments Variable argument processing Not supported 7.16 Boolean type and values Define bool , true , false and _ _bool_true_false_are_defined Not supported, but planned to 7.17 Common definitions Define ptrdiff_t , size_t , wchar_t , NULL , offsetof Not supported 7.18 Integer types Used to define intN_t , intptr_t , and other integer types, as well as macro that set their limits Not supported Considered for implementation if proves to help serialization / deserialization 7.20 General utilities Used to define general utility items that we do not seem to need now except for the functions listed below Not supported, only partial implementation can be planned 7.20.3 Memory management functions calloc , malloc , realloc , free Not supported, high priority 7.20.4 Communication with the environment abort , exit , atexit , _Exit , getenv , system Not supported, low priority Standard C program termination mechanisms under consideration 7.20.5 Searching and sorting utilities Not supported, partially implemented and being tested 7.21 String handling Stings memory operations Not implemented, only the features below have priority 7.21.2 Copying functions memcpy, memmove, aslo its string conterparts. Implemented partially in the runtime, needs to be moved to the std lib 7.21.4 Comparison functions memcmp Not implemented 7.21.6 Miscellaneous functions memset Implemented as a part of the runtime, need to be moved to the std lib 7.23 Date and time Not implemented C for TVM Numbers in the Feature column indicate references to the TON TVM specification. Please, refer to the original document. FEATURE USAGE SUPPORT STATUS COMMENTS TVM types Partially implemented Only integers are supported Operations with cells (A.7) Slice, Builder, Dictionary, Message, External Internal addresses, etc. Partially implemented in the runtime Standard node operations involve data types specified in Assembly instructions. These Assembly instructions are converted into C equivalents at some point of the optimization process Operations with dictionaries (A.10) #include cell.h Limited implementation in the runtime A low level library that is implemented via cell intrinsics to provide developer-friendly cell handling options. GAS related logic (A.11.2) Functions to buy gas for Grams and vice versa, defines gas limits Not implemented Same as above for dictionaries Operations with time (A.11.4) Current time, time of the current block and transaction Not implemented Hashing and cryptography (A.11.5) Not implemented Currency manipulation (A.11.6) Loads and stores Grams Partial implementation Message serialization Implemented Message deserialization Implemented Outbound message and output action (A.11.8) Partially implemented Sending messages available Debug support (A.12) Partially implemented For more details on available debugging options, navigate to the Debugging options topic. Events emitting Not implemented Planned Convenience FEATURE USAGE SUPPORT STATUS NOTES SUGGESTIONS Toolchain support in the driver: the driver should use our std lib headers (or don't use it at all) instead of using the system ones Not implemented Planned Toolchain support in the driver: default pipeline is to be available clang -O3 input.c should produce a .boc file (or return a compilation error) Not implemented Planned","title":"Language Features"},{"location":"Compilers/LLVM Compiler/C Support Status/#language-features","text":"FEATURE USAGE SUPPORT STATUS COMMENTS WORKAROUNDS 6.2.1 Scopes of identifiers Define scope and visibility rules Supported by LLVM 6.2.2 Linkages of identifiers Define linkage types: external, internal, no linkage Supported but not in the default pipeline. LLVM bitcode linkage is required The linker has to support linkage of multiple translation units.The workaround is to compile each translation unit into LLVM IR: clang -S -c -O3 input1.c -emit-llvm -o input1.ll clang -S -c -O3 input2.c -emit-llvm -o input2.ll Link the IR together: llvm-link input1.ll input2.ll -o input.bc And compiling the result: clang -O3 -S -c input.bc 6.2.3 Name spaces of identifiers Define classes of identifiers with disambiguation rules Supported by LLVM 6.2.4 Storage durations of objects Define automatic, static and other lifetimes Supported by LLVM 6.2.5 Types Define types in C Integer types _Bool, char, short, int, long, long long as well as their signed and unsigned counterparts Now a workaround is implemented, proper i257 is work in progress All integers are 257 bits wide Floating point types Not supported Floating point type does not exist in the TVM. It only works with 257-bit integers. Complex types Complex numbers Not supported Complex types do not exist in the TVM. It only works with 257-bit integers. Enumerations Supported by LLVM Void type Supported by LLVM Array type Supported, see notes Dynamic arrays not supported, optimizations pending. Arrays are currently implemented as general memory (via dictionaries), but tuples are considered. Also, additional testing is needed. Structure type Supported, see notes byval mishandling is a known issue. There are two types of transfer: by value and by reference. Byval is not supported, so the workaround is to use transfer by reference. Union type Supported Function type Supported Point type Supported Qualifiers const, volatile, restrict Supported by LLVM Persistent data handling needs coverage 6.2.5.9 Representation of unsigned types Specifies that overflow is not possible for unsigned integers Not supported Unsigned integers currently work the same way signed ones do. We have more testing in the pipeline and do not recommend using coding practices and tricks that rely on overflow values. 6.2.6 Representations of types Restrict binary representation of values Supported by LLVM We use SMR for signed numbers and it is in line with the specification (6.2.6.2). It also allow representing signed numbers with more bits than its unsigned counterpart. 6.2.7 Compatible type and composite type Define value conversion rules Supported by LLVM 6.3 Conversions Define type conversion rules Supported by LLVM All the conversions are supported, but testing is still in progress 6.4 Lexical elements Define C syntax Supported by LLVM The syntax was not changed 6.5 Expressions Define rules to build an expression in C and the relevant semantics Generally supported, additional checking may be required bitwise operations on signed integers contain implementation particularities. No SMR issues expected unless Clang assumes a different representation 6.6 Constant Expressions Defines expressions that are calculated in compile time, defines the sizeof semantics The feature itself is supported by LLVM, but we supply Clang with false integer type size information. i257 activities block the feature Full support requires correct operation of sizeof work making sure that (T*)((char *)a + sizeof(*a)) is the same as a[1] 6.7 Declarations, except 6.7.8 Initialization Define how syntax and semantics of declarations (and definitions in C) Supported by LLVM 6.7.8 Initialization Defines value initialization Pending, testing in progress Issues not supporting implicit 0 initialization for static data were tested. Now it is necessary to makes sure that all initialization cases from N1256 (C99) work correctly and that the linker supports all related sections. For example, the .comm directive is not supported now. 6.8 Statements and blocks Define constructs shaping control-flow in C: loops, if, switch, goto, return, etc Supported More optimization needed. Switch is currently lowered with LLVM lowerswitch pass, native support under consideration, as well as additional control-flow optimizations 6.9 External definitions Define how external function and objects are declared in C Not supported by the Linker, workaround to be provided 6.10 Preprocessing directives #define , #include , etc Supported by LLVM J.2 Undefined behavior Limited support Tests and feedback needed TVM builtins For each core, non-stack manipulation instruction in TVM there has to be an intrinsic-based way to generate it in the compiler. A low-level library developer has to be familiar with these intrinsics. For example an LDU instruction accessible via the llvm.tvm.ldu intrinsic. Partially supported, more effort needed Limitation related to the current runtime implementation TVM annotations Denote special meaning for functions (e.g. sign check, public method, etc.) and data (e.g. persistent data) Partially supported Naming rules used instead of annotations (not optimal) Persistent data semantic Supported More optimizations needed","title":"Language Features"},{"location":"Compilers/LLVM Compiler/C Support Status/#c-standard-library","text":"FEATURE USAGE SUPPORT STATUS COMMENTS WORKAROUNDS 7.1.3 Reserved identifiers Define the list of identifiers that have to be avoided in our libraries Reserved identifiers are used 7.2 Diagnostics Defines the assert macro: a standard debugging tool used by C / C++ developers Not supported 7.4 Character handling Character operations Not supported, low priority 7.57.10 Sizes of integer types Errors A low level method for handling errors in the library and in system calls Not supported Considered for support if required to achieve compatibility with other parts of the C standard library 7.8 Format conversion of integer types Used for printing, converting to/from strings and for some auxiliary functions Not supported, low priority 7.10 Sizes of integer types Integer type size definition Not supported, but considered for implementation 7.15 Variable arguments Variable argument processing Not supported 7.16 Boolean type and values Define bool , true , false and _ _bool_true_false_are_defined Not supported, but planned to 7.17 Common definitions Define ptrdiff_t , size_t , wchar_t , NULL , offsetof Not supported 7.18 Integer types Used to define intN_t , intptr_t , and other integer types, as well as macro that set their limits Not supported Considered for implementation if proves to help serialization / deserialization 7.20 General utilities Used to define general utility items that we do not seem to need now except for the functions listed below Not supported, only partial implementation can be planned 7.20.3 Memory management functions calloc , malloc , realloc , free Not supported, high priority 7.20.4 Communication with the environment abort , exit , atexit , _Exit , getenv , system Not supported, low priority Standard C program termination mechanisms under consideration 7.20.5 Searching and sorting utilities Not supported, partially implemented and being tested 7.21 String handling Stings memory operations Not implemented, only the features below have priority 7.21.2 Copying functions memcpy, memmove, aslo its string conterparts. Implemented partially in the runtime, needs to be moved to the std lib 7.21.4 Comparison functions memcmp Not implemented 7.21.6 Miscellaneous functions memset Implemented as a part of the runtime, need to be moved to the std lib 7.23 Date and time Not implemented","title":"C Standard Library"},{"location":"Compilers/LLVM Compiler/C Support Status/#c-for-tvm","text":"Numbers in the Feature column indicate references to the TON TVM specification. Please, refer to the original document. FEATURE USAGE SUPPORT STATUS COMMENTS TVM types Partially implemented Only integers are supported Operations with cells (A.7) Slice, Builder, Dictionary, Message, External Internal addresses, etc. Partially implemented in the runtime Standard node operations involve data types specified in Assembly instructions. These Assembly instructions are converted into C equivalents at some point of the optimization process Operations with dictionaries (A.10) #include cell.h Limited implementation in the runtime A low level library that is implemented via cell intrinsics to provide developer-friendly cell handling options. GAS related logic (A.11.2) Functions to buy gas for Grams and vice versa, defines gas limits Not implemented Same as above for dictionaries Operations with time (A.11.4) Current time, time of the current block and transaction Not implemented Hashing and cryptography (A.11.5) Not implemented Currency manipulation (A.11.6) Loads and stores Grams Partial implementation Message serialization Implemented Message deserialization Implemented Outbound message and output action (A.11.8) Partially implemented Sending messages available Debug support (A.12) Partially implemented For more details on available debugging options, navigate to the Debugging options topic. Events emitting Not implemented Planned","title":"C for TVM"},{"location":"Compilers/LLVM Compiler/C Support Status/#convenience","text":"FEATURE USAGE SUPPORT STATUS NOTES SUGGESTIONS Toolchain support in the driver: the driver should use our std lib headers (or don't use it at all) instead of using the system ones Not implemented Planned Toolchain support in the driver: default pipeline is to be available clang -O3 input.c should produce a .boc file (or return a compilation error) Not implemented Planned","title":"Convenience"},{"location":"Compilers/LLVM Compiler/C to TVM Library/","text":"General Program Structure Traditional C programs have one main function, which in turn calls other functions. Contracts look more like classes with multiple functions, callable from outside. Also, for more similarity, each contract has its own memory (it is called persistent in TVM). So, a typical contract in C has no main function, but has several public methods, and several persistent variables. Public methods A function becomes a public method for contract X, if it is declared in the X.abi file. Global and persistent variables Programs written in C language call code once: before the code starts working all data is initialized; after execution is over, all data is disposed of. As far as contracts are concerned, they retain their state between contract methods invocations. So there are two different types of global variables: traditional global C variables are forgotten after the method stops working; persistent variables, which are stored in blockchain; these values remain (persist) between method invocations. Global variables can be made persistent by adding the _persistent postfix: int x = 0; // Forgotten after each method invocation int y_persistent = 0; // Kept in blockchain and does not lose its value Low-Level Implementation Details The above primitives are written by TON Labs team, and TVM does not really impose this format of communication. In fact, a contract has a single entry point. When a request (message) is made it, a slice (that is, a bit string) is provided along with it. A low-level part of the TON standard library contains a selector: a special function that parses a slice and calls a given contract method. Method selection is determined by a method id specified in the initial bytes of the slice. The remaining slice elements are stored into a working slice. Contract methods are generated by a special script according to an abi file. Then they are put into a X_wrapper.c file , where X is the name of the contract. These methods deserialize parameters from a slice and transfer them as parameters to the proper contract function implementation. Library Structure The library is a set of files that have to be included into your contract code directly or indirectly to implement predefined C structures. These structures are designed to ensure smoother development of code that can be compiled to TVM Assembly. For learning purposes, we provide a commented sample contract that shows how library files are included in it, how they work, and how the code is written with regard to it. This contract is a blockchain transfer transaction designed for a Piggy Bank dapp. Note that the library has a cross-reference structure. In other words, files, included into the final smart contract (.h headers with declarations), in turn, include other files (.inc with definitions) from the library. Also, there are .inc or .c files that contain implementations for declarations and definitions. But, these are not included into other files or into the contract itself. The file naming convention indicates that there are files implementing the TON-compatible C structures, messaging logic, contract data (fields) and files that allow defining TVM-specific components in C. The arguments.h file enables faster function argument parsing without introducing additional structures. Inclusion Pattern Detailed File Description The sample smart contract includes several header files. Basically, they allow creating a valid version of a smart-contract. Given follow-up library revisions and modifications, as well as project particularities, you may find that some files are redundant for you. #include ton-sdk/tvm.h #include ton-sdk/messages.h #include ton-sdk/arguments.h #include ton-sdk/smart-contract-info.h The body of the contract contains arguments that are parsed, business logic stored in permanent memory and the final message. The first part of the message is taken from the ABI protocol and the second is generated by the contract (big integer, 46 symbols). TVM.h The tvm.h file declares general C structures. Note : Bodies of functions for value manipulation are implemented in the tvm.c file, which is compiled along with your source files and linked to the resulting contract binary file. smart-contract-info.h, smart-contract-info.inc, define-ton-structure-header.inc The smart-contract-info.h header file defines SmartContractInfo TON-specific structure. The fields of the structure are declared in smart-contract-info.inc file. File define-ton-structure-header.inc contains some helper macroses, which declare: SmartContractInfo structure by itself builder and cell serialization functions slice and cell deserialization functions Note : Please, refer to the TVM specification for more info on the concept of bag of cells , cell serialization and slice deserialization. The smart-contract-info.inc defines the contract field structure in the TON_STRUCT macro. The macro lists the supported fields with names, lengths and types. #define TON_STRUCT_NAME SmartContractInfo #define TON_STRUCT \\\\ FIELD_CONSTANT_UNSIGNED(smc_info, 0x076ef1ea, 32) \\\\ FIELD_UNSIGNED(actions, 16) \\\\ FIELD_UNSIGNED(msgs_sent, 16) \\\\ FIELD_UNSIGNED(unixtime, 32) \\\\ FIELD_UNSIGNED(block_lt, 64) \\\\ FIELD_UNSIGNED(trans_lt, 64) \\\\ FIELD_UNSIGNED(rand_seed, 256) \\\\ FIELD_COMPLEX(balance_remaining, CurrencyCollection) \\\\ FIELD_COMPLEX(myself, MsgAddressInt) #include HEADER_OR_C #undef HEADER_OR_C Below is field declarations and macroses in the above code are explained: The first line defines the structure name, SmartContractInfo (this macro is used in many points where structure name is necessary). FIELD_CONSTANT_UNSIGNED macro defines a constant (\"virtual\") field which is not really stored within a structure, but its value is placed into a slice at serialization and checked at deserialization. FIELD_UNSIGNED no in-depth explanation needed. FIELD_COMPLEX allows to define a nested structure. HEADER_OR_C macro includes either source or header file depending on the context. This macro is undefined after use to allow declaring the next structure in file (if exists) without warnings that a macro is already declared. This complicated system of includes and macroses defines a lot of useful functions and structures. For example, the function below from the contract returns balance information in compliance with the structure defined in the macro. SmartContractInfo sc_info = get_SmartContractInfo(); int balance = sc_info.balance_remaining.grams.amount; message.h and message.inc The message.h file declares a macro to enable messaging procedures. In refers to the message.inc file where actual messaging rules are defined. The message.inc maps messaging rules to structures and fields declared in the tvm.h and define-ton-struct-header.inc files. The arguments.h file is covered above. Notes on the ABI Contract messages in TON Labs contracts are formatted according to ABI specifications. Currently only (u)int values are supported.","title":"C to TVM Library"},{"location":"Compilers/LLVM Compiler/C to TVM Library/#general-program-structure","text":"Traditional C programs have one main function, which in turn calls other functions. Contracts look more like classes with multiple functions, callable from outside. Also, for more similarity, each contract has its own memory (it is called persistent in TVM). So, a typical contract in C has no main function, but has several public methods, and several persistent variables.","title":"General Program Structure"},{"location":"Compilers/LLVM Compiler/C to TVM Library/#public-methods","text":"A function becomes a public method for contract X, if it is declared in the X.abi file.","title":"Public methods"},{"location":"Compilers/LLVM Compiler/C to TVM Library/#global-and-persistent-variables","text":"Programs written in C language call code once: before the code starts working all data is initialized; after execution is over, all data is disposed of. As far as contracts are concerned, they retain their state between contract methods invocations. So there are two different types of global variables: traditional global C variables are forgotten after the method stops working; persistent variables, which are stored in blockchain; these values remain (persist) between method invocations. Global variables can be made persistent by adding the _persistent postfix: int x = 0; // Forgotten after each method invocation int y_persistent = 0; // Kept in blockchain and does not lose its value","title":"Global and persistent variables"},{"location":"Compilers/LLVM Compiler/C to TVM Library/#low-level-implementation-details","text":"The above primitives are written by TON Labs team, and TVM does not really impose this format of communication. In fact, a contract has a single entry point. When a request (message) is made it, a slice (that is, a bit string) is provided along with it. A low-level part of the TON standard library contains a selector: a special function that parses a slice and calls a given contract method. Method selection is determined by a method id specified in the initial bytes of the slice. The remaining slice elements are stored into a working slice. Contract methods are generated by a special script according to an abi file. Then they are put into a X_wrapper.c file , where X is the name of the contract. These methods deserialize parameters from a slice and transfer them as parameters to the proper contract function implementation.","title":"Low-Level Implementation Details"},{"location":"Compilers/LLVM Compiler/C to TVM Library/#library-structure","text":"The library is a set of files that have to be included into your contract code directly or indirectly to implement predefined C structures. These structures are designed to ensure smoother development of code that can be compiled to TVM Assembly. For learning purposes, we provide a commented sample contract that shows how library files are included in it, how they work, and how the code is written with regard to it. This contract is a blockchain transfer transaction designed for a Piggy Bank dapp. Note that the library has a cross-reference structure. In other words, files, included into the final smart contract (.h headers with declarations), in turn, include other files (.inc with definitions) from the library. Also, there are .inc or .c files that contain implementations for declarations and definitions. But, these are not included into other files or into the contract itself. The file naming convention indicates that there are files implementing the TON-compatible C structures, messaging logic, contract data (fields) and files that allow defining TVM-specific components in C. The arguments.h file enables faster function argument parsing without introducing additional structures.","title":"Library Structure"},{"location":"Compilers/LLVM Compiler/C to TVM Library/#inclusion-pattern","text":"","title":"Inclusion Pattern"},{"location":"Compilers/LLVM Compiler/C to TVM Library/#detailed-file-description","text":"The sample smart contract includes several header files. Basically, they allow creating a valid version of a smart-contract. Given follow-up library revisions and modifications, as well as project particularities, you may find that some files are redundant for you. #include ton-sdk/tvm.h #include ton-sdk/messages.h #include ton-sdk/arguments.h #include ton-sdk/smart-contract-info.h The body of the contract contains arguments that are parsed, business logic stored in permanent memory and the final message. The first part of the message is taken from the ABI protocol and the second is generated by the contract (big integer, 46 symbols).","title":"Detailed File Description"},{"location":"Compilers/LLVM Compiler/C to TVM Library/#tvmh","text":"The tvm.h file declares general C structures. Note : Bodies of functions for value manipulation are implemented in the tvm.c file, which is compiled along with your source files and linked to the resulting contract binary file.","title":"TVM.h"},{"location":"Compilers/LLVM Compiler/C to TVM Library/#smart-contract-infoh-smart-contract-infoinc-define-ton-structure-headerinc","text":"The smart-contract-info.h header file defines SmartContractInfo TON-specific structure. The fields of the structure are declared in smart-contract-info.inc file. File define-ton-structure-header.inc contains some helper macroses, which declare: SmartContractInfo structure by itself builder and cell serialization functions slice and cell deserialization functions Note : Please, refer to the TVM specification for more info on the concept of bag of cells , cell serialization and slice deserialization. The smart-contract-info.inc defines the contract field structure in the TON_STRUCT macro. The macro lists the supported fields with names, lengths and types. #define TON_STRUCT_NAME SmartContractInfo #define TON_STRUCT \\\\ FIELD_CONSTANT_UNSIGNED(smc_info, 0x076ef1ea, 32) \\\\ FIELD_UNSIGNED(actions, 16) \\\\ FIELD_UNSIGNED(msgs_sent, 16) \\\\ FIELD_UNSIGNED(unixtime, 32) \\\\ FIELD_UNSIGNED(block_lt, 64) \\\\ FIELD_UNSIGNED(trans_lt, 64) \\\\ FIELD_UNSIGNED(rand_seed, 256) \\\\ FIELD_COMPLEX(balance_remaining, CurrencyCollection) \\\\ FIELD_COMPLEX(myself, MsgAddressInt) #include HEADER_OR_C #undef HEADER_OR_C Below is field declarations and macroses in the above code are explained: The first line defines the structure name, SmartContractInfo (this macro is used in many points where structure name is necessary). FIELD_CONSTANT_UNSIGNED macro defines a constant (\"virtual\") field which is not really stored within a structure, but its value is placed into a slice at serialization and checked at deserialization. FIELD_UNSIGNED no in-depth explanation needed. FIELD_COMPLEX allows to define a nested structure. HEADER_OR_C macro includes either source or header file depending on the context. This macro is undefined after use to allow declaring the next structure in file (if exists) without warnings that a macro is already declared. This complicated system of includes and macroses defines a lot of useful functions and structures. For example, the function below from the contract returns balance information in compliance with the structure defined in the macro. SmartContractInfo sc_info = get_SmartContractInfo(); int balance = sc_info.balance_remaining.grams.amount;","title":"smart-contract-info.h, smart-contract-info.inc, define-ton-structure-header.inc"},{"location":"Compilers/LLVM Compiler/C to TVM Library/#messageh-and-messageinc","text":"The message.h file declares a macro to enable messaging procedures. In refers to the message.inc file where actual messaging rules are defined. The message.inc maps messaging rules to structures and fields declared in the tvm.h and define-ton-struct-header.inc files. The arguments.h file is covered above.","title":"message.h and message.inc"},{"location":"Compilers/LLVM Compiler/C to TVM Library/#notes-on-the-abi","text":"Contract messages in TON Labs contracts are formatted according to ABI specifications. Currently only (u)int values are supported.","title":"Notes on the ABI"},{"location":"Compilers/LLVM Compiler/Compiler Highlights/","text":"Components Toolchain: c - binary Standard library \u2013 runtime Contract development library Compiler TVM-linker Implemented Languages C Limited C++ support: C++98, C++03, C++11, C++14, most features of C++17. For more details see https://clang.llvm.org/cxx_status.html for Clang 7 It was checked that classes, inheritance without virtual methods, templates and overloading work. Note that virtual methods and exceptions are not supported.","title":"Compiler Highlights"},{"location":"Compilers/LLVM Compiler/Compiler Highlights/#components","text":"Toolchain: c - binary Standard library \u2013 runtime Contract development library Compiler TVM-linker","title":"Components"},{"location":"Compilers/LLVM Compiler/Compiler Highlights/#implemented-languages","text":"C Limited C++ support: C++98, C++03, C++11, C++14, most features of C++17. For more details see https://clang.llvm.org/cxx_status.html for Clang 7 It was checked that classes, inheritance without virtual methods, templates and overloading work. Note that virtual methods and exceptions are not supported.","title":"Implemented Languages"},{"location":"Compilers/LLVM Compiler/Debugging Options/","text":"Analyze Test For the time being, there is not way to analyze contract return values: the contract sends external messages, and the instrument which can parse them is yet to be developed. Still, there are two ways to visualize contract execution results: peeking into persistent memory and transferring funds to other accounts. For the issues below, we consider that you already sent all messages to contracts and now are analyzing new state of the blockchain. Persistent Memory This method requires your contract to write values into persistent memory. Open a terminal window. Change your directory to /build_contract_ .c . Start test-lite-client: test-lite-client -\u0421 ton-global.json. Use the getaccount 0: command to retrieve the contact data (expect a long list of values). Find the ' data: ' string. It contains raw contents of the persistent memory specified after the string. Close the terminal when finished. Transferring Funds This method requires your contract to send funds to another account. Open a new terminal window. Change your directory to project-name /build_contract_ contract-name .c Start test-lite-client: **test-lite-client -\u0421 ton-global.json.** Use the **getaccount** **0: another account address** command to retrieve the contact data (expect a long list of values). Find **storage/balance/grams/amount** field (it is close to the top of the account info) and check its value. Close the terminal when finished.","title":"Debugging Options"},{"location":"Compilers/LLVM Compiler/Debugging Options/#analyze-test","text":"For the time being, there is not way to analyze contract return values: the contract sends external messages, and the instrument which can parse them is yet to be developed. Still, there are two ways to visualize contract execution results: peeking into persistent memory and transferring funds to other accounts. For the issues below, we consider that you already sent all messages to contracts and now are analyzing new state of the blockchain.","title":"Analyze &amp; Test"},{"location":"Compilers/LLVM Compiler/Debugging Options/#persistent-memory","text":"This method requires your contract to write values into persistent memory. Open a terminal window. Change your directory to /build_contract_ .c . Start test-lite-client: test-lite-client -\u0421 ton-global.json. Use the getaccount 0: command to retrieve the contact data (expect a long list of values). Find the ' data: ' string. It contains raw contents of the persistent memory specified after the string. Close the terminal when finished.","title":"Persistent Memory"},{"location":"Compilers/LLVM Compiler/Debugging Options/#transferring-funds","text":"This method requires your contract to send funds to another account. Open a new terminal window. Change your directory to project-name /build_contract_ contract-name .c Start test-lite-client: **test-lite-client -\u0421 ton-global.json.** Use the **getaccount** **0: another account address** command to retrieve the contact data (expect a long list of values). Find **storage/balance/grams/amount** field (it is close to the top of the account info) and check its value. Close the terminal when finished.","title":"Transferring Funds"},{"location":"Compilers/Solidity-Compiler/Reference Guide/","text":"Decrements The current compiler version does not support Solidity decrements operation. Don't use expressions like: b--; Use instead: b - 1; String Literals The current compiler version does not support Solidity string literal. Avoid expressions like: bytes32 b = foo ; And: string memory b = foo ; Unfixed Decimals Unfixed decimals are not currently supported by the compiler, avoid expressions like: ufixed b = a * 2.5; Conditional Loops The compiler supports for and while conditional loops, but does not support do .. while.. expressions. Don't use: do { i++; } while (i x); Use instead: i++; while (i x) { i++; } Comma Operator The comma operator is not yet supported by the compiler, use the suggested workaround. Don't use expressions like: a = (b++, c++); Use instead: b++; a = c++; All in all, this operator is not used often, but you may need for an expression like: void rev(char *s, size_t len) { char *first; for (first = s, s += len; s = first; --s) { putchar(*s); } } Function Modifiers Currently, modifiers are not supported by the sol2tmv compiler, though it is a planned feature and we have a workaround. Modifiers must be called directly as functions. The modifier should be defined as a pure or view internal function and should compile correctly. Example //original solidity contract Test { address owner; modifier onlyOwner() { require(msg.sender == owner); _; } function doSmthg() public onlyOwner { } } //sol2tvm contract Test { address owner; function onlyOwner() view internal { require(msg.sender == owner); } function doSmthg() public { onlyOwner(); } } Assembly Inline, Solidity and Standalone assembly implementations are not used outside the Ethereum VM. TON Labs sol2tvm compiler uses its own equivalent of inline Assembly , other versions are not supported and cannot be compiled. Assembly is used sparingly in smart contracts and there is no hard and fast way to provide a workaround. If you have to migrate a smart contract containing assembly code, remove it or rewrite it in Solidity. Below we have some standard conversion samples taken from public sources. Sample 1 Assembly mul(1, add(2, 3)) Solidity uint a = (2+3) * 1; Sample 2 Assembly function add(uint a, uint b){ assembly { let sum := add(a, b) mstore(mload(0x40), sum) }} \u200b Solidity function add(uint a, uint b) { uint sum = a + b;} Call Functions These functions are best described in Solidity documentation here: https://solidity.readthedocs.io/en/v0.5.11/types.html#address Call, delegatecall and staticcall are used to interface with contracts that do not follow the ABI, or to get more direct control over the encoding. We are focused on providing the highest level of security in our products. So, we feel that interacting with contracts that do not have an ABI public description is not in line with what we want to achieve. Therefore, we do not support or have any plans to support these features or to create an analogue. Workarounds have not been specified yet. Return and Callback Return works as expected only for internal contract calls according to TON architecture. It is not possible to use return to receive a message back from external contract. By design, in TON you need to use callback as a separate function in the second contract that sends a message back. If contract A calls contract B and requires a return of value, a callback should be specified in contract A to receive the answer. Example: contract A { function a() { B.b(); //make request } function c() { //this is callback } } contract B { function b() { A.c() //send answer } }","title":"Reference Guide"},{"location":"Compilers/Solidity-Compiler/Reference Guide/#decrements","text":"The current compiler version does not support Solidity decrements operation. Don't use expressions like: b--; Use instead: b - 1;","title":"Decrements"},{"location":"Compilers/Solidity-Compiler/Reference Guide/#string-literals","text":"The current compiler version does not support Solidity string literal. Avoid expressions like: bytes32 b = foo ; And: string memory b = foo ;","title":"String Literals"},{"location":"Compilers/Solidity-Compiler/Reference Guide/#unfixed-decimals","text":"Unfixed decimals are not currently supported by the compiler, avoid expressions like: ufixed b = a * 2.5;","title":"Unfixed Decimals"},{"location":"Compilers/Solidity-Compiler/Reference Guide/#conditional-loops","text":"The compiler supports for and while conditional loops, but does not support do .. while.. expressions. Don't use: do { i++; } while (i x); Use instead: i++; while (i x) { i++; }","title":"Conditional Loops"},{"location":"Compilers/Solidity-Compiler/Reference Guide/#comma-operator","text":"The comma operator is not yet supported by the compiler, use the suggested workaround. Don't use expressions like: a = (b++, c++); Use instead: b++; a = c++; All in all, this operator is not used often, but you may need for an expression like: void rev(char *s, size_t len) { char *first; for (first = s, s += len; s = first; --s) { putchar(*s); } }","title":"Comma Operator"},{"location":"Compilers/Solidity-Compiler/Reference Guide/#function-modifiers","text":"Currently, modifiers are not supported by the sol2tmv compiler, though it is a planned feature and we have a workaround. Modifiers must be called directly as functions. The modifier should be defined as a pure or view internal function and should compile correctly.","title":"Function Modifiers"},{"location":"Compilers/Solidity-Compiler/Reference Guide/#example","text":"//original solidity contract Test { address owner; modifier onlyOwner() { require(msg.sender == owner); _; } function doSmthg() public onlyOwner { } } //sol2tvm contract Test { address owner; function onlyOwner() view internal { require(msg.sender == owner); } function doSmthg() public { onlyOwner(); } }","title":"Example"},{"location":"Compilers/Solidity-Compiler/Reference Guide/#assembly","text":"Inline, Solidity and Standalone assembly implementations are not used outside the Ethereum VM. TON Labs sol2tvm compiler uses its own equivalent of inline Assembly , other versions are not supported and cannot be compiled. Assembly is used sparingly in smart contracts and there is no hard and fast way to provide a workaround. If you have to migrate a smart contract containing assembly code, remove it or rewrite it in Solidity. Below we have some standard conversion samples taken from public sources.","title":"Assembly"},{"location":"Compilers/Solidity-Compiler/Reference Guide/#sample-1","text":"Assembly mul(1, add(2, 3)) Solidity uint a = (2+3) * 1;","title":"Sample 1"},{"location":"Compilers/Solidity-Compiler/Reference Guide/#sample-2","text":"Assembly function add(uint a, uint b){ assembly { let sum := add(a, b) mstore(mload(0x40), sum) }} \u200b Solidity function add(uint a, uint b) { uint sum = a + b;}","title":"Sample 2"},{"location":"Compilers/Solidity-Compiler/Reference Guide/#call-functions","text":"These functions are best described in Solidity documentation here: https://solidity.readthedocs.io/en/v0.5.11/types.html#address Call, delegatecall and staticcall are used to interface with contracts that do not follow the ABI, or to get more direct control over the encoding. We are focused on providing the highest level of security in our products. So, we feel that interacting with contracts that do not have an ABI public description is not in line with what we want to achieve. Therefore, we do not support or have any plans to support these features or to create an analogue. Workarounds have not been specified yet.","title":"Call Functions"},{"location":"Compilers/Solidity-Compiler/Reference Guide/#return-and-callback","text":"Return works as expected only for internal contract calls according to TON architecture. It is not possible to use return to receive a message back from external contract. By design, in TON you need to use callback as a separate function in the second contract that sends a message back. If contract A calls contract B and requires a return of value, a callback should be specified in contract A to receive the answer. Example: contract A { function a() { B.b(); //make request } function c() { //this is callback } } contract B { function b() { A.c() //send answer } }","title":"Return and Callback"},{"location":"Compilers/Solidity-Compiler/Solidity Support Status/","text":"Solidity Support Status Fully Supported/Pending Release Fully supported features and feature groups. FEATURE USAGE NOTES Pragmas Pragma... Version pragma solidity =0.5.0 0.6.0 Experimental pragma experimental ... ABIEncoderV2 pragma experimental ABIEncoderV2 Import import \"filename\" ``import * as symbolName from \"filename\" ``import {symbol1 as alias, symbol2} from \"filename\" Additional test are in the pipeline Comments //, / / Boolean: bool, true, false operators !, , II, ==, != lazy evaluation f(x) == true \u21d2 (f(x) || g(y)) == true integers intN/uintN , N=8..256 comparisons = , , == , != , = , Bit Operators: , | , ^ , ~ shift , base arithmetic + , - , unary - , * division / modulo % exponent ** Ternary operator b = true ? 2 : 3; Enums enum ActionChoices { GoLeft, GoRight, GoStraight, SitStill } Return variables Structs struct Mapping types mapping Integer types Conversions between Elementary Types Implicit conversions Explicit conversions Order of Evaluation of Expressions not specified, lazy bools Assignments for arrays and structs Assignments in expressions Member constants Default member values View functions function f(uint a) public view returns (uint) Pure functions function f(uint a) public pure returns (uint) Now Arrays in events Return arrays in public methods Nested structure encoding Contract types My contractC Using for Using B for A Library functions are added to a type Abstract contracts contract A { function u() public; } Metadata ABI, version, etc. Super super.method() Return See more about usage particularities of return and callback in TON Multiple Inheritance and linearization Arguments for base constructors Returning multiple values return (n1, n2, n3); Partially Supported/Planned Features and feature groups that are now partially supported and/or planned to be supported. Note that implementation priority depends on the demand for the feature, its relevance to the TVM and on the overall effort estimate. NAME USAGE NOTES AND LINKS Data Location: memory Fully supported storage Ethereum-specific, unsupported now. Always use memory location calldata Same as above Block and Transaction Properties: Global symbols initially provided by EVM developers for debugging The feature set is partially supported. You can use: get_block_lt tvm_trans_lt get_balance get_address hash of the given block blockhash (uint blockNumber) returns (bytes32) Not yet fully supported; only available for 256 most recent blocks excluding the current one current block miner address block.coinbase (address payable) Not yet supported current block difficulty block.difficulty (uint) Not yet supported current block gas limit block.gaslimit (uint) Not yet supported current block number block.timestamp (uint) , now(uint) Supported current block timestamp; seconds since Unix epoch block.number (uint) Supported remaining gas gasleft() returns (uint256) Not yet supported complete call data msg.data (bytes calldata) Not yet supported message sender (current call) msg.sender (address payable) Supported first 4 bytes of the call data (function identifier) msg.sig (bytes4) Supported number of WEI sent with the message msg.value (uint) Supported transaction gas price tx.gasprice (uint) Not yet supported transaction sender (full call chain) tx.origin (address payable) Not yet supported Contract Related: Partial support of the feature group this address(this) Supported inheritance Supported sefldestruct Deletes the active contract and sends funds the provided Address Not yet supported, planned. Value types Partially supported. Value type variable handling optimization behavior documenting pending. The suggested workaround is to create a copy explicitly, if needed Reference types Partially supported feature. Reference types are opposite of fixed types. They can be deployed after TON TVM memory features are supported completely. No workarounds or ETA at the moment. Rational literals .1, 2e-10 Planned Hexadecimal literals hex\"001122FF\" Currently tested Interfaces interface Token { struct ... function ... } Only pure interfaces are supported Function Modifiers Unsupported now, planned to support. See also Hints and workarounds Function calls The feature group is partially supported internal function calls Supported external function calls Supported named calls and anonymous function parameters function f() public { set({value: 2, key: 3}); } function set(uint key, uint value) public { data[key] = value; } Not supported, tests are being carried out. A fairly complex and rarely used feature. Implementation depends on feedback omitted function parameter names function func(uint k, uint) public pure returns(uint) { return k; } Supported, tests in the pipeline creating contracts via new explicit constructor call Not supported, inheritance-dependent. Fallback function () external { ... } Currently in development. Address: address addr The group is partially supported. Address literals and address payable types are not supported yet. address payable address payable addrPayable More research of the type needed Address Literals \"0xdCad3a6d3569DF655070DEd06cb7A1b2Ccd1D3AF\" It is suggested to convert to uint160 address comparisons = , , == , != , = , It is suggested to convert to uint160 balance address.balance Supported transfer addressPayable.transfer(N) Supported send addressPayable.send(N) Supported call, delegatecall, staticcall * call(bytes) Not supported for security reasons, see additional information here . Arrays: This feature groups is partially supported fixed size [k] Supported dynamic size [] Supported bytes and strings as arrays Planned memory arrays bytes[] Partial support, all arrays are in memory literals [1, 2, 3] Supported, tests under way length Supported push Supported pop Supported Events: event Deposit(address _from, uint _value); Features from this group are partially supported emit emit Deposit(msg.sender, msg.value); Partially supported indexed Stores event parameter as topic, not supported now anonymous Does not store event signature as topic, not supported now Math and Crypto: The feature group is partially supported (x + y) % k addmod(uint x, uint y, uint k) returns (uint) Not supported; not relevant for the TVM (x * y) % k mulmod(uint x, uint y, uint k) returns (uint) Not supported now; not relevant for the TVM Keccak-256 hash keccak256(bytes memory) returns (bytes32) This option will not be supported. An analog is planned for release within the next few months based on tvm_hash() . No workarounds at this moment. SHA-256 hash sha256(bytes memory) returns (bytes32) Supported partially RIPEMD-160 hash ripemd160(bytes memory) returns (bytes20) This option will not be supported. An analog is planned for release within the next few months based on tvm_hash(). No workarounds at this moment. erecovery ecrecover(bytes32 hash, uint8 v, bytes32 r, bytes32 s) returns (address) EVM-specific operation; replaced by signing and verification mechanic described in the ABI Spec Fixed-size byte arrays bytes1..32 bts Partial support soon. bytes32 pending release, testing under way. Control structures: The feature groups is partially supported, see details below. if, else if () { } else { } Supported ?: bool isTrue = (a == 1) ? true : false Supported for, while for (uint p = 0; p N; p++) { } Supported do while Planned break, continue Supported return Pending release Parameters: The feature groups is partially supported int/uint Fully supported arrays Partial support, only arrays of ints/addresses supported structs Fully supported address Fully supported contract Supported as uint256 Error handling: In this group only require is relevant to the TVM. TVM handles errors itself assert assert(bool condition) Not relevant for TVM require require(bool condition , string memory message ) Supported revert revert( string memory reason ) Not relevant for TVM Visibility: The feature group is partially supported external Partial, can be called internally now public Supported internal Supported private Not supported. Can be called from children, depend on inheritance ABI: Features in this group are mostly not supported, ABI operation mapping required encoding/decoding abi.encode(...) returns (bytes memory)``abi.decode(bytes memory encodedData (...)) returns (...) Pending release packed encoding abi.encodePacked(...) returns (bytes memory) Not supported encoding with selector abi.encodeWithSignature(string memory signature, ...) returns (bytes memory) Not supported encoding with hash code Not supported Operations involving LValues += , -= , *= , /= , %= , |= , = , ^= , a++ , a\u2014 , ++a , \u2014a Only operations with integers are supported. More research and development needed for other cases. Delete Assigns initial value. Handled in ExpressionCompiler? Supported Scoping and declarations Partial support Unsupported/Irrelevant Supporting features and feature groups from this category has low priority or is out of the project scope, mainly because they are EVM-specific. In some cases we suggest a workaround. Depending on the project progress, we may decide to provide support for some of these at later stages. NAME NOTES/USAGE MORE Inline, Solidity, Standalone Assembly Ethereum-specific feature Hints and suggestions SMTChecker pragma experimental SMTChecker Natspec ///, @title, @author, @dev, @param, @return, @notice Currently not used in the TVM. Later support may be considered. Refer to the original documentation for more details on the feature. Call Functions Not supported for security reasons. See also the Reference guide. Overloading function f(uint _in) ``function f(uint _in, bool _b) Low priority, support may be considered in the future Overload resolution and argument matching function f(uint8 _in) ``function f(uint256 _in) Low priority, support may be considered in the future Reference types Reference types are opposite of fixed types. They can be deployed after TON TVM memory features are supported completely. No workarounds or ETA at the moment. Function types Function to type conversion not supported. Low priority feature Tuples Generally not supported; limited support in in Return statements. More testing needed. Dynamically-sized byte arrays: The feature groups is not currently supported. byte Can be supported after fixed size is deployed and stable. string string A string encoded in UTF-8 are not supported. Strings can not be implemented before data storage on TON TVM is completely supported. At this point, we do not support data storage completely. The suggested workaround is to use short fixed-size byte arrays once released. String literals and Types \"foo\", 'bar' To be deployed in the framework of literals support; encode as byte arrays Special chars \\ newline , \\\\ , \\' , \\\" , \\b , \\f , \\n, \\r , \\t , \\v , \\xNN , \\uNNNN To be deployed in the framework of literals support Fixed point numbers, operations fixed/ufixed, fixed/ufixedMxN, =, , ==, !=, =, , +, -, unary -, *, /, % Currently the feature is not supported. It is planned to implement mapping connecting text representation of an instruction to its numerical counterpart. On the total, there are 476 instructions. The map will be used for text assembly generation. Ether units wei, finney, szabo, ether Not supported, EVM-specific Time units seconds, minutes, hours, days, weeks Not supported now, see a workaround Type information: No plans to support this whole group yet. Usage potential unclear. type type(c) name creationCode runtimeCode Explicit conversions Not supported or very limited support for address types. Cannot be implemented before fallback. Implicit conversions Not supported, requires inheritance. Will not be implemented before explicit conversions. Constant state variables constant Not supported now, research needed Getter functions getArray Not supported now, research needed Function modifiers Not supported Exceptions Not supported now, research needed Inheriting Different Kinds of Members of the Same Name Inheritance-dependent (see above). Call protection for libraries Not supported now Copy of operations No plans to support Libraries library Set { ... } Creating contracts via new","title":"Solidity Support Status"},{"location":"Compilers/Solidity-Compiler/Solidity Support Status/#solidity-support-status","text":"","title":"Solidity Support Status"},{"location":"Compilers/Solidity-Compiler/Solidity Support Status/#fully-supportedpending-release","text":"Fully supported features and feature groups. FEATURE USAGE NOTES Pragmas Pragma... Version pragma solidity =0.5.0 0.6.0 Experimental pragma experimental ... ABIEncoderV2 pragma experimental ABIEncoderV2 Import import \"filename\" ``import * as symbolName from \"filename\" ``import {symbol1 as alias, symbol2} from \"filename\" Additional test are in the pipeline Comments //, / / Boolean: bool, true, false operators !, , II, ==, != lazy evaluation f(x) == true \u21d2 (f(x) || g(y)) == true integers intN/uintN , N=8..256 comparisons = , , == , != , = , Bit Operators: , | , ^ , ~ shift , base arithmetic + , - , unary - , * division / modulo % exponent ** Ternary operator b = true ? 2 : 3; Enums enum ActionChoices { GoLeft, GoRight, GoStraight, SitStill } Return variables Structs struct Mapping types mapping Integer types Conversions between Elementary Types Implicit conversions Explicit conversions Order of Evaluation of Expressions not specified, lazy bools Assignments for arrays and structs Assignments in expressions Member constants Default member values View functions function f(uint a) public view returns (uint) Pure functions function f(uint a) public pure returns (uint) Now Arrays in events Return arrays in public methods Nested structure encoding Contract types My contractC Using for Using B for A Library functions are added to a type Abstract contracts contract A { function u() public; } Metadata ABI, version, etc. Super super.method() Return See more about usage particularities of return and callback in TON Multiple Inheritance and linearization Arguments for base constructors Returning multiple values return (n1, n2, n3);","title":"Fully Supported/Pending Release"},{"location":"Compilers/Solidity-Compiler/Solidity Support Status/#partially-supportedplanned","text":"Features and feature groups that are now partially supported and/or planned to be supported. Note that implementation priority depends on the demand for the feature, its relevance to the TVM and on the overall effort estimate. NAME USAGE NOTES AND LINKS Data Location: memory Fully supported storage Ethereum-specific, unsupported now. Always use memory location calldata Same as above Block and Transaction Properties: Global symbols initially provided by EVM developers for debugging The feature set is partially supported. You can use: get_block_lt tvm_trans_lt get_balance get_address hash of the given block blockhash (uint blockNumber) returns (bytes32) Not yet fully supported; only available for 256 most recent blocks excluding the current one current block miner address block.coinbase (address payable) Not yet supported current block difficulty block.difficulty (uint) Not yet supported current block gas limit block.gaslimit (uint) Not yet supported current block number block.timestamp (uint) , now(uint) Supported current block timestamp; seconds since Unix epoch block.number (uint) Supported remaining gas gasleft() returns (uint256) Not yet supported complete call data msg.data (bytes calldata) Not yet supported message sender (current call) msg.sender (address payable) Supported first 4 bytes of the call data (function identifier) msg.sig (bytes4) Supported number of WEI sent with the message msg.value (uint) Supported transaction gas price tx.gasprice (uint) Not yet supported transaction sender (full call chain) tx.origin (address payable) Not yet supported Contract Related: Partial support of the feature group this address(this) Supported inheritance Supported sefldestruct Deletes the active contract and sends funds the provided Address Not yet supported, planned. Value types Partially supported. Value type variable handling optimization behavior documenting pending. The suggested workaround is to create a copy explicitly, if needed Reference types Partially supported feature. Reference types are opposite of fixed types. They can be deployed after TON TVM memory features are supported completely. No workarounds or ETA at the moment. Rational literals .1, 2e-10 Planned Hexadecimal literals hex\"001122FF\" Currently tested Interfaces interface Token { struct ... function ... } Only pure interfaces are supported Function Modifiers Unsupported now, planned to support. See also Hints and workarounds Function calls The feature group is partially supported internal function calls Supported external function calls Supported named calls and anonymous function parameters function f() public { set({value: 2, key: 3}); } function set(uint key, uint value) public { data[key] = value; } Not supported, tests are being carried out. A fairly complex and rarely used feature. Implementation depends on feedback omitted function parameter names function func(uint k, uint) public pure returns(uint) { return k; } Supported, tests in the pipeline creating contracts via new explicit constructor call Not supported, inheritance-dependent. Fallback function () external { ... } Currently in development. Address: address addr The group is partially supported. Address literals and address payable types are not supported yet. address payable address payable addrPayable More research of the type needed Address Literals \"0xdCad3a6d3569DF655070DEd06cb7A1b2Ccd1D3AF\" It is suggested to convert to uint160 address comparisons = , , == , != , = , It is suggested to convert to uint160 balance address.balance Supported transfer addressPayable.transfer(N) Supported send addressPayable.send(N) Supported call, delegatecall, staticcall * call(bytes) Not supported for security reasons, see additional information here . Arrays: This feature groups is partially supported fixed size [k] Supported dynamic size [] Supported bytes and strings as arrays Planned memory arrays bytes[] Partial support, all arrays are in memory literals [1, 2, 3] Supported, tests under way length Supported push Supported pop Supported Events: event Deposit(address _from, uint _value); Features from this group are partially supported emit emit Deposit(msg.sender, msg.value); Partially supported indexed Stores event parameter as topic, not supported now anonymous Does not store event signature as topic, not supported now Math and Crypto: The feature group is partially supported (x + y) % k addmod(uint x, uint y, uint k) returns (uint) Not supported; not relevant for the TVM (x * y) % k mulmod(uint x, uint y, uint k) returns (uint) Not supported now; not relevant for the TVM Keccak-256 hash keccak256(bytes memory) returns (bytes32) This option will not be supported. An analog is planned for release within the next few months based on tvm_hash() . No workarounds at this moment. SHA-256 hash sha256(bytes memory) returns (bytes32) Supported partially RIPEMD-160 hash ripemd160(bytes memory) returns (bytes20) This option will not be supported. An analog is planned for release within the next few months based on tvm_hash(). No workarounds at this moment. erecovery ecrecover(bytes32 hash, uint8 v, bytes32 r, bytes32 s) returns (address) EVM-specific operation; replaced by signing and verification mechanic described in the ABI Spec Fixed-size byte arrays bytes1..32 bts Partial support soon. bytes32 pending release, testing under way. Control structures: The feature groups is partially supported, see details below. if, else if () { } else { } Supported ?: bool isTrue = (a == 1) ? true : false Supported for, while for (uint p = 0; p N; p++) { } Supported do while Planned break, continue Supported return Pending release Parameters: The feature groups is partially supported int/uint Fully supported arrays Partial support, only arrays of ints/addresses supported structs Fully supported address Fully supported contract Supported as uint256 Error handling: In this group only require is relevant to the TVM. TVM handles errors itself assert assert(bool condition) Not relevant for TVM require require(bool condition , string memory message ) Supported revert revert( string memory reason ) Not relevant for TVM Visibility: The feature group is partially supported external Partial, can be called internally now public Supported internal Supported private Not supported. Can be called from children, depend on inheritance ABI: Features in this group are mostly not supported, ABI operation mapping required encoding/decoding abi.encode(...) returns (bytes memory)``abi.decode(bytes memory encodedData (...)) returns (...) Pending release packed encoding abi.encodePacked(...) returns (bytes memory) Not supported encoding with selector abi.encodeWithSignature(string memory signature, ...) returns (bytes memory) Not supported encoding with hash code Not supported Operations involving LValues += , -= , *= , /= , %= , |= , = , ^= , a++ , a\u2014 , ++a , \u2014a Only operations with integers are supported. More research and development needed for other cases. Delete Assigns initial value. Handled in ExpressionCompiler? Supported Scoping and declarations Partial support","title":"Partially  Supported/Planned"},{"location":"Compilers/Solidity-Compiler/Solidity Support Status/#unsupportedirrelevant","text":"Supporting features and feature groups from this category has low priority or is out of the project scope, mainly because they are EVM-specific. In some cases we suggest a workaround. Depending on the project progress, we may decide to provide support for some of these at later stages. NAME NOTES/USAGE MORE Inline, Solidity, Standalone Assembly Ethereum-specific feature Hints and suggestions SMTChecker pragma experimental SMTChecker Natspec ///, @title, @author, @dev, @param, @return, @notice Currently not used in the TVM. Later support may be considered. Refer to the original documentation for more details on the feature. Call Functions Not supported for security reasons. See also the Reference guide. Overloading function f(uint _in) ``function f(uint _in, bool _b) Low priority, support may be considered in the future Overload resolution and argument matching function f(uint8 _in) ``function f(uint256 _in) Low priority, support may be considered in the future Reference types Reference types are opposite of fixed types. They can be deployed after TON TVM memory features are supported completely. No workarounds or ETA at the moment. Function types Function to type conversion not supported. Low priority feature Tuples Generally not supported; limited support in in Return statements. More testing needed. Dynamically-sized byte arrays: The feature groups is not currently supported. byte Can be supported after fixed size is deployed and stable. string string A string encoded in UTF-8 are not supported. Strings can not be implemented before data storage on TON TVM is completely supported. At this point, we do not support data storage completely. The suggested workaround is to use short fixed-size byte arrays once released. String literals and Types \"foo\", 'bar' To be deployed in the framework of literals support; encode as byte arrays Special chars \\ newline , \\\\ , \\' , \\\" , \\b , \\f , \\n, \\r , \\t , \\v , \\xNN , \\uNNNN To be deployed in the framework of literals support Fixed point numbers, operations fixed/ufixed, fixed/ufixedMxN, =, , ==, !=, =, , +, -, unary -, *, /, % Currently the feature is not supported. It is planned to implement mapping connecting text representation of an instruction to its numerical counterpart. On the total, there are 476 instructions. The map will be used for text assembly generation. Ether units wei, finney, szabo, ether Not supported, EVM-specific Time units seconds, minutes, hours, days, weeks Not supported now, see a workaround Type information: No plans to support this whole group yet. Usage potential unclear. type type(c) name creationCode runtimeCode Explicit conversions Not supported or very limited support for address types. Cannot be implemented before fallback. Implicit conversions Not supported, requires inheritance. Will not be implemented before explicit conversions. Constant state variables constant Not supported now, research needed Getter functions getArray Not supported now, research needed Function modifiers Not supported Exceptions Not supported now, research needed Inheriting Different Kinds of Members of the Same Name Inheritance-dependent (see above). Call protection for libraries Not supported now Copy of operations No plans to support Libraries library Set { ... } Creating contracts via new","title":"Unsupported/Irrelevant"},{"location":"Compilers/Solidity-Compiler/Usage/","text":"","title":"Usage"},{"location":"FAQ/SDK and Integration/","text":"SDK and Integration Q : Would you be able to point me to where BOC messages are created or signed inside the JavaScript or Rust SDK? In the JS SDK, I just see that all calls end up hitting this.requestLibrary with some library specified, and that looks like it ends up calling a TONClientLibrary module, but it's not clear where these libraries actually exist (they seem to be on the node itself). A : BOC messages are created and signed inside the Rust SDK library. The library is located at the client side. For the Node.js SDK client, the native Node.js addon is used. For React Native, there is a native library for target platform where the client application is running. For the Web client, there is the Web Assembly module downloaded and executed at the client device. The Rust SDK library contains core SDK functions used on all platforms. The SDK will be available as Open Source and more platform and language rappers are to be developed. We are open to customer and community suggestions and contributions to the repository, once it is open. Q : Don\u2019t see any code in the SDK's that is actually generating keys locally or constructing .boc messages. It seems they are just calling your node to do that for them, so it seems like more of a client to the node. Please correct me if that\u2019s not right. A : See the previous answer. Keys are generated in the Rust core library running on a client device. The message BOC construction code is also located there. The SDK's interaction with the node is limited to sending external blockchain messages calling contracts and querying results from the GraphQL server. All crypto operations are performed locally. Q : Is there an API call to the full node that returns a given account\u2019s balance along with the block height at which that balance was calculated, in a single API call? Note: This IS NOT the same thing as historical balance lookup. (Example: GET /balance/account1 - {balance:10, height: 123902}) The current account state provided by the lite-client does not include this information. Can we be given this information if it is not available today? A : It is possible to get this information by the series of graphQL queries: query an account by its ID (address) and remember last_trans_lt (last transaction logical time) query { accounts(filter: {id: {eq: 0000000000000000000000000000000000000000000000000000000000000000 }}) { id, storage {last_trans_lt} } } result: { data : { accounts : [ { id : 0000000000000000000000000000000000000000000000000000000000000000 , storage : { last_trans_lt : 4 } } ] } } query the transaction with your account ID and the logical time; remember the corresponding block_id query { transactions(filter: { account_addr: {eq: 0000000000000000000000000000000000000000000000000000000000000000 } lt: {eq: 4} }) { id, block_id } } result: { data : { transactions : [ { id : 3badb9e5707db8e61e0e335e02eacb6df2a118512791b620c73a71d826e840c3 , block_id : 4a8537f7499e122fc539b6250cd70168e80a129dcd684de6d0928d86105cf430 } ] } } query a block by an ID with the required data: query { blocks(filter: { id: {eq: 4a8537f7499e122fc539b6250cd70168e80a129dcd684de6d0928d86105cf430 } }) { id, info { seq_no } } } result: { data : { blocks : [ { id : 4a8537f7499e122fc539b6250cd70168e80a129dcd684de6d0928d86105cf430 , info : { seq_no : 1 } } ] } } Q : Does your node currently (or will you) provide an API to submit pre-signed messages (e.g. a pre-signed bag-of-cells message)? Can we have this endpoint (not a CLI interface) if it does not exist today? A : To send pre-generated messages, use the processMessage function of the SDK JS client. Also, there will be a function to construct unsigned messages. You will be able to sign generated message yourself and then to send it using the SDK. For example you can generate message to call the contract by SDK function. That function returns a serialized message and its hash to be signed. You sign it using your own implementation of the signature algorithm (or using some hardware security module). Then you call another SDK function that adds your signature to the message generated at first step. Finally, the resulting signed message can be sent by processMessage function. Q : How does one derive the message (or transaction) hash from a signed bag-of-cells message to a contract? Can you provide details on how we can compute this on our own? (Ideally we can compute this so we can look it up after submitting to the network.) A : The SDK returns hash of the generated message as a message ID. We will provide a function which will return hash for a specific message in the next few weeks. To calculate hash manually, deserialize the bag of cells into a tree of cells and calculate the representation hash of the root cell as described in paragraph 3.1.5 of the original TVM specification. It's quite an effort, though. Q : It seems that messages are not replay protected on their own. Is this the case? Is there any default replay protection provided by the network or must every contract implement their own sequence number or similar method to replay protection? A : There is no default replay attack protection in TON. A contract developer is supposed to implement it manually. There are only \"best practices\" by TON developers here . TON Labs compilers will have a default inline implementation of replay protection. Q : Can you provide more explicit details or provide an example of how an account\u2019s address is derived from the compiled contract and initial state and specifically how that hash is computed and over what components? Source code is also helpful here if you can provide it. A : A blockchain account contains the State Init field. It stores the contract code and persisted data. State init is also tree of cells. At contract deployment this field is transferred alongside the deploying message (so called constructor message) and is set as the contract initial state. The representation hash (see paragraph 3.1.5 of the TVM specification) of the contract initial state is the account address. The node checks that the state init hash of the deployment message is equal to the destination address. The SDK will have a function for computing account address by its initial state. The SDK source code will be available soon. Q : Is (or will be) the solidity-to-tvm and tvm-linker source code available to users? If not, can agreements be signed to make it available to partners? A : Yes, both Sol2Tvm compiler and TVM-Linker will be available as open source. Q : With a Solidity contract, how does one properly specify an address parameter? In solidity, addresses are uint256 but this can only capture the address portion and not the workchain_id. How would one specify the full address parameter correctly here? (e.g. \u201c0:D702CC0414858D83A5538A3C1C86231872F006453AF7C825A59F9DD12D636AF\u201d is invalid in solidity for an address param) A : Now we only use the address field of MsgAddressInt structure as Solidity address type. We assume that worckchain_id is 0. But in future the address type will represent the whole MsgAddressInt structure. Now workchain_id can be defined separately as int8. Q : When deploying a contract init message that was created using a solidity contract, the Sol2TVM compiler and tvm_linker, I\u2019m seeing the init succeed initially but then also get replayed dozens of times after. How does one replay protect a contract init message for a solidity-compiled contract? (example message that was replayed after the initialization was already successful previously: ) A : The sample message at has no init (it is init:nothing ), and a transaction with this message is aborted. But in general, the StateInit data attached to a message is used by the node only once: when a contract is in the Uninit state. Replays of such message can succeed, but the contract code will not be changed. An Init msg created with sol2tvm compiler and tvm_linker contains an encoded constructor call. Now you can call constructor multiple times, but in future releases it will be changed.","title":"SDK and Integration"},{"location":"FAQ/SDK and Integration/#sdk-and-integration","text":"Q : Would you be able to point me to where BOC messages are created or signed inside the JavaScript or Rust SDK? In the JS SDK, I just see that all calls end up hitting this.requestLibrary with some library specified, and that looks like it ends up calling a TONClientLibrary module, but it's not clear where these libraries actually exist (they seem to be on the node itself). A : BOC messages are created and signed inside the Rust SDK library. The library is located at the client side. For the Node.js SDK client, the native Node.js addon is used. For React Native, there is a native library for target platform where the client application is running. For the Web client, there is the Web Assembly module downloaded and executed at the client device. The Rust SDK library contains core SDK functions used on all platforms. The SDK will be available as Open Source and more platform and language rappers are to be developed. We are open to customer and community suggestions and contributions to the repository, once it is open. Q : Don\u2019t see any code in the SDK's that is actually generating keys locally or constructing .boc messages. It seems they are just calling your node to do that for them, so it seems like more of a client to the node. Please correct me if that\u2019s not right. A : See the previous answer. Keys are generated in the Rust core library running on a client device. The message BOC construction code is also located there. The SDK's interaction with the node is limited to sending external blockchain messages calling contracts and querying results from the GraphQL server. All crypto operations are performed locally. Q : Is there an API call to the full node that returns a given account\u2019s balance along with the block height at which that balance was calculated, in a single API call? Note: This IS NOT the same thing as historical balance lookup. (Example: GET /balance/account1 - {balance:10, height: 123902}) The current account state provided by the lite-client does not include this information. Can we be given this information if it is not available today? A : It is possible to get this information by the series of graphQL queries: query an account by its ID (address) and remember last_trans_lt (last transaction logical time) query { accounts(filter: {id: {eq: 0000000000000000000000000000000000000000000000000000000000000000 }}) { id, storage {last_trans_lt} } } result: { data : { accounts : [ { id : 0000000000000000000000000000000000000000000000000000000000000000 , storage : { last_trans_lt : 4 } } ] } } query the transaction with your account ID and the logical time; remember the corresponding block_id query { transactions(filter: { account_addr: {eq: 0000000000000000000000000000000000000000000000000000000000000000 } lt: {eq: 4} }) { id, block_id } } result: { data : { transactions : [ { id : 3badb9e5707db8e61e0e335e02eacb6df2a118512791b620c73a71d826e840c3 , block_id : 4a8537f7499e122fc539b6250cd70168e80a129dcd684de6d0928d86105cf430 } ] } } query a block by an ID with the required data: query { blocks(filter: { id: {eq: 4a8537f7499e122fc539b6250cd70168e80a129dcd684de6d0928d86105cf430 } }) { id, info { seq_no } } } result: { data : { blocks : [ { id : 4a8537f7499e122fc539b6250cd70168e80a129dcd684de6d0928d86105cf430 , info : { seq_no : 1 } } ] } } Q : Does your node currently (or will you) provide an API to submit pre-signed messages (e.g. a pre-signed bag-of-cells message)? Can we have this endpoint (not a CLI interface) if it does not exist today? A : To send pre-generated messages, use the processMessage function of the SDK JS client. Also, there will be a function to construct unsigned messages. You will be able to sign generated message yourself and then to send it using the SDK. For example you can generate message to call the contract by SDK function. That function returns a serialized message and its hash to be signed. You sign it using your own implementation of the signature algorithm (or using some hardware security module). Then you call another SDK function that adds your signature to the message generated at first step. Finally, the resulting signed message can be sent by processMessage function. Q : How does one derive the message (or transaction) hash from a signed bag-of-cells message to a contract? Can you provide details on how we can compute this on our own? (Ideally we can compute this so we can look it up after submitting to the network.) A : The SDK returns hash of the generated message as a message ID. We will provide a function which will return hash for a specific message in the next few weeks. To calculate hash manually, deserialize the bag of cells into a tree of cells and calculate the representation hash of the root cell as described in paragraph 3.1.5 of the original TVM specification. It's quite an effort, though. Q : It seems that messages are not replay protected on their own. Is this the case? Is there any default replay protection provided by the network or must every contract implement their own sequence number or similar method to replay protection? A : There is no default replay attack protection in TON. A contract developer is supposed to implement it manually. There are only \"best practices\" by TON developers here . TON Labs compilers will have a default inline implementation of replay protection. Q : Can you provide more explicit details or provide an example of how an account\u2019s address is derived from the compiled contract and initial state and specifically how that hash is computed and over what components? Source code is also helpful here if you can provide it. A : A blockchain account contains the State Init field. It stores the contract code and persisted data. State init is also tree of cells. At contract deployment this field is transferred alongside the deploying message (so called constructor message) and is set as the contract initial state. The representation hash (see paragraph 3.1.5 of the TVM specification) of the contract initial state is the account address. The node checks that the state init hash of the deployment message is equal to the destination address. The SDK will have a function for computing account address by its initial state. The SDK source code will be available soon. Q : Is (or will be) the solidity-to-tvm and tvm-linker source code available to users? If not, can agreements be signed to make it available to partners? A : Yes, both Sol2Tvm compiler and TVM-Linker will be available as open source. Q : With a Solidity contract, how does one properly specify an address parameter? In solidity, addresses are uint256 but this can only capture the address portion and not the workchain_id. How would one specify the full address parameter correctly here? (e.g. \u201c0:D702CC0414858D83A5538A3C1C86231872F006453AF7C825A59F9DD12D636AF\u201d is invalid in solidity for an address param) A : Now we only use the address field of MsgAddressInt structure as Solidity address type. We assume that worckchain_id is 0. But in future the address type will represent the whole MsgAddressInt structure. Now workchain_id can be defined separately as int8. Q : When deploying a contract init message that was created using a solidity contract, the Sol2TVM compiler and tvm_linker, I\u2019m seeing the init succeed initially but then also get replayed dozens of times after. How does one replay protect a contract init message for a solidity-compiled contract? (example message that was replayed after the initialization was already successful previously: ) A : The sample message at has no init (it is init:nothing ), and a transaction with this message is aborted. But in general, the StateInit data attached to a message is used by the node only once: when a contract is in the Uninit state. Replays of such message can succeed, but the contract code will not be changed. An Init msg created with sol2tvm compiler and tvm_linker contains an encoded constructor call. Now you can call constructor multiple times, but in future releases it will be changed.","title":"SDK and Integration"},{"location":"FAQ/Smart Contracts/","text":"Smart Contracts *Q : Based on your documentation and the white paper, there is a gas limit on transactions/transfers but this is not set by the sender but is a function of the transfer amount or contract balance. Do senders/contracts have any ability to set an upper limit on the gas consumed by a transaction A : contracts can set upper gas limit in msg.value (in nanograms), but receiver contract can increase this limit buying more gas (accept cmd). We cannot set gas limit for external messages; it is automatically calculated as minimal contract balance or global gas limit per transaction. Q : Do you have any insight into the various send modes for SENDRAWMSG ? I'm trying to understand failure scenarios and if that call fails when mode=0 , then the internal contract state fails to update and we risk the failed message being replayed until the account is drained. mode=2 is supposed to \"ignore errors\" such that the contract state will get updated even if the msg fails to send. But by changing the mode to 2 I'm now seeing some additional fees taken out of my transfer amount (specifically my transfer amt is reduced by 0.001 Grams which is the total_fwd_fee ) Do you have any insight here? A : Forward fees reduce transfer amount even if mode=0; these are always present in internal messages.","title":"Smart Contracts"},{"location":"FAQ/Smart Contracts/#smart-contracts","text":"*Q : Based on your documentation and the white paper, there is a gas limit on transactions/transfers but this is not set by the sender but is a function of the transfer amount or contract balance. Do senders/contracts have any ability to set an upper limit on the gas consumed by a transaction A : contracts can set upper gas limit in msg.value (in nanograms), but receiver contract can increase this limit buying more gas (accept cmd). We cannot set gas limit for external messages; it is automatically calculated as minimal contract balance or global gas limit per transaction. Q : Do you have any insight into the various send modes for SENDRAWMSG ? I'm trying to understand failure scenarios and if that call fails when mode=0 , then the internal contract state fails to update and we risk the failed message being replayed until the account is drained. mode=2 is supposed to \"ignore errors\" such that the contract state will get updated even if the msg fails to send. But by changing the mode to 2 I'm now seeing some additional fees taken out of my transfer amount (specifically my transfer amt is reduced by 0.001 Grams which is the total_fwd_fee ) Do you have any insight here? A : Forward fees reduce transfer amount even if mode=0; these are always present in internal messages.","title":"Smart Contracts"},{"location":"FAQ/Solidity Compiler/","text":"Solidity Compiler Q: There are samples of transaction generation via the LLVM Compiler and via the SOL2TVM Compiler. Yet, there is no signing operation in the sample Solidity code. A : Check the contract04.sol example, it demonstrates how to transfer grams with the **address.transfer()** function; Signing is not yet supported, plan to add it in the next release Q: Does Solidity compiler support ecrecover? Now it throws \u201cstd::exception::what: unknown variable: ecrecover\u201d. If not, will there be support soon? There is nothing in the guide about it. A : No, this is an Ethereum-specific operation. But we plan to provide an equivalent, for now use the ABI. Q: Is 'address(this)' operational? A : Only address(this).balance is available at this moment. The address(this) function will be available soon. Q: Can structures be transferred as function parameters? A : Not for public functions. The feature is to be released later. For internal functions, yes, this is possible. Q: The .push method is unavailable. How do I add a new element? A : You can use array[array.length] = new_element;. The .push method will be added later. Q: How an address is formed for a Solidity contract? A : The address of a Solidity smart-contract for TON is deterministic and is computed prior to its deployment. Full address of the contract consists of a 32-bit ID of a workchain the contract is being deployed to and of the 256-bit internal address (or account identifier) inside the chosen workchain. The internal address is a representative hash of the contract initial state. The contract Initial state consists of the contract code serialized according to the TON blockchain specification, section 5.3.10, and its data. Hash computation principles: the hash function applied to the relevant hash code computation is called \"representation hash\". Its detailed description is available in the TON blockchain specification, section 1.1.8. Essentially, the representation hash is sha256 function recursively applied to the storage cell of its argument.","title":"Solidity Compiler"},{"location":"FAQ/Solidity Compiler/#solidity-compiler","text":"Q: There are samples of transaction generation via the LLVM Compiler and via the SOL2TVM Compiler. Yet, there is no signing operation in the sample Solidity code. A : Check the contract04.sol example, it demonstrates how to transfer grams with the **address.transfer()** function; Signing is not yet supported, plan to add it in the next release Q: Does Solidity compiler support ecrecover? Now it throws \u201cstd::exception::what: unknown variable: ecrecover\u201d. If not, will there be support soon? There is nothing in the guide about it. A : No, this is an Ethereum-specific operation. But we plan to provide an equivalent, for now use the ABI. Q: Is 'address(this)' operational? A : Only address(this).balance is available at this moment. The address(this) function will be available soon. Q: Can structures be transferred as function parameters? A : Not for public functions. The feature is to be released later. For internal functions, yes, this is possible. Q: The .push method is unavailable. How do I add a new element? A : You can use array[array.length] = new_element;. The .push method will be added later. Q: How an address is formed for a Solidity contract? A : The address of a Solidity smart-contract for TON is deterministic and is computed prior to its deployment. Full address of the contract consists of a 32-bit ID of a workchain the contract is being deployed to and of the 256-bit internal address (or account identifier) inside the chosen workchain. The internal address is a representative hash of the contract initial state. The contract Initial state consists of the contract code serialized according to the TON blockchain specification, section 5.3.10, and its data. Hash computation principles: the hash function applied to the relevant hash code computation is called \"representation hash\". Its detailed description is available in the TON blockchain specification, section 1.1.8. Essentially, the representation hash is sha256 function recursively applied to the storage cell of its argument.","title":"Solidity Compiler"},{"location":"FAQ/TON and TVM/","text":"TON and TVM Q: How to deploy a contract to TON testnet if I use your Toolchain? A : Follow the procedure here . If you are a new user, check the related topics as well (Node SE Installation, Deployment). Q: Which messaging format is used in smart contracts? A : TON Labs uses the same message format as specified at ton . org . The message header format is covered in the blockchain whitepaper (ton.pdf clause 2.4.9 ), the message layout is covered by the blockchain specification (tblkch.pdf 3.1.7. ). Q: How is hash calculated? A : Hash calculation principles used in the TON test node are covered in the official TON VM documentation (tvm.pdf clause 3.1.4 -3.1.7 , tblkch.pdf 1.1.4 ). We use another method to calculate the hash of bag of cells, but we get the same result. Q: Is there any standard multisig contract we can use for TON? How can a multisig wallet be implemented in the TON network? A : The standard TON multisig contract specs and source code are unavailable at the moment. Existing open source multisig contracts can be used, but not all Solidity features are supported now by our compiler. Q: Do you have a good way of doing multiple receive addresses for the same wallet? A : Within TON every contract has only one address. You can use your Forwarder.sol contract, but it cannot be compiled with the current compiler version without some fixes. Q: Are wallets supposed to be deployed on the workchain, masterchain or some other chain? A : Any chain will do, but the basic workchain 0 is the recommended option. Masterchain has very high fees. Q: How do fees work? Does a smart contract pay its own fee or is it charged on the caller address? Does the TON use similar concepts of gas price and gas limit? A : Fees are charged on the contract that executes a transaction. There is a storage fee, a gas fee and a fee for sending messages from contracts . TON contracts consume gas (tvm.pdf clause 1.4 , appendix A.1 ) and have gas limits with specific features.","title":"TON and TVM"},{"location":"FAQ/TON and TVM/#ton-and-tvm","text":"Q: How to deploy a contract to TON testnet if I use your Toolchain? A : Follow the procedure here . If you are a new user, check the related topics as well (Node SE Installation, Deployment). Q: Which messaging format is used in smart contracts? A : TON Labs uses the same message format as specified at ton . org . The message header format is covered in the blockchain whitepaper (ton.pdf clause 2.4.9 ), the message layout is covered by the blockchain specification (tblkch.pdf 3.1.7. ). Q: How is hash calculated? A : Hash calculation principles used in the TON test node are covered in the official TON VM documentation (tvm.pdf clause 3.1.4 -3.1.7 , tblkch.pdf 1.1.4 ). We use another method to calculate the hash of bag of cells, but we get the same result. Q: Is there any standard multisig contract we can use for TON? How can a multisig wallet be implemented in the TON network? A : The standard TON multisig contract specs and source code are unavailable at the moment. Existing open source multisig contracts can be used, but not all Solidity features are supported now by our compiler. Q: Do you have a good way of doing multiple receive addresses for the same wallet? A : Within TON every contract has only one address. You can use your Forwarder.sol contract, but it cannot be compiled with the current compiler version without some fixes. Q: Are wallets supposed to be deployed on the workchain, masterchain or some other chain? A : Any chain will do, but the basic workchain 0 is the recommended option. Masterchain has very high fees. Q: How do fees work? Does a smart contract pay its own fee or is it charged on the caller address? Does the TON use similar concepts of gas price and gas limit? A : Fees are charged on the contract that executes a transaction. There is a storage fee, a gas fee and a fee for sending messages from contracts . TON contracts consume gas (tvm.pdf clause 1.4 , appendix A.1 ) and have gas limits with specific features.","title":"TON and TVM"},{"location":"SDK/Installation/","text":"Preparation Prerequisites Install the latest version of Docker . See installation tips in the screenshots below: For Linux users, make sure that you are able to run docker as non-root user (see https://docs.docker.com/install/linux/linux-postinstall/ ); Tip : check this page for more Docker installation options https://phoenixnap.com/kb/how-to-install-docker-on-ubuntu-18-04 . Install Node.js 10.x or newer. Make sure that Docker daemon is running on your computer. To check its status, call docker ps . Note that it is recommended to have at least 2Gb of RAM to use Node SE efficiently. Basic Installation This is the easiest version. You can only call three commands to install the solution. First, install TON Labs CLI by running: npm install -g ton-dev-cli Important : If you get errors related to permissions when trying to install packages globally, you can try to fix them using the following options: https://docs.npmjs.com/resolving-eacces-permissions-errors-when-installing-packages-globally . Or call: sudo chown -R $(whoami) $(npm root -g) If you fail, run the command under sudo . Then setup your machine. The step is optional, because tondev start and tondev sol perform the step on demand (see below). tondev setup Run the Local Node Call the following command to run the local node instance (Node SE): tondev start Manual Installation If you have troubles with tondev CLI utility you can install all required components yourself with the following commands: Note that Windows and Linux use different slashes ( / vs. * * ) for system paths. Make sure to change them as needed in the paths to avoid errors. docker pull tonlabs/local-node docker pull tonlabs/compilers docker create -e USER_AGREEMENT=yes --name tonlabs-local-node -i -p80:80 tonlabs/local-node mkdir user home directory /.tonlabs/compilers/projects docker create -e USER_AGREEMENT=yes --name tonlabs-compilers -it --mount type=bind,dst=/projects,src= user home directory /.tonlabs/compilers/projects tonlabs/compilers docker start tonlabs-local-node docker start tonlabs-compilers Home directory may have one of the following formats: Windows: C:\\Users\\User1 MacOS: '/Users/johnDough' Linux: /home/johnDough \u200b Install Client Libraries Tip : go to the Getting Started section, to create your own environment and a test project from scratch according to detailed guidelines. Rust Add a dependency into your cargo manifest: [dependencies] ton-client-rs = 0.11.1 Call the following command: cargo update Node.js Call the following command to install Node.js client library (the recommended version comes first): dependencies : { ton-client-node-js : ^0.12.1 } Then execute (in the project folder): ~/ton-dev/hello$ npm install Or instead of steps 1 and 2 call: npm install ton-client-node-js Web Call the following command to install client library for web browsers: npm install ton-client-web-js React Native Call the following command to install client library for React Native: npm install ton-client-react-native-js Visit TON Dev for additional product, company community info.","title":"Installation"},{"location":"SDK/Installation/#preparation","text":"","title":"Preparation"},{"location":"SDK/Installation/#prerequisites","text":"Install the latest version of Docker . See installation tips in the screenshots below: For Linux users, make sure that you are able to run docker as non-root user (see https://docs.docker.com/install/linux/linux-postinstall/ ); Tip : check this page for more Docker installation options https://phoenixnap.com/kb/how-to-install-docker-on-ubuntu-18-04 . Install Node.js 10.x or newer. Make sure that Docker daemon is running on your computer. To check its status, call docker ps . Note that it is recommended to have at least 2Gb of RAM to use Node SE efficiently.","title":"Prerequisites"},{"location":"SDK/Installation/#basic-installation","text":"This is the easiest version. You can only call three commands to install the solution. First, install TON Labs CLI by running: npm install -g ton-dev-cli Important : If you get errors related to permissions when trying to install packages globally, you can try to fix them using the following options: https://docs.npmjs.com/resolving-eacces-permissions-errors-when-installing-packages-globally . Or call: sudo chown -R $(whoami) $(npm root -g) If you fail, run the command under sudo . Then setup your machine. The step is optional, because tondev start and tondev sol perform the step on demand (see below). tondev setup","title":"Basic Installation"},{"location":"SDK/Installation/#run-the-local-node","text":"Call the following command to run the local node instance (Node SE): tondev start","title":"Run the Local Node"},{"location":"SDK/Installation/#manual-installation","text":"If you have troubles with tondev CLI utility you can install all required components yourself with the following commands: Note that Windows and Linux use different slashes ( / vs. * * ) for system paths. Make sure to change them as needed in the paths to avoid errors. docker pull tonlabs/local-node docker pull tonlabs/compilers docker create -e USER_AGREEMENT=yes --name tonlabs-local-node -i -p80:80 tonlabs/local-node mkdir user home directory /.tonlabs/compilers/projects docker create -e USER_AGREEMENT=yes --name tonlabs-compilers -it --mount type=bind,dst=/projects,src= user home directory /.tonlabs/compilers/projects tonlabs/compilers docker start tonlabs-local-node docker start tonlabs-compilers Home directory may have one of the following formats: Windows: C:\\Users\\User1 MacOS: '/Users/johnDough' Linux: /home/johnDough \u200b","title":"Manual Installation"},{"location":"SDK/Installation/#install-client-libraries","text":"Tip : go to the Getting Started section, to create your own environment and a test project from scratch according to detailed guidelines.","title":"Install Client Libraries"},{"location":"SDK/Installation/#rust","text":"Add a dependency into your cargo manifest: [dependencies] ton-client-rs = 0.11.1 Call the following command: cargo update","title":"Rust"},{"location":"SDK/Installation/#nodejs","text":"Call the following command to install Node.js client library (the recommended version comes first): dependencies : { ton-client-node-js : ^0.12.1 } Then execute (in the project folder): ~/ton-dev/hello$ npm install Or instead of steps 1 and 2 call: npm install ton-client-node-js","title":"Node.js"},{"location":"SDK/Installation/#web","text":"Call the following command to install client library for web browsers: npm install ton-client-web-js","title":"Web"},{"location":"SDK/Installation/#react-native","text":"Call the following command to install client library for React Native: npm install ton-client-react-native-js Visit TON Dev for additional product, company community info.","title":"React Native"},{"location":"SDK/Overview/","text":"Accessible Toolkit TON Labs SDK comes with tools and features helping TON Dev developers to: Compile smart contracts into the TVC format See the Toolchain documentation for detailed information about TON Labs compilers. For additional information on the TVC format, refer to the original TON blockchain documentation. Deploy, run, test and debug smart contracts using a local Node Server (Node SE) Quickly and easily interact with blockchain data and track changes Components TON Labs Local Node \u2013 Debug and test your smart contracts in a controlled environment with an instance that acts just like a production node. TON Labs Compiler Kit \u2013 Compile TVC files from Solidity source code and from C using our LLVM-based solution. TON Labs Client Libraries \u2013 An open standard to develop smart contract and test them locally. TON Dev CLI that glues the components together and enables smooth installation and development. Each TON Labs Client Library includes: Crypto \u2013 TON-related cryptography functions. Contracts - smart contract deployment and management. Queries \u2013 monitoring and querying blockchain data in real time. Prerequisites To use the product, you need a machine that supports Docker . All the necessary docker images are available at docker hub. You also have to install one of the newest stable versions of Node.js. Any supported development/runtime environment can run TON Labs Client Libraries installed with the proper package manager. Warning : Docker utilizes a built-in virtual machine management component called Hyper-V to run itself. It is not a feature of Windows Home edition. Therefore, the solution cannot be installed on Windows Home Edition. All the other Windows editions fit the required criteria. Tip : If you are a Windows Home user, try installing a VM according to the doc here . Sources You can use the installation procedure provided in the this guide to smoothly create your own development lab, but, in case you are interested, here are the links to sources: https://github.com/tonlabs/ton-client-node-js https://github.com/tonlabs/ton-client-web-js https://github.com/tonlabs/ton-client-react-native-js https://github.com/tonlabs/ton-client-rs https://hub.docker.com/r/tonlabs/local-node https://hub.docker.com/r/tonlabs/compilers Visit TON Dev for additional product, company community info.","title":"Overview"},{"location":"SDK/Overview/#accessible-toolkit","text":"TON Labs SDK comes with tools and features helping TON Dev developers to: Compile smart contracts into the TVC format See the Toolchain documentation for detailed information about TON Labs compilers. For additional information on the TVC format, refer to the original TON blockchain documentation. Deploy, run, test and debug smart contracts using a local Node Server (Node SE) Quickly and easily interact with blockchain data and track changes","title":"Accessible Toolkit"},{"location":"SDK/Overview/#components","text":"TON Labs Local Node \u2013 Debug and test your smart contracts in a controlled environment with an instance that acts just like a production node. TON Labs Compiler Kit \u2013 Compile TVC files from Solidity source code and from C using our LLVM-based solution. TON Labs Client Libraries \u2013 An open standard to develop smart contract and test them locally. TON Dev CLI that glues the components together and enables smooth installation and development. Each TON Labs Client Library includes: Crypto \u2013 TON-related cryptography functions. Contracts - smart contract deployment and management. Queries \u2013 monitoring and querying blockchain data in real time.","title":"Components"},{"location":"SDK/Overview/#prerequisites","text":"To use the product, you need a machine that supports Docker . All the necessary docker images are available at docker hub. You also have to install one of the newest stable versions of Node.js. Any supported development/runtime environment can run TON Labs Client Libraries installed with the proper package manager. Warning : Docker utilizes a built-in virtual machine management component called Hyper-V to run itself. It is not a feature of Windows Home edition. Therefore, the solution cannot be installed on Windows Home Edition. All the other Windows editions fit the required criteria. Tip : If you are a Windows Home user, try installing a VM according to the doc here .","title":"Prerequisites"},{"location":"SDK/Overview/#sources","text":"You can use the installation procedure provided in the this guide to smoothly create your own development lab, but, in case you are interested, here are the links to sources: https://github.com/tonlabs/ton-client-node-js https://github.com/tonlabs/ton-client-web-js https://github.com/tonlabs/ton-client-react-native-js https://github.com/tonlabs/ton-client-rs https://hub.docker.com/r/tonlabs/local-node https://hub.docker.com/r/tonlabs/compilers Visit TON Dev for additional product, company community info.","title":"Sources"},{"location":"SDK/Auxiliaries/Getting Logs/","text":"To review logs, call the following command providing the relevant container name or id: docker exec -it container_name_or_id bash The log is then displayed in the terminal. The log file is stored at cd /ton-node/log in output.log . You can also copy it directly to host by calling: docker cp container :/ton-node/log/output.log dest_path The screenshot shows log of the local node performance. Note that the use of sudo depends on your local settings and preferences. It is not necessary or mandatory.","title":"Getting Logs"},{"location":"SDK/Auxiliaries/Installing Ubuntu VM/","text":"Accessible Toolkit TON Labs SDK comes with tools and features helping TON Dev developers to: Compile smart contracts into the TVC format See the Toolchain documentation for detailed information about TON Labs compilers. For additional information on the TVC format, refer to the original TON blockchain documentation. Deploy, run, test and debug smart contracts using a local Node Server (Node SE) Quickly and easily interact with blockchain data and track changes Components TON Labs Local Node \u2013 Debug and test your smart contracts in a controlled environment with an instance that acts just like a production node. TON Labs Compiler Kit \u2013 Compile TVC files from Solidity source code and from C using our LLVM-based solution. TON Labs Client Libraries \u2013 An open standard to develop smart contract and test them locally. TON Dev CLI that glues the components together and enables smooth installation and development. Each TON Labs Client Library includes: Crypto \u2013 TON-related cryptography functions. Contracts - smart contract deployment and management. Queries \u2013 monitoring and querying blockchain data in real time. Prerequisites To use the product, you need a machine that supports Docker . All the necessary docker images are available at docker hub. You also have to install one of the newest stable versions of Node.js. Any supported development/runtime environment can run TON Labs Client Libraries installed with the proper package manager. Warning : Docker utilizes a built-in virtual machine management component called Hyper-V to run itself. It is not a feature of Windows Home edition. Therefore, the solution cannot be installed on Windows Home Edition. All the other Windows editions fit the required criteria. Tip : If you are a Windows Home user, try installing a VM according to the doc here . Sources You can use the installation procedure provided in the this guide to smoothly create your own development lab, but, in case you are interested, here are the links to sources: https://github.com/tonlabs/ton-client-node-js https://github.com/tonlabs/ton-client-web-js https://github.com/tonlabs/ton-client-react-native-js https://github.com/tonlabs/ton-client-rs https://hub.docker.com/r/tonlabs/local-node https://hub.docker.com/r/tonlabs/compilers Visit TON Dev for additional product, company community info.","title":"Installing Ubuntu VM"},{"location":"SDK/Auxiliaries/Installing Ubuntu VM/#accessible-toolkit","text":"TON Labs SDK comes with tools and features helping TON Dev developers to: Compile smart contracts into the TVC format See the Toolchain documentation for detailed information about TON Labs compilers. For additional information on the TVC format, refer to the original TON blockchain documentation. Deploy, run, test and debug smart contracts using a local Node Server (Node SE) Quickly and easily interact with blockchain data and track changes","title":"Accessible Toolkit"},{"location":"SDK/Auxiliaries/Installing Ubuntu VM/#components","text":"TON Labs Local Node \u2013 Debug and test your smart contracts in a controlled environment with an instance that acts just like a production node. TON Labs Compiler Kit \u2013 Compile TVC files from Solidity source code and from C using our LLVM-based solution. TON Labs Client Libraries \u2013 An open standard to develop smart contract and test them locally. TON Dev CLI that glues the components together and enables smooth installation and development. Each TON Labs Client Library includes: Crypto \u2013 TON-related cryptography functions. Contracts - smart contract deployment and management. Queries \u2013 monitoring and querying blockchain data in real time.","title":"Components"},{"location":"SDK/Auxiliaries/Installing Ubuntu VM/#prerequisites","text":"To use the product, you need a machine that supports Docker . All the necessary docker images are available at docker hub. You also have to install one of the newest stable versions of Node.js. Any supported development/runtime environment can run TON Labs Client Libraries installed with the proper package manager. Warning : Docker utilizes a built-in virtual machine management component called Hyper-V to run itself. It is not a feature of Windows Home edition. Therefore, the solution cannot be installed on Windows Home Edition. All the other Windows editions fit the required criteria. Tip : If you are a Windows Home user, try installing a VM according to the doc here .","title":"Prerequisites"},{"location":"SDK/Auxiliaries/Installing Ubuntu VM/#sources","text":"You can use the installation procedure provided in the this guide to smoothly create your own development lab, but, in case you are interested, here are the links to sources: https://github.com/tonlabs/ton-client-node-js https://github.com/tonlabs/ton-client-web-js https://github.com/tonlabs/ton-client-react-native-js https://github.com/tonlabs/ton-client-rs https://hub.docker.com/r/tonlabs/local-node https://hub.docker.com/r/tonlabs/compilers Visit TON Dev for additional product, company community info.","title":"Sources"},{"location":"SDK/Auxiliaries/TON SDK CLI/","text":"Install and Run To install, call: npm install -g ton-dev-cli To run, call: tondev command ...args Key \u0421ommands help : displays the complete list of available commands; setup : installs all required TON Labs software and start services; start : starts Node SE and Compiler containers; sol files [ -l js ] : build the contract .tvc and .abi.json files from Solidity files Optionally you can generate a JavaScript file with contract ABI and TVC encoded with base64 tondev setup tondev sol filename tondev sol filename -l js clean : stops and removes all containers and images related to Node SE and its components; info gets the current Node SE state. The command shows: the list of images and docker containers related to Node SE. current container state list of versions available at docker hub. container settings the version in use use version : allows switching between containers, e.g.: tondev use 0.11.0 . By default :latest is used. restart restarts the containers; recreate used to recreate containers; When called without parameters, tondev is similar to the info command. \u200b Reference List Usage: tondev [options] [command] TON Labs development tools Options: -V, --version output the version number -a, --available show available versions -h, --help output usage information Commands: info [options] Show summary about dev environment setup [options] Setup dev environment start [options] Start dev containers stop [options] Stop dev containers restart [options] Restart dev containers recreate [options] Recreate dev containers clean [options] Remove docker containers and images related to TON Dev use [options] version Use specified version for containers set [options] [network...] Set network[s] options add [network...] Add network[s] remove|rm [network...] Remove network[s] sol [options] [files...] Build solidity contract[s] -------------- Commands help: -------------- Command: info Usage: tondev info [options] Show summary about dev environment Options: Visit TON Dev for additional product, company community info.","title":"TON SDK CLI"},{"location":"SDK/Auxiliaries/TON SDK CLI/#install-and-run","text":"To install, call: npm install -g ton-dev-cli To run, call: tondev command ...args","title":"Install and Run"},{"location":"SDK/Auxiliaries/TON SDK CLI/#key-ommands","text":"help : displays the complete list of available commands; setup : installs all required TON Labs software and start services; start : starts Node SE and Compiler containers; sol files [ -l js ] : build the contract .tvc and .abi.json files from Solidity files Optionally you can generate a JavaScript file with contract ABI and TVC encoded with base64 tondev setup tondev sol filename tondev sol filename -l js clean : stops and removes all containers and images related to Node SE and its components; info gets the current Node SE state. The command shows: the list of images and docker containers related to Node SE. current container state list of versions available at docker hub. container settings the version in use use version : allows switching between containers, e.g.: tondev use 0.11.0 . By default :latest is used. restart restarts the containers; recreate used to recreate containers; When called without parameters, tondev is similar to the info command. \u200b","title":"Key \u0421ommands"},{"location":"SDK/Auxiliaries/TON SDK CLI/#reference-list","text":"Usage: tondev [options] [command] TON Labs development tools Options: -V, --version output the version number -a, --available show available versions -h, --help output usage information Commands: info [options] Show summary about dev environment setup [options] Setup dev environment start [options] Start dev containers stop [options] Stop dev containers restart [options] Restart dev containers recreate [options] Recreate dev containers clean [options] Remove docker containers and images related to TON Dev use [options] version Use specified version for containers set [options] [network...] Set network[s] options add [network...] Add network[s] remove|rm [network...] Remove network[s] sol [options] [files...] Build solidity contract[s] -------------- Commands help: -------------- Command: info Usage: tondev info [options] Show summary about dev environment Options: Visit TON Dev for additional product, company community info.","title":"Reference List"},{"location":"SDK/Auxiliaries/Troubleshooting/","text":"Accessible Toolkit TON Labs SDK comes with tools and features helping TON Dev developers to: Compile smart contracts into the TVC format See the Toolchain documentation for detailed information about TON Labs compilers. For additional information on the TVC format, refer to the original TON blockchain documentation. Deploy, run, test and debug smart contracts using a local Node Server (Node SE) Quickly and easily interact with blockchain data and track changes Components TON Labs Local Node \u2013 Debug and test your smart contracts in a controlled environment with an instance that acts just like a production node. TON Labs Compiler Kit \u2013 Compile TVC files from Solidity source code and from C using our LLVM-based solution. TON Labs Client Libraries \u2013 An open standard to develop smart contract and test them locally. TON Dev CLI that glues the components together and enables smooth installation and development. Each TON Labs Client Library includes: Crypto \u2013 TON-related cryptography functions. Contracts - smart contract deployment and management. Queries \u2013 monitoring and querying blockchain data in real time. Prerequisites To use the product, you need a machine that supports Docker . All the necessary docker images are available at docker hub. You also have to install one of the newest stable versions of Node.js. Any supported development/runtime environment can run TON Labs Client Libraries installed with the proper package manager. Warning : Docker utilizes a built-in virtual machine management component called Hyper-V to run itself. It is not a feature of Windows Home edition. Therefore, the solution cannot be installed on Windows Home Edition. All the other Windows editions fit the required criteria. Tip : If you are a Windows Home user, try installing a VM according to the doc here . Sources You can use the installation procedure provided in the this guide to smoothly create your own development lab, but, in case you are interested, here are the links to sources: https://github.com/tonlabs/ton-client-node-js https://github.com/tonlabs/ton-client-web-js https://github.com/tonlabs/ton-client-react-native-js https://github.com/tonlabs/ton-client-rs https://hub.docker.com/r/tonlabs/local-node https://hub.docker.com/r/tonlabs/compilers Visit TON Dev for additional product, company community info.","title":"Troubleshooting"},{"location":"SDK/Auxiliaries/Troubleshooting/#accessible-toolkit","text":"TON Labs SDK comes with tools and features helping TON Dev developers to: Compile smart contracts into the TVC format See the Toolchain documentation for detailed information about TON Labs compilers. For additional information on the TVC format, refer to the original TON blockchain documentation. Deploy, run, test and debug smart contracts using a local Node Server (Node SE) Quickly and easily interact with blockchain data and track changes","title":"Accessible Toolkit"},{"location":"SDK/Auxiliaries/Troubleshooting/#components","text":"TON Labs Local Node \u2013 Debug and test your smart contracts in a controlled environment with an instance that acts just like a production node. TON Labs Compiler Kit \u2013 Compile TVC files from Solidity source code and from C using our LLVM-based solution. TON Labs Client Libraries \u2013 An open standard to develop smart contract and test them locally. TON Dev CLI that glues the components together and enables smooth installation and development. Each TON Labs Client Library includes: Crypto \u2013 TON-related cryptography functions. Contracts - smart contract deployment and management. Queries \u2013 monitoring and querying blockchain data in real time.","title":"Components"},{"location":"SDK/Auxiliaries/Troubleshooting/#prerequisites","text":"To use the product, you need a machine that supports Docker . All the necessary docker images are available at docker hub. You also have to install one of the newest stable versions of Node.js. Any supported development/runtime environment can run TON Labs Client Libraries installed with the proper package manager. Warning : Docker utilizes a built-in virtual machine management component called Hyper-V to run itself. It is not a feature of Windows Home edition. Therefore, the solution cannot be installed on Windows Home Edition. All the other Windows editions fit the required criteria. Tip : If you are a Windows Home user, try installing a VM according to the doc here .","title":"Prerequisites"},{"location":"SDK/Auxiliaries/Troubleshooting/#sources","text":"You can use the installation procedure provided in the this guide to smoothly create your own development lab, but, in case you are interested, here are the links to sources: https://github.com/tonlabs/ton-client-node-js https://github.com/tonlabs/ton-client-web-js https://github.com/tonlabs/ton-client-react-native-js https://github.com/tonlabs/ton-client-rs https://hub.docker.com/r/tonlabs/local-node https://hub.docker.com/r/tonlabs/compilers Visit TON Dev for additional product, company community info.","title":"Sources"},{"location":"SDK/Client Libraries/Library Modules/Contracts/","text":"About the ABI Despite the fact that each TON contract is actually a single function, the TON SDK allows defining multiple functions within it. To achieve it, the original multi-functional contract is compiled into a single function one with an incoming message dispatcher. For correct encoding incoming messages to these contracts and decoding output ones, the SDK Library uses an ABI: a structural description of input/output messages related to contract functions. Compiling to TVC With the SDK compiler you can: obtain TVM-ready code from Solidity sources. obtain TVM-ready code from our LLVM-based compiler that can potentially take source code in various general purpose languages. Now we have an implementation of the C language. The Toolchain documentation contains all information on TON Labs Toolchain. The Compiler Kit is shipped as a Docker container with pre-configured tools ready to work. Deploying contracts The Contracts module of the TON Labs Client Library allows you to deploy a compiled contract to the blockchain. To deploy a contract, you need TVM-ready code ( .tvc file), an ABI ( .abi.json file) and a key pair. Note : a contract cannot be deployed before it has some amount of Grams on its balance. All attempts to deploy a contract with a zero balance will fail. So, before deploying a contract, run another one to transfer Grams to the contract you plan to deploy. Make sure that the transferred amount covers all deployment fees and costs. Or, in case you are using Node SE instance, use the pre-deployed Giver for it. Add this code to your index.js file: const nodeSeGiverAddress = 'a46af093b38fcae390e9af5104a93e22e82c29bcb35bf88160e4478417028884'; const nodeSeGiverAbi = { ABI version : 1, functions : [ { name : constructor , inputs : [ ], outputs : [ ] }, { name : sendGrams , inputs : [ { name : dest , type : uint256 }, { name : amount , type : uint64 } ], outputs : [ ] } ], events : [ ], data : [ ] }; async function get_grams_from_giver(client, account) { const { contracts, queries } = client; const result = await contracts.run({ address: giverAddress, functionName: 'sendGrams', abi: giverAbi, input: { dest: `0x${account}`, amount: 10000000000 }, keyPair: null, }); const wait = await queries.accounts.waitFor( { id: { eq: account }, storage: { balance: { Grams: { gt: 0 } } } }, 'id storage {balance {Grams}}' ); }; Now you need to calculate future address by generating deploy message of the contract to know where to transfer funds for deploy. const futureHelloAddress = (await client.contracts.createDeployMessage({ package: HelloContract.package, constructorParams: {}, keyPair: helloKeys, })).address; console.log(`Future address of the contract will be: ${futureHelloAddress}`); Transfer some grams to this address: await get_grams_from_giver(client, futureHelloAddress); console.log(`Grams were transfered from giver to ${futureHelloAddress}`); Now you are ready to initialize the account with contract code by deploying it. Run const helloAddress = (await client.contracts.deploy({ package: HelloContract.package, constructorParams: {}, keyPair: helloKeys, })).address; console.log(`Hello contract was deployed at address: ${helloAddress}`); The package parameter is a structure with two fields: abi and imageBase64 , where: abi is a contract ABI; imageBase64 is the TVC code encoded with base64. The contructorParams includes parameters passed to the constructor. It can be empty and expressed as {} , if the constructor has no parameters. The keyPair is a mandatory parameter that specifies the following: public key is placed into contract initial state as a rule for deploying ABI-based contracts; secret key is used to sign a constructor invocation. The deployment method executes the following sequence: Prepares a deploy request. Sends a constructor message to a node Waits until the deployment is complete. Generates the constructor invocation request. Sends the invocation to the blockchain node. Waits until the invocation phase is complete. The returned result contains an account address assigned to the newly deployed contract. Running contracts Running functions Running a contract implies the following steps: Generating an input message to contract with a function name and parameter values. Posting this message to the node. Waiting until the node runs the contract at the TVM, recording the result into blockchain and synchronizing the changes with TON. Reading an output message with function result from the blockchain and decoding it. In the SDK all these steps are incorporated within the run library method. To run a contract, we need its address, an ABI, a function name with parameters and a key pair if message signing is required. const resut = await client.contracts.run({ address: helloAddress, abi: HelloContract.package.abi, functionName: 'sayHello', input: {}, keyPair: helloKeys, }); The result contains the output field with a decoded output message returned by the source contract function. If an optional keyPair parameter is specified, the input message is signed and accompanied with a public key. So, the contract can perform authorization using a verifiable public key passed to it. Running locally Cases are when all a contract function does is calculate some data based on the current contract state and return the calculation result. In these cases we do not need the standard sequence to run a contract. Instead, the following steps are taken: Generate an input message to contract with a function name and parameter values. Read the current contract state into an application. The contract state is taken from ArangoDB. Run the contract code on a lightweight TVM included into the client library by passing a contract state and an input message. Decode the contract output message. This running method is less time-consuming and involves no fees related to a regular contract execution. Note : local contract invocation does not impact the blockchain: all transactions, message and state change produces are just discarded. To execute a contract inside an application just use the runLocal method instead of run . The parameters are the same, only the method name differs. const localResponse = await client.contracts.runLocal({ address: helloAddress, abi: HelloContract.package.abi, functionName: 'sayHello', input: {}, keyPair: helloKeys, }); Decoding messages Some contract functions can generate output messages targeted at some external services. Mainly, these are integration services designed as a glue between blockchain contracts and regular REST (or similar) services. Typically, these services use the following scenario: The service subscribes to messages changes in a blockchain. Usually a subscription is filtered by messages related to a specific account. When a new message comes to a blockchain, an integration service is triggered. It reads and decodes this message. Then, the integration service invokes an offchain service using parameters according to the decoded data. For these services the Client library provides the decodeOutputMessage method. It decodes output messages recorded into a blockchain. In addition to decoding output messages the Client library provides the decodeInputMessage method that decodes input messages. Note : Decoding requires an ABI and is only applicable to ABI compliant messages. Advanced Features Advanced Features Signing messages externally Although the library provides friendly and simple functions to deploy and run contracts, there are cases when more precision and control is required to deploy and run an application contract. For example, an application can use a crypto provider inaccessible from the client library (e.g. a JavaCard crypto provider). To solve this, the library offers several functions: createUnsignedDeployRequest and createUnsignedRunRequest \u2013 these functions take the same parameters as the deploy or run functions except that instead of keyPair only the public key is passed. This function returns an encoded message body and a byte buffer required to produce a signature. createSignedDeployMessage and createSignedRunMessage \u2013 this functions take an unsigned message body, sign bytes and the public key. The output is a message compatible with a blockchain node. createDeployMessage and createRunMessage \u2013 these functions generate the same sequence. The example below shows how to create an unsigned deploy message, sign it and then combine the unsigned message with the signature and finally to deploy the signed message. async function testExternalSigning(client) { const { contracts, crypto } = client; // Generate Key Pair const masterKeys = await crypto.ed25519Keypair(); // Prepare deploy params and use only public key const deployParams = { package: events_package, constructorParams: {}, keyPair: { public: masterKeys.public, secret: '' }, }; // Create unsigned deploy message const unsignedMessage = await contracts.createUnsignedDeployMessage(deployParams); const bytesToSignBase64 = unsignedMessage.signParams.bytesToSignBase64; // Create signature for bytes buffer // This can be done in isolated secret place like a HSM const signBytesBase64 = await crypto.naclSignDetached( { base64: bytesToSignBase64 }, `${masterKeys.secret}${masterKeys.public}`, TONOutputEncoding.Base64 ); // Create signed message with provided sign const signed = await contracts.createSignedDeployMessage({ address: unsignedMessage.address, createSignedParams: { publicKeyHex: masterKeys.public, signBytesBase64: signBytesBase64, unsignedBytesBase64: unsignedMessage.signParams.unsignedBytesBase64, } }); // Deploy signed message const message = await contracts.createDeployMessage(deployParams); expect(signed.message.messageBodyBase64).toEqual(message.message.messageBodyBase64); }","title":"Contracts"},{"location":"SDK/Client Libraries/Library Modules/Contracts/#about-the-abi","text":"Despite the fact that each TON contract is actually a single function, the TON SDK allows defining multiple functions within it. To achieve it, the original multi-functional contract is compiled into a single function one with an incoming message dispatcher. For correct encoding incoming messages to these contracts and decoding output ones, the SDK Library uses an ABI: a structural description of input/output messages related to contract functions.","title":"About the ABI"},{"location":"SDK/Client Libraries/Library Modules/Contracts/#compiling-to-tvc","text":"With the SDK compiler you can: obtain TVM-ready code from Solidity sources. obtain TVM-ready code from our LLVM-based compiler that can potentially take source code in various general purpose languages. Now we have an implementation of the C language. The Toolchain documentation contains all information on TON Labs Toolchain. The Compiler Kit is shipped as a Docker container with pre-configured tools ready to work.","title":"Compiling to TVC"},{"location":"SDK/Client Libraries/Library Modules/Contracts/#deploying-contracts","text":"The Contracts module of the TON Labs Client Library allows you to deploy a compiled contract to the blockchain. To deploy a contract, you need TVM-ready code ( .tvc file), an ABI ( .abi.json file) and a key pair. Note : a contract cannot be deployed before it has some amount of Grams on its balance. All attempts to deploy a contract with a zero balance will fail. So, before deploying a contract, run another one to transfer Grams to the contract you plan to deploy. Make sure that the transferred amount covers all deployment fees and costs. Or, in case you are using Node SE instance, use the pre-deployed Giver for it. Add this code to your index.js file: const nodeSeGiverAddress = 'a46af093b38fcae390e9af5104a93e22e82c29bcb35bf88160e4478417028884'; const nodeSeGiverAbi = { ABI version : 1, functions : [ { name : constructor , inputs : [ ], outputs : [ ] }, { name : sendGrams , inputs : [ { name : dest , type : uint256 }, { name : amount , type : uint64 } ], outputs : [ ] } ], events : [ ], data : [ ] }; async function get_grams_from_giver(client, account) { const { contracts, queries } = client; const result = await contracts.run({ address: giverAddress, functionName: 'sendGrams', abi: giverAbi, input: { dest: `0x${account}`, amount: 10000000000 }, keyPair: null, }); const wait = await queries.accounts.waitFor( { id: { eq: account }, storage: { balance: { Grams: { gt: 0 } } } }, 'id storage {balance {Grams}}' ); }; Now you need to calculate future address by generating deploy message of the contract to know where to transfer funds for deploy. const futureHelloAddress = (await client.contracts.createDeployMessage({ package: HelloContract.package, constructorParams: {}, keyPair: helloKeys, })).address; console.log(`Future address of the contract will be: ${futureHelloAddress}`); Transfer some grams to this address: await get_grams_from_giver(client, futureHelloAddress); console.log(`Grams were transfered from giver to ${futureHelloAddress}`); Now you are ready to initialize the account with contract code by deploying it. Run const helloAddress = (await client.contracts.deploy({ package: HelloContract.package, constructorParams: {}, keyPair: helloKeys, })).address; console.log(`Hello contract was deployed at address: ${helloAddress}`); The package parameter is a structure with two fields: abi and imageBase64 , where: abi is a contract ABI; imageBase64 is the TVC code encoded with base64. The contructorParams includes parameters passed to the constructor. It can be empty and expressed as {} , if the constructor has no parameters. The keyPair is a mandatory parameter that specifies the following: public key is placed into contract initial state as a rule for deploying ABI-based contracts; secret key is used to sign a constructor invocation. The deployment method executes the following sequence: Prepares a deploy request. Sends a constructor message to a node Waits until the deployment is complete. Generates the constructor invocation request. Sends the invocation to the blockchain node. Waits until the invocation phase is complete. The returned result contains an account address assigned to the newly deployed contract.","title":"Deploying contracts"},{"location":"SDK/Client Libraries/Library Modules/Contracts/#running-contracts","text":"","title":"Running contracts"},{"location":"SDK/Client Libraries/Library Modules/Contracts/#running-functions","text":"Running a contract implies the following steps: Generating an input message to contract with a function name and parameter values. Posting this message to the node. Waiting until the node runs the contract at the TVM, recording the result into blockchain and synchronizing the changes with TON. Reading an output message with function result from the blockchain and decoding it. In the SDK all these steps are incorporated within the run library method. To run a contract, we need its address, an ABI, a function name with parameters and a key pair if message signing is required. const resut = await client.contracts.run({ address: helloAddress, abi: HelloContract.package.abi, functionName: 'sayHello', input: {}, keyPair: helloKeys, }); The result contains the output field with a decoded output message returned by the source contract function. If an optional keyPair parameter is specified, the input message is signed and accompanied with a public key. So, the contract can perform authorization using a verifiable public key passed to it.","title":"Running functions"},{"location":"SDK/Client Libraries/Library Modules/Contracts/#running-locally","text":"Cases are when all a contract function does is calculate some data based on the current contract state and return the calculation result. In these cases we do not need the standard sequence to run a contract. Instead, the following steps are taken: Generate an input message to contract with a function name and parameter values. Read the current contract state into an application. The contract state is taken from ArangoDB. Run the contract code on a lightweight TVM included into the client library by passing a contract state and an input message. Decode the contract output message. This running method is less time-consuming and involves no fees related to a regular contract execution. Note : local contract invocation does not impact the blockchain: all transactions, message and state change produces are just discarded. To execute a contract inside an application just use the runLocal method instead of run . The parameters are the same, only the method name differs. const localResponse = await client.contracts.runLocal({ address: helloAddress, abi: HelloContract.package.abi, functionName: 'sayHello', input: {}, keyPair: helloKeys, });","title":"Running  locally"},{"location":"SDK/Client Libraries/Library Modules/Contracts/#decoding-messages","text":"Some contract functions can generate output messages targeted at some external services. Mainly, these are integration services designed as a glue between blockchain contracts and regular REST (or similar) services. Typically, these services use the following scenario: The service subscribes to messages changes in a blockchain. Usually a subscription is filtered by messages related to a specific account. When a new message comes to a blockchain, an integration service is triggered. It reads and decodes this message. Then, the integration service invokes an offchain service using parameters according to the decoded data. For these services the Client library provides the decodeOutputMessage method. It decodes output messages recorded into a blockchain. In addition to decoding output messages the Client library provides the decodeInputMessage method that decodes input messages. Note : Decoding requires an ABI and is only applicable to ABI compliant messages. Advanced Features","title":"Decoding messages"},{"location":"SDK/Client Libraries/Library Modules/Contracts/#advanced-features","text":"","title":"Advanced Features"},{"location":"SDK/Client Libraries/Library Modules/Contracts/#signing-messages-externally","text":"Although the library provides friendly and simple functions to deploy and run contracts, there are cases when more precision and control is required to deploy and run an application contract. For example, an application can use a crypto provider inaccessible from the client library (e.g. a JavaCard crypto provider). To solve this, the library offers several functions: createUnsignedDeployRequest and createUnsignedRunRequest \u2013 these functions take the same parameters as the deploy or run functions except that instead of keyPair only the public key is passed. This function returns an encoded message body and a byte buffer required to produce a signature. createSignedDeployMessage and createSignedRunMessage \u2013 this functions take an unsigned message body, sign bytes and the public key. The output is a message compatible with a blockchain node. createDeployMessage and createRunMessage \u2013 these functions generate the same sequence. The example below shows how to create an unsigned deploy message, sign it and then combine the unsigned message with the signature and finally to deploy the signed message. async function testExternalSigning(client) { const { contracts, crypto } = client; // Generate Key Pair const masterKeys = await crypto.ed25519Keypair(); // Prepare deploy params and use only public key const deployParams = { package: events_package, constructorParams: {}, keyPair: { public: masterKeys.public, secret: '' }, }; // Create unsigned deploy message const unsignedMessage = await contracts.createUnsignedDeployMessage(deployParams); const bytesToSignBase64 = unsignedMessage.signParams.bytesToSignBase64; // Create signature for bytes buffer // This can be done in isolated secret place like a HSM const signBytesBase64 = await crypto.naclSignDetached( { base64: bytesToSignBase64 }, `${masterKeys.secret}${masterKeys.public}`, TONOutputEncoding.Base64 ); // Create signed message with provided sign const signed = await contracts.createSignedDeployMessage({ address: unsignedMessage.address, createSignedParams: { publicKeyHex: masterKeys.public, signBytesBase64: signBytesBase64, unsignedBytesBase64: unsignedMessage.signParams.unsignedBytesBase64, } }); // Deploy signed message const message = await contracts.createDeployMessage(deployParams); expect(signed.message.messageBodyBase64).toEqual(message.message.messageBodyBase64); }","title":"Signing messages externally"},{"location":"SDK/Client Libraries/Library Modules/Crypto/","text":"TON Client Library is shipped with a crypto module that contains the following set of crypto functions for TON blockchain. math and random: generate_random_bytes, modular_power, factorize; sha256, sha512; generate_random_ed25519_keys; scrypt; menmonic: mnemonic_get_words, mnemonic_generate_random, mnemonic_from_entropy, mnemonic_is_valid, mnemonic_seed_from_phrase_and_salt, mnemonic_entropy_from_phrase; HD Keys: hdkey_xprv_from_mnemonic, hdkey_secret_from_xprv, hdkey_public_from_xprv, hdkey_derive_from_xprv, hdkey_derive_from_xprv_path; NaCl: nacl_sign_keys, nacl_sign_keys_from_secret, nacl_box_keys, nacl_box_keys_from_secret_key, nacl_secret_box, nacl_secret_box_open, nacl_box, nacl_box_open, nacl_sign, nacl_sign_open, nacl_sign_detached; Key store: keystore_add, keystore_remove, clear. Key Store The crypto module holds a set of key pairs accessible through a handle. A key pair can be added to a key store or removed from it. Once added to a keystore, a key pair gets a handle assigned to it. This handle can be used in relevant crypto functions instead of the key pair itself. Reference Links Follow the link to our github repository to get the list of our crypto-functions: https://github.com/tonlabs/ton-client-js/blob/75270514d6e1051fe7159b7bcc79f1110ebe6d1b/types.js#L55 These functions are standard and familiar to the professional audience. For a brief guide, follow the link: https://github.com/dchest/tweetnacl-js/blob/master/README.md#documentation (search for functions starting with nacl ).","title":"Crypto"},{"location":"SDK/Client Libraries/Library Modules/Crypto/#key-store","text":"The crypto module holds a set of key pairs accessible through a handle. A key pair can be added to a key store or removed from it. Once added to a keystore, a key pair gets a handle assigned to it. This handle can be used in relevant crypto functions instead of the key pair itself.","title":"Key Store"},{"location":"SDK/Client Libraries/Library Modules/Crypto/#reference-links","text":"Follow the link to our github repository to get the list of our crypto-functions: https://github.com/tonlabs/ton-client-js/blob/75270514d6e1051fe7159b7bcc79f1110ebe6d1b/types.js#L55 These functions are standard and familiar to the professional audience. For a brief guide, follow the link: https://github.com/dchest/tweetnacl-js/blob/master/README.md#documentation (search for functions starting with nacl ).","title":"Reference Links"},{"location":"SDK/Client Libraries/Library Modules/Overview/","text":"TON Labs Client Libraries provide TON Dev community with functionality that allows your applications to interact with blockchain. All functions are divided into: crypto \u2013 most cryptography functions required to work with blockchain. contracts - interaction with nodes to deploy and run smart contracts on the blockchain. queries \u2013 monitoring and querying realtime data. The functionality relies on an indexing database over blockchain. Regardless of the selected language, each library usage follows the same principles. There is a similar set of modules, functions and their respective parameters. Each TON Labs Client Library is stateful, so at the first step you have to create an instance of a TON Labs Client object, configure it and setup. Usually, all three actions are performed by a single call to the relevant TON Labs Client constructor. Visit TON Dev for additional product, company community info.","title":"Overview"},{"location":"SDK/Client Libraries/Library Modules/Queries/","text":"Use the SDK to make queries to blockchain objects. A live blockchain snapshot is accessible through an ArangoDB instance in the local node. To query it, GraphQL protocol with subscription options is implemented (get the schema at http://127.0.0.1/graphql ). All data in the database are divided into following collections: accounts : blockchain account data; transactions : transactions related to accounts; messages: input and output messages related to transactions; blocks: blockchain blocks. The structure of each collection item matches that on the TON blochchain. So, for additional details on specific fields refer to official TON documentation. The queries module of the Client library defines four objects to access each collection: accounts , transactions , messages and blocks . Each object has a set of query methods: query : filters collection items according to the requested condition. The available filtration functionality covers a wide range of tasks. If none of the collection items matches the request, an empty set is returned. waitFor : same as above, but this method never returns until the requested item appears (i.e. it actually waits). subscribe : starts monitoring the relevant blockchain for items matching the requests. The subscription monitors all insert and update operations. Making queries To perform a query over the relevant blockchain, choose a collection and then specify a filter, result projection, sorting order and the maximum number of items in the results list. const transactions = await client.queries.transactions.query({ now: { eq: 1567601735 } }, 'id now status'); The example above demonstrates a query to the transactions collection with the following parameters: filter : a JSON object matching the internal collection structure. It supports additional conditions for particular fields. In the example above, the now field of a transaction must be equal to 1567601735. result : is a result projection that deter structural subset used for returning items. In the example above the request is limited to three fields: id , now and status . Note that results have to follow GraphQL rules. Given that the now field is unique in the example, the transactions array is either empty or contains one item. The waitFor method can be used to obtain items that are not yet written to the blockchain but are expected to appear. const transactions = await client.queries.transactions.waitFor({ now: { eq: 1567601735 } }, 'id now status'); The signature of the waitFor is exactly the same as for the query . The only difference is behavior: if there is no transaction with the specified now in the requested blockchain, this method waits indefinitely until the transaction appears in the blockchain. Subscriptions Some applications monitor blockchain for a specific data set or for potential updates. The subscribe method (included in collection object) handles these scenarios: const subscription = client.queries.blocks.subscribe({}, 'id', (e, doc) = { console.log('On block have created: ', doc); }); setTimeout(() = { subscription.unsubscribe(); resolve(); }, 10*60*1000); In this example, we start a subscription and react whenever a block is inserted or updated in the relevant blockchain. The filter and result parameters are the same as in the query method. The filter parameter narrows the action down to a subset of monitored items. In this case, the filter is empty: all items are included into monitoring. The last parameter is an event handler. This event is triggered every time the monitored block is inserted or updated in the relevant blockchain. The return value of the subscribe method is a subscription object with one available method: unsubscribe . The subscription remains active until it is called. In the example above the subscription is cancelled within 10 min. Filtration and sorting Filters applied to querying functions are data structures matching collection items with several extra features: The value for scalar fields (e.g. strings, numbers etc.) is a structure with the scalar filter. The value for array fields is a structure with an array filter. The value for nested structures is a filter for nested structure. Scalar filters Scalar filter is a structure with one or more predefined fields. Each field defines a specific scalar operation and a reference value: eq : item value must be equal to the specified value; ne : item value must not be equal to the specified value; gt : item value must be greater than the specified value; lt : item value must be less than specified value; ge : item value must be greater than or equal to the specified value; le : item value must be less than or equal to the specified value; in : item value must be contained in the specified array of values; notIn : item value must not be contained within the specified array of values. Filter example: { id: { eq: 'e19948d53c4fc8d405fbb8bde4af83039f37ce6bc9d0fc07bbd47a1cf59a8465'}, status: { in: [ Preliminary , Proposed , Finalized ] } } Note that when a scalar filter for a field contains multiple operators, the AND logical operator is used to combine all the conditions: { now: { gt: 1563449, lt: 2063449 } } The logic from the above snippet can be expressed in the following way: (transaction.now 1563449) (transaction.now 2063449) Array filters Array filters are used for array (list) fields. Each has to contain at least one of the predefined operators: any : used when at least one array item matches the nested filter; all : used when all items matches the nested filter. The any or all must contain a nested filter for an array item. Array operators are mutually exclusive and can not be combined. For empty arrays, the array filter is assumed to be false. Structure filters If an item is a structure, then a filter has to contain fields named as fields of this item. Each nested filter field contains a condition for the appropriate field of an item. The AND operator is used to combine conditions for several fields. Joins The NoSQL database contains additional fields that work as cross-references for related collections. For example, the transactions collection has the in_message field that stores the relevant message item. The message item exists in messages collection and has the id value equal to the in_msg value in transactions . Joined items are represented as nested structures in a filter and in the result projection. Sorting and limiting By default, retrieval order for several items is not defined. To specify it, use the orderBy parameter of query method. The sort order is represented by an array or sort descriptors. These structures contain two fields: path and direction : path specifies a path from a root item of the collection to the field that determines the order of return items. The path includes field names separated by dot. direction specifies the sorting order: ASC or DESC (ascending and descending). You can specify more than one field to define an order. If two items have equal values for the first sort descriptor, then second descriptor is used for comparison, etc. If values of sorting fields are the same for several items, then the order of these items is not defined. The limit parameter determines the maximum number of items returned. This parameter has a default value of 50 and can not exceed it. If specified limit exceeds 50, 50 is used. Special fields Each items in each collection has a unique key stored in the id field. This ID is the same as the item blockchain identifier. Variability and Nested Levels GraphQL is designed to search for entities similar to documents. In our case these entities are represented by the above mentioned collections. Obviously, each entity may have a set of fields. A field can be used as a filter. But, some complex fields (e.g. a message header) also include fields (values) and whole structures. These enclosed fields are not consistent even within a single collection. Therefore, you cannot make a query that is filtered by, say, header field alone. You have to build a complex query that drills down to \u0430 particular scalar field or field with primitive value (string, number or boolean) at the bottom level of the whole nested structure. As mentioned before, field structures may depend on document type or other conditions. In this case we have to use the GraphQL 'union' type which means that a value can have one of alternative types. For example the message header field depends on message type: internal, external inbound or external outbound, so we have three alternative variants for message header structure with three fields in the header ( MsgInt , MsgExtIn or MsgExtOut ). In the projection part of GraphQl queries we can use ' ...on ' syntax to specify a result set for every variant at any level. Thus, the sample implies two nested levels and the number is unlimited. you can drill down as deep, as needed. ...on field_name { field_name { filter_value } } Once you type ...on , autocomplete hints appear. See the usage example below. query{ messages(filter: { header: { IntMsgInfo: { created_lt: { gt: 281 } }, } }, orderBy: [{path: header.IntMsgInfo.created_lt , direction: ASC}]) { id header { ...on MessageHeaderIntMsgInfoVariant { IntMsgInfo { created_lt } } } } } We see that the existing approach and schema are not perfect. There are improvement options and wee seek to implement them.","title":"Queries"},{"location":"SDK/Client Libraries/Library Modules/Queries/#making-queries","text":"To perform a query over the relevant blockchain, choose a collection and then specify a filter, result projection, sorting order and the maximum number of items in the results list. const transactions = await client.queries.transactions.query({ now: { eq: 1567601735 } }, 'id now status'); The example above demonstrates a query to the transactions collection with the following parameters: filter : a JSON object matching the internal collection structure. It supports additional conditions for particular fields. In the example above, the now field of a transaction must be equal to 1567601735. result : is a result projection that deter structural subset used for returning items. In the example above the request is limited to three fields: id , now and status . Note that results have to follow GraphQL rules. Given that the now field is unique in the example, the transactions array is either empty or contains one item. The waitFor method can be used to obtain items that are not yet written to the blockchain but are expected to appear. const transactions = await client.queries.transactions.waitFor({ now: { eq: 1567601735 } }, 'id now status'); The signature of the waitFor is exactly the same as for the query . The only difference is behavior: if there is no transaction with the specified now in the requested blockchain, this method waits indefinitely until the transaction appears in the blockchain.","title":"Making queries"},{"location":"SDK/Client Libraries/Library Modules/Queries/#subscriptions","text":"Some applications monitor blockchain for a specific data set or for potential updates. The subscribe method (included in collection object) handles these scenarios: const subscription = client.queries.blocks.subscribe({}, 'id', (e, doc) = { console.log('On block have created: ', doc); }); setTimeout(() = { subscription.unsubscribe(); resolve(); }, 10*60*1000); In this example, we start a subscription and react whenever a block is inserted or updated in the relevant blockchain. The filter and result parameters are the same as in the query method. The filter parameter narrows the action down to a subset of monitored items. In this case, the filter is empty: all items are included into monitoring. The last parameter is an event handler. This event is triggered every time the monitored block is inserted or updated in the relevant blockchain. The return value of the subscribe method is a subscription object with one available method: unsubscribe . The subscription remains active until it is called. In the example above the subscription is cancelled within 10 min.","title":"Subscriptions"},{"location":"SDK/Client Libraries/Library Modules/Queries/#filtration-and-sorting","text":"Filters applied to querying functions are data structures matching collection items with several extra features: The value for scalar fields (e.g. strings, numbers etc.) is a structure with the scalar filter. The value for array fields is a structure with an array filter. The value for nested structures is a filter for nested structure.","title":"Filtration and sorting"},{"location":"SDK/Client Libraries/Library Modules/Queries/#scalar-filters","text":"Scalar filter is a structure with one or more predefined fields. Each field defines a specific scalar operation and a reference value: eq : item value must be equal to the specified value; ne : item value must not be equal to the specified value; gt : item value must be greater than the specified value; lt : item value must be less than specified value; ge : item value must be greater than or equal to the specified value; le : item value must be less than or equal to the specified value; in : item value must be contained in the specified array of values; notIn : item value must not be contained within the specified array of values. Filter example: { id: { eq: 'e19948d53c4fc8d405fbb8bde4af83039f37ce6bc9d0fc07bbd47a1cf59a8465'}, status: { in: [ Preliminary , Proposed , Finalized ] } } Note that when a scalar filter for a field contains multiple operators, the AND logical operator is used to combine all the conditions: { now: { gt: 1563449, lt: 2063449 } } The logic from the above snippet can be expressed in the following way: (transaction.now 1563449) (transaction.now 2063449)","title":"Scalar filters"},{"location":"SDK/Client Libraries/Library Modules/Queries/#array-filters","text":"Array filters are used for array (list) fields. Each has to contain at least one of the predefined operators: any : used when at least one array item matches the nested filter; all : used when all items matches the nested filter. The any or all must contain a nested filter for an array item. Array operators are mutually exclusive and can not be combined. For empty arrays, the array filter is assumed to be false.","title":"Array filters"},{"location":"SDK/Client Libraries/Library Modules/Queries/#structure-filters","text":"If an item is a structure, then a filter has to contain fields named as fields of this item. Each nested filter field contains a condition for the appropriate field of an item. The AND operator is used to combine conditions for several fields.","title":"Structure filters"},{"location":"SDK/Client Libraries/Library Modules/Queries/#joins","text":"The NoSQL database contains additional fields that work as cross-references for related collections. For example, the transactions collection has the in_message field that stores the relevant message item. The message item exists in messages collection and has the id value equal to the in_msg value in transactions . Joined items are represented as nested structures in a filter and in the result projection.","title":"Joins"},{"location":"SDK/Client Libraries/Library Modules/Queries/#sorting-and-limiting","text":"By default, retrieval order for several items is not defined. To specify it, use the orderBy parameter of query method. The sort order is represented by an array or sort descriptors. These structures contain two fields: path and direction : path specifies a path from a root item of the collection to the field that determines the order of return items. The path includes field names separated by dot. direction specifies the sorting order: ASC or DESC (ascending and descending). You can specify more than one field to define an order. If two items have equal values for the first sort descriptor, then second descriptor is used for comparison, etc. If values of sorting fields are the same for several items, then the order of these items is not defined. The limit parameter determines the maximum number of items returned. This parameter has a default value of 50 and can not exceed it. If specified limit exceeds 50, 50 is used.","title":"Sorting and limiting"},{"location":"SDK/Client Libraries/Library Modules/Queries/#special-fields","text":"Each items in each collection has a unique key stored in the id field. This ID is the same as the item blockchain identifier.","title":"Special fields"},{"location":"SDK/Client Libraries/Library Modules/Queries/#variability-and-nested-levels","text":"GraphQL is designed to search for entities similar to documents. In our case these entities are represented by the above mentioned collections. Obviously, each entity may have a set of fields. A field can be used as a filter. But, some complex fields (e.g. a message header) also include fields (values) and whole structures. These enclosed fields are not consistent even within a single collection. Therefore, you cannot make a query that is filtered by, say, header field alone. You have to build a complex query that drills down to \u0430 particular scalar field or field with primitive value (string, number or boolean) at the bottom level of the whole nested structure. As mentioned before, field structures may depend on document type or other conditions. In this case we have to use the GraphQL 'union' type which means that a value can have one of alternative types. For example the message header field depends on message type: internal, external inbound or external outbound, so we have three alternative variants for message header structure with three fields in the header ( MsgInt , MsgExtIn or MsgExtOut ). In the projection part of GraphQl queries we can use ' ...on ' syntax to specify a result set for every variant at any level. Thus, the sample implies two nested levels and the number is unlimited. you can drill down as deep, as needed. ...on field_name { field_name { filter_value } } Once you type ...on , autocomplete hints appear. See the usage example below. query{ messages(filter: { header: { IntMsgInfo: { created_lt: { gt: 281 } }, } }, orderBy: [{path: header.IntMsgInfo.created_lt , direction: ASC}]) { id header { ...on MessageHeaderIntMsgInfoVariant { IntMsgInfo { created_lt } } } } } We see that the existing approach and schema are not perfect. There are improvement options and wee seek to implement them.","title":"Variability and Nested Levels"},{"location":"SDK/Client Libraries/Using Libraries/Node.js/","text":"Follow guidelines in this section to create your own environment based on Node.js with the Node SE tools and to develop your first test contract. First and foremost, create a local folder for all your test projects. Note that in this documentation the sample folder is called ton-dev . If your folder has a different name, make sure to edit the code accordingly. Creating a contract Create \"hello\" folder and place the \"hello.sol\" contract source code into it: pragma solidity =0.5.0 0.6.0; contract HelloTON { uint32 deployTime; constructor() public { deployTime = uint32(now); } function sayHello() public view returns (uint32) { return deployTime; } } \u200b Call cd hello to navigate to the new folder. Run TON labs Sol2TVM compiler: tondev sol hello -l js -L deploy -l js option is used to generate JavaScript client helper code for the compiled contract. -L deploy is used to include an imageBase64 field into the generated JavaScript contract client code. Creating an app Before being able to play with a smart contract on the blockchain, we need a blockchain infrastructure for contract testing and debugging. Make sure that you started a local node instance according to the guidelines provided in the Installation section. tondev start Let's start with Node.js to show how to build a test application, deploy and run its smart contract. Note: To create an application according to this procedure, you have to install Node.js. It is recommended to have the latest version. Let's initialize a Node.js application: ~/ton-dev/hello$ touch index.js ~/ton-dev/hello$ npm init Add a section to package.json: dependencies : { ton-client-node-js : ^0.12.1 } Then execute (in the project folder): ~/ton-dev/hello$ npm install \\2. Connect to Node SE or to TON Labs testnet. In JS Client Libraries the TONClient class is used to connect to TON Blockchain node, that can work with SDK. If you use the local node (NodeSE), specify ' http://0.0.0.0 ' in the following code: const client = new TONClient(); client.config.setData({ servers: [' http://0.0.0.0 '] }); Important : for Windows use http://127.0.0.1/ or http://localhost . If you use TON Labs testnet, specify: servers: ['Node URL']. For testing we use ' https://testnet.ton.dev ' : const client = new TONClient(); client.config.setData({ servers: [' https://https://testnet.ton.dev '] }); In JS Client you can simultaneously use several nodes. Create a separate TONClient object for each connection. Open the \"index.js\" file in your preferred editor and enter the code below. const { TONClient } = require('ton-client-node-js'); async function main(client) { } (async () = { try { const client = new TONClient(); client.config.setData({ servers: ['NodeSE/Testnet URL'] }); await client.setup(); await main(client); console.log('Hello TON Done'); process.exit(0); } catch (error) { console.error(error); } })(); Run the client app as follows: ~/ton-dev/hello$ node index.js Hello TON Done ~/ton-dev/hello$ Deployment Before a contract is deployed, it has to be defined in your node.js application. The necessary elements are: a compatible TVM code and an ABI structure. Both elements were obtained at the compilation stage before in the helloPackage.js file. Tip : For more details on the ABI, see the specification . For deployment, you also have to take the following steps: Generate the key pair. Each time a contract is deployed, you can generate keys with a built-in ton.crypto.ed25519Keypair crypto module. Or use pre-generated keys to get predictable results. It is the option used for this example: { public: '55d7bab463a6a3ef5e03bb5f975836ddfb589b9ccb00329be7da8ea981c5268a', secret: 'de93a97c7103c2d44e47972265cfdfe266fd28c8cadc4875804ee9f57cf786d6', } Switch to your test app source code to declare a smart contract package and the relevant key pair: ... // Define contract package const HelloContract = require('./helloContract'); // Define keys for our contract const helloKeys = { public: '55d7bab463a6a3ef5e03bb5f975836ddfb589b9ccb00329be7da8ea981c5268a', secret: 'de93a97c7103c2d44e47972265cfdfe266fd28c8cadc4875804ee9f57cf786d6', }; async function main(client) { } ... The contract is almost ready for deployment, but in TON blockchain you must deposit GRAMs to the address of the deployed contract before the actual deploy . Otherwise deploy will fail. You can send Grams from another contract or use our giver. To learn how to use giver, check the relevant section in the document covering the Contracts module. There is a detailed usage example. ... async function main(client) { const helloAddress = (await client.contracts.deploy({ package: HelloContract.package, constructorParams: {}, keyPair: helloKeys, })).address; console.log(`Hello contract was deployed at address: ${helloAddress}`); } ... Now run to check how it works. ~/ton-dev/hello$ node index.js Hello contract was deployed at address: 516c7a2bc72c5728526eb73064da07a2876d964c3da5ed2488e1aba3da20be3f ~/ton-dev/hello$ Running a contract Running your contract on blockchain is also quite simple ... async function main(client) { const helloAddress = (await client.contracts.deploy({ package: HelloContract.package, constructorParams: {}, keyPair: helloKeys, })).address; console.log(`Hello contract was deployed at address: ${helloAddress}`); const response = await client.contracts.run({ address: helloAddress, abi: HelloContract.package.abi, functionName: 'sayHello', input: {}, keyPair: helloKeys, }); console.log('Hello contract was responded to sayHello:', response); } ... Now run the app: ~/ton-dev/hello$ node index.js Hello contract was deployed at address: 516c7a2bc72c5728526eb73064da07a2876d964c3da5ed2488e1aba3da20be3f Hello contract was responded to sayHello: { output: { value0: '0x5d6fba2e' } } Hello TON Done ~/ton-dev/hello$ Alternatively, you can run a contract in the TVM instance included into a client library without interaction with TVM node: ... async function main(client) { const helloAddress = (await client.contracts.deploy({ package: HelloContract.package, constructorParams: {}, keyPair: helloKeys, })).address; console.log(`Hello contract was deployed at address: ${helloAddress}`); const response = await client.contracts.run({ address: helloAddress, abi: HelloContract.package.abi, functionName: 'sayHello', input: {}, keyPair: helloKeys, }); console.log('Hello contract was responded to sayHello:', response); const localResponse = await client.contracts.runLocal({ address: helloAddress, abi: HelloContract.package.abi, functionName: 'sayHello', input: {}, keyPair: helloKeys, }); console.log('Hello contract was ran on a client TVM and also responded to sayHello:', localResponse); } ... Run: ~/ton-dev/hello$ node index.js Hello contract was deployed at address: 516c7a2bc72c5728526eb73064da07a2876d964c3da5ed2488e1aba3da20be3f Hello contract was responded to sayHello: { output: { value0: '0x5d6fba2e' } } Hello contract was ran on a client TVM and also responded to sayHello: { output: { value0: '0x5d6fba2e' } } Hello TON Done ~/ton-dev/hello$ Find more information about deploying and running in the Contracts section. Querying blockchain Each node server is equipped with a database that tracks the relevant blockchain. This database is accessible through a GraphQL based protocol for querying blockchain. The Client library contains the Query Module designed to perform GraphQL queries over a blockchain. The simplest way to query a blockchain is using the following query method: async function queries(client) { const transactions = await client.queries.transactions.query({}, 'id now status'); console.log('All Transactions: ', transactions); } Then all transactions in the relevant blockchain are displayed (the first 50, to be precise). 50 is the default number used when no limit is specified or when it exceeds 50. For each transaction, we have three result fields: id , now and status . We have several options to filter the results: const transactions = await client.queries.transactions.query({ now: { eq: 1567601735 } }, 'id now status'); console.log('Filtered Transactions: ', transactions); The example gets all transactions with now equals to 1567601735. Find more information about a filtering in the Queries section.","title":"Node.js"},{"location":"SDK/Client Libraries/Using Libraries/Node.js/#creating-a-contract","text":"Create \"hello\" folder and place the \"hello.sol\" contract source code into it: pragma solidity =0.5.0 0.6.0; contract HelloTON { uint32 deployTime; constructor() public { deployTime = uint32(now); } function sayHello() public view returns (uint32) { return deployTime; } } \u200b Call cd hello to navigate to the new folder. Run TON labs Sol2TVM compiler: tondev sol hello -l js -L deploy -l js option is used to generate JavaScript client helper code for the compiled contract. -L deploy is used to include an imageBase64 field into the generated JavaScript contract client code.","title":"Creating a contract"},{"location":"SDK/Client Libraries/Using Libraries/Node.js/#creating-an-app","text":"Before being able to play with a smart contract on the blockchain, we need a blockchain infrastructure for contract testing and debugging. Make sure that you started a local node instance according to the guidelines provided in the Installation section. tondev start Let's start with Node.js to show how to build a test application, deploy and run its smart contract. Note: To create an application according to this procedure, you have to install Node.js. It is recommended to have the latest version. Let's initialize a Node.js application: ~/ton-dev/hello$ touch index.js ~/ton-dev/hello$ npm init Add a section to package.json: dependencies : { ton-client-node-js : ^0.12.1 } Then execute (in the project folder): ~/ton-dev/hello$ npm install \\2. Connect to Node SE or to TON Labs testnet. In JS Client Libraries the TONClient class is used to connect to TON Blockchain node, that can work with SDK. If you use the local node (NodeSE), specify ' http://0.0.0.0 ' in the following code: const client = new TONClient(); client.config.setData({ servers: [' http://0.0.0.0 '] }); Important : for Windows use http://127.0.0.1/ or http://localhost . If you use TON Labs testnet, specify: servers: ['Node URL']. For testing we use ' https://testnet.ton.dev ' : const client = new TONClient(); client.config.setData({ servers: [' https://https://testnet.ton.dev '] }); In JS Client you can simultaneously use several nodes. Create a separate TONClient object for each connection. Open the \"index.js\" file in your preferred editor and enter the code below. const { TONClient } = require('ton-client-node-js'); async function main(client) { } (async () = { try { const client = new TONClient(); client.config.setData({ servers: ['NodeSE/Testnet URL'] }); await client.setup(); await main(client); console.log('Hello TON Done'); process.exit(0); } catch (error) { console.error(error); } })(); Run the client app as follows: ~/ton-dev/hello$ node index.js Hello TON Done ~/ton-dev/hello$","title":"Creating an app"},{"location":"SDK/Client Libraries/Using Libraries/Node.js/#deployment","text":"Before a contract is deployed, it has to be defined in your node.js application. The necessary elements are: a compatible TVM code and an ABI structure. Both elements were obtained at the compilation stage before in the helloPackage.js file. Tip : For more details on the ABI, see the specification . For deployment, you also have to take the following steps: Generate the key pair. Each time a contract is deployed, you can generate keys with a built-in ton.crypto.ed25519Keypair crypto module. Or use pre-generated keys to get predictable results. It is the option used for this example: { public: '55d7bab463a6a3ef5e03bb5f975836ddfb589b9ccb00329be7da8ea981c5268a', secret: 'de93a97c7103c2d44e47972265cfdfe266fd28c8cadc4875804ee9f57cf786d6', } Switch to your test app source code to declare a smart contract package and the relevant key pair: ... // Define contract package const HelloContract = require('./helloContract'); // Define keys for our contract const helloKeys = { public: '55d7bab463a6a3ef5e03bb5f975836ddfb589b9ccb00329be7da8ea981c5268a', secret: 'de93a97c7103c2d44e47972265cfdfe266fd28c8cadc4875804ee9f57cf786d6', }; async function main(client) { } ... The contract is almost ready for deployment, but in TON blockchain you must deposit GRAMs to the address of the deployed contract before the actual deploy . Otherwise deploy will fail. You can send Grams from another contract or use our giver. To learn how to use giver, check the relevant section in the document covering the Contracts module. There is a detailed usage example. ... async function main(client) { const helloAddress = (await client.contracts.deploy({ package: HelloContract.package, constructorParams: {}, keyPair: helloKeys, })).address; console.log(`Hello contract was deployed at address: ${helloAddress}`); } ... Now run to check how it works. ~/ton-dev/hello$ node index.js Hello contract was deployed at address: 516c7a2bc72c5728526eb73064da07a2876d964c3da5ed2488e1aba3da20be3f ~/ton-dev/hello$","title":"Deployment"},{"location":"SDK/Client Libraries/Using Libraries/Node.js/#running-a-contract","text":"Running your contract on blockchain is also quite simple ... async function main(client) { const helloAddress = (await client.contracts.deploy({ package: HelloContract.package, constructorParams: {}, keyPair: helloKeys, })).address; console.log(`Hello contract was deployed at address: ${helloAddress}`); const response = await client.contracts.run({ address: helloAddress, abi: HelloContract.package.abi, functionName: 'sayHello', input: {}, keyPair: helloKeys, }); console.log('Hello contract was responded to sayHello:', response); } ... Now run the app: ~/ton-dev/hello$ node index.js Hello contract was deployed at address: 516c7a2bc72c5728526eb73064da07a2876d964c3da5ed2488e1aba3da20be3f Hello contract was responded to sayHello: { output: { value0: '0x5d6fba2e' } } Hello TON Done ~/ton-dev/hello$ Alternatively, you can run a contract in the TVM instance included into a client library without interaction with TVM node: ... async function main(client) { const helloAddress = (await client.contracts.deploy({ package: HelloContract.package, constructorParams: {}, keyPair: helloKeys, })).address; console.log(`Hello contract was deployed at address: ${helloAddress}`); const response = await client.contracts.run({ address: helloAddress, abi: HelloContract.package.abi, functionName: 'sayHello', input: {}, keyPair: helloKeys, }); console.log('Hello contract was responded to sayHello:', response); const localResponse = await client.contracts.runLocal({ address: helloAddress, abi: HelloContract.package.abi, functionName: 'sayHello', input: {}, keyPair: helloKeys, }); console.log('Hello contract was ran on a client TVM and also responded to sayHello:', localResponse); } ... Run: ~/ton-dev/hello$ node index.js Hello contract was deployed at address: 516c7a2bc72c5728526eb73064da07a2876d964c3da5ed2488e1aba3da20be3f Hello contract was responded to sayHello: { output: { value0: '0x5d6fba2e' } } Hello contract was ran on a client TVM and also responded to sayHello: { output: { value0: '0x5d6fba2e' } } Hello TON Done ~/ton-dev/hello$ Find more information about deploying and running in the Contracts section.","title":"Running a contract"},{"location":"SDK/Client Libraries/Using Libraries/Node.js/#querying-blockchain","text":"Each node server is equipped with a database that tracks the relevant blockchain. This database is accessible through a GraphQL based protocol for querying blockchain. The Client library contains the Query Module designed to perform GraphQL queries over a blockchain. The simplest way to query a blockchain is using the following query method: async function queries(client) { const transactions = await client.queries.transactions.query({}, 'id now status'); console.log('All Transactions: ', transactions); } Then all transactions in the relevant blockchain are displayed (the first 50, to be precise). 50 is the default number used when no limit is specified or when it exceeds 50. For each transaction, we have three result fields: id , now and status . We have several options to filter the results: const transactions = await client.queries.transactions.query({ now: { eq: 1567601735 } }, 'id now status'); console.log('Filtered Transactions: ', transactions); The example gets all transactions with now equals to 1567601735. Find more information about a filtering in the Queries section.","title":"Querying blockchain"},{"location":"SDK/Client Libraries/Using Libraries/Rust/","text":"Make sure to create a local folder for all your test projects. Creating a contract Create the \"hello\" folder and place the \"hello.sol\" contract source code into it: pragma solidity =0.5.0 0.6.0; contract HelloTON { uint32 deployTime; constructor() public { deployTime = uint32(now); } function sayHello() public view returns (uint32) { return deployTime; } } Call cd hello to navigate to the new folder. Run the TON Labs Solidity compiler: tondev sol hello Creating an app To get a functional playground, we need blockchain infrastructure for contract testing and debugging. We suggest using our Node SE. Make sure that you ran a Node SE instant according to the guidelines provided in the Installation section. tondev start Note: To create an application according to this procedure, you have to install the newest Rust compiler. Initialize a Rust application in the hello directory: ~/ton-dev/hello$ cargo init Created binary (application) package Open the newly created Cargo.toml file in your preferred editor and add following line to the [dependencies] section: ton-client-rs = 0.11.1 It enables using TON SDK Client package in your hello project. Connect to the local node (Node SE) or to TON Labs testnet. In Rust Client Libraries the TONClient class is used to connect to TON Blockchain nodes that can work with SDK. If you use Node SE, specify new_with_base_url(\" http://0.0.0.0 \") (local URL). Important : for Windows use http://127.0.0.1/ or http://localhost . If you use the testnet, specify its URL. For test purposes, use Ton Labs test net URL new_with_base_url(' https://testnet.ton.dev ') Go to the main.rs file in hello/src and paste the following code into it: extern crate ton_client_rs; use ton_client_rs::TonClient; fn main() { let ton = TonClient::new_with_base_url( NodeSE/testnet URL ).expect( Couldn't create TonClient ); println!( Hello TON Done ); } Run the client app from hello directory: ~/ton-dev/hello$ cargo run ... Running `target\\\\debug\\\\hello.exe` Hello TON Done ~/ton-dev/hello$ Generate keys to sign the deploy transaction using ton_client.crypto.generate_ed25519_keys() function: extern crate ton_client_rs; use ton_client_rs::TonClient; fn main() { let ton = TonClient::new_with_base_url( http://0.0.0.0 ).expect( Couldn't create TonClient ); play_with_ton(ton); println!( Hello TON Done ); } fn play_with_ton(ton_client: TonClient) { let keys = ton_client.crypto.generate_ed25519_keys().expect( Couldn't create key pair ); println!( Generated keys: {}:{} , keys.secret, keys.public); } Deployment Before a contract can be deployed, the application needs retrieve: a compatible TVM code and an ABI structure. Both elements were obtained at the compilation stage and stored in the hello.tvc and hello.abi.json . Tip : For more details on the ABI, see the specification . Below is the final contract deployment code: ... fn play_with_ton(ton_client: TonClient) { let keys = ton_client.crypto.generate_ed25519_keys().expect( Couldn't create key pair ); println!( Generated keys:\\n{}\\n{} , keys.secret, keys.public); let code = std::fs::read( hello.tvc ).expect( Couldn't read code file ); let abi = std::fs::read_to_string( hello.abi.json ).expect( Couldn't read ABI file ); let address = ton_client.contracts.deploy( abi, code, {} .into(), keys) .expect( Couldn't deploy contract ); println!( Hello contract was deployed at address: {} , address); } ... Run the contract to see how it works. ~/ton-dev/hello$ cargo run ... Running `target\\\\debug\\\\hello.exe` Generated keys: 4236d45d544eccd16b16dea85f8aa201a7edfee06bb7f3e307c0ec02f9cb35ef 02154a29510c8bf29c4b4998e6510f60f224ab566eefaeaa9df22d7a90297b7e Hello contract was deployed at address: b2a0d72b81d2cfae8bd3e7dc60c20a9f478570b8bea749318ff84fa0bd46d6bd Hello TON Done ~/ton-dev/hello$ Running a contract Run your contract; it is also quite simple: ... fn play_with_ton(ton_client: TonClient) { let keys = ton_client.crypto.generate_ed25519_keys().expect( Couldn't create key pair ); println!( Generated keys:\\\\n{}\\\\n{} , keys.secret, keys.public); let code = std::fs::read( hello.tvc ).expect( Couldn't read code file ); let abi = std::fs::read_to_string( hello.abi.json ).expect( Couldn't read ABI file ); let address = ton_client.contracts.deploy( abi, code, {} .into(), keys) .expect( Couldn't deploy contract ); println!( Hello contract was deployed at address: {} , address); let response = ton_client.contracts.run( address, abi, sayHello , {} .into(), Some( keys)) .expect( Couldn't run contract ); println!( Hello contract was responded to sayHello: {} , response); } ... Then run the app: ~/ton-dev/hello$ cargo run ... Running `target\\\\debug\\\\hello.exe` Generated keys: a7571d6041d45c261759caa04f73034396bf1a3aa35f092d5eb83a407f8284f8 1fcf08942290cf190287659f078199b0901e9403d852142f241c630e9b1ca6b3 Hello contract was deployed at address: d8634d6164b02c3a6c1447c505147ca1dde6149ba02b61f9eb21915d62467fde Hello contract was responded to sayHello: { value0 : 0x5d78a4c7 } Hello TON Done ~/ton-dev/hello$ You can find more information about deploying and running in the Working with contracts section. Querying blockchain Each node server is equipped with a database that tracks the relevant blockchain. This database is accessible through a GraphQL based protocol for querying blockchain. The Client library contains the Query Module designed to perform GraphQL queries over a blockchain. The simplest way to query a blockchain is using the following query method: const TRANSACTION_FIELDS: str = r# id now status #; let query_result = ton.queries.transactions.query( json!({}).to_string(), TRANSACTION_FIELDS).unwrap(); println(query_result); Then all transactions in the relevant blockchain are displayed (the first 50, to be precise). 50 is the default number used when no limit is specified or when it exceeds 50. For each transaction, we have three result fields: id , now and status . We have several options to filter the results: const TRANSACTION_FIELDS: str = r# id now status #; let query_result = ton.queries.transactions.query( json!({ now : { eq : 1567601735 } }).to_string(), TRANSACTION_FIELDS).unwrap(); The example gets all transactions with now equals to 1567601735. Find more information about a filtering in the Queries section.","title":"Rust"},{"location":"SDK/Client Libraries/Using Libraries/Rust/#creating-a-contract","text":"Create the \"hello\" folder and place the \"hello.sol\" contract source code into it: pragma solidity =0.5.0 0.6.0; contract HelloTON { uint32 deployTime; constructor() public { deployTime = uint32(now); } function sayHello() public view returns (uint32) { return deployTime; } } Call cd hello to navigate to the new folder. Run the TON Labs Solidity compiler: tondev sol hello","title":"Creating a contract"},{"location":"SDK/Client Libraries/Using Libraries/Rust/#creating-an-app","text":"To get a functional playground, we need blockchain infrastructure for contract testing and debugging. We suggest using our Node SE. Make sure that you ran a Node SE instant according to the guidelines provided in the Installation section. tondev start Note: To create an application according to this procedure, you have to install the newest Rust compiler. Initialize a Rust application in the hello directory: ~/ton-dev/hello$ cargo init Created binary (application) package Open the newly created Cargo.toml file in your preferred editor and add following line to the [dependencies] section: ton-client-rs = 0.11.1 It enables using TON SDK Client package in your hello project. Connect to the local node (Node SE) or to TON Labs testnet. In Rust Client Libraries the TONClient class is used to connect to TON Blockchain nodes that can work with SDK. If you use Node SE, specify new_with_base_url(\" http://0.0.0.0 \") (local URL). Important : for Windows use http://127.0.0.1/ or http://localhost . If you use the testnet, specify its URL. For test purposes, use Ton Labs test net URL new_with_base_url(' https://testnet.ton.dev ') Go to the main.rs file in hello/src and paste the following code into it: extern crate ton_client_rs; use ton_client_rs::TonClient; fn main() { let ton = TonClient::new_with_base_url( NodeSE/testnet URL ).expect( Couldn't create TonClient ); println!( Hello TON Done ); } Run the client app from hello directory: ~/ton-dev/hello$ cargo run ... Running `target\\\\debug\\\\hello.exe` Hello TON Done ~/ton-dev/hello$ Generate keys to sign the deploy transaction using ton_client.crypto.generate_ed25519_keys() function: extern crate ton_client_rs; use ton_client_rs::TonClient; fn main() { let ton = TonClient::new_with_base_url( http://0.0.0.0 ).expect( Couldn't create TonClient ); play_with_ton(ton); println!( Hello TON Done ); } fn play_with_ton(ton_client: TonClient) { let keys = ton_client.crypto.generate_ed25519_keys().expect( Couldn't create key pair ); println!( Generated keys: {}:{} , keys.secret, keys.public); }","title":"Creating an app"},{"location":"SDK/Client Libraries/Using Libraries/Rust/#deployment","text":"Before a contract can be deployed, the application needs retrieve: a compatible TVM code and an ABI structure. Both elements were obtained at the compilation stage and stored in the hello.tvc and hello.abi.json . Tip : For more details on the ABI, see the specification . Below is the final contract deployment code: ... fn play_with_ton(ton_client: TonClient) { let keys = ton_client.crypto.generate_ed25519_keys().expect( Couldn't create key pair ); println!( Generated keys:\\n{}\\n{} , keys.secret, keys.public); let code = std::fs::read( hello.tvc ).expect( Couldn't read code file ); let abi = std::fs::read_to_string( hello.abi.json ).expect( Couldn't read ABI file ); let address = ton_client.contracts.deploy( abi, code, {} .into(), keys) .expect( Couldn't deploy contract ); println!( Hello contract was deployed at address: {} , address); } ... Run the contract to see how it works. ~/ton-dev/hello$ cargo run ... Running `target\\\\debug\\\\hello.exe` Generated keys: 4236d45d544eccd16b16dea85f8aa201a7edfee06bb7f3e307c0ec02f9cb35ef 02154a29510c8bf29c4b4998e6510f60f224ab566eefaeaa9df22d7a90297b7e Hello contract was deployed at address: b2a0d72b81d2cfae8bd3e7dc60c20a9f478570b8bea749318ff84fa0bd46d6bd Hello TON Done ~/ton-dev/hello$","title":"Deployment"},{"location":"SDK/Client Libraries/Using Libraries/Rust/#running-a-contract","text":"Run your contract; it is also quite simple: ... fn play_with_ton(ton_client: TonClient) { let keys = ton_client.crypto.generate_ed25519_keys().expect( Couldn't create key pair ); println!( Generated keys:\\\\n{}\\\\n{} , keys.secret, keys.public); let code = std::fs::read( hello.tvc ).expect( Couldn't read code file ); let abi = std::fs::read_to_string( hello.abi.json ).expect( Couldn't read ABI file ); let address = ton_client.contracts.deploy( abi, code, {} .into(), keys) .expect( Couldn't deploy contract ); println!( Hello contract was deployed at address: {} , address); let response = ton_client.contracts.run( address, abi, sayHello , {} .into(), Some( keys)) .expect( Couldn't run contract ); println!( Hello contract was responded to sayHello: {} , response); } ... Then run the app: ~/ton-dev/hello$ cargo run ... Running `target\\\\debug\\\\hello.exe` Generated keys: a7571d6041d45c261759caa04f73034396bf1a3aa35f092d5eb83a407f8284f8 1fcf08942290cf190287659f078199b0901e9403d852142f241c630e9b1ca6b3 Hello contract was deployed at address: d8634d6164b02c3a6c1447c505147ca1dde6149ba02b61f9eb21915d62467fde Hello contract was responded to sayHello: { value0 : 0x5d78a4c7 } Hello TON Done ~/ton-dev/hello$ You can find more information about deploying and running in the Working with contracts section.","title":"Running a contract"},{"location":"SDK/Client Libraries/Using Libraries/Rust/#querying-blockchain","text":"Each node server is equipped with a database that tracks the relevant blockchain. This database is accessible through a GraphQL based protocol for querying blockchain. The Client library contains the Query Module designed to perform GraphQL queries over a blockchain. The simplest way to query a blockchain is using the following query method: const TRANSACTION_FIELDS: str = r# id now status #; let query_result = ton.queries.transactions.query( json!({}).to_string(), TRANSACTION_FIELDS).unwrap(); println(query_result); Then all transactions in the relevant blockchain are displayed (the first 50, to be precise). 50 is the default number used when no limit is specified or when it exceeds 50. For each transaction, we have three result fields: id , now and status . We have several options to filter the results: const TRANSACTION_FIELDS: str = r# id now status #; let query_result = ton.queries.transactions.query( json!({ now : { eq : 1567601735 } }).to_string(), TRANSACTION_FIELDS).unwrap(); The example gets all transactions with now equals to 1567601735. Find more information about a filtering in the Queries section.","title":"Querying blockchain"},{"location":"SDK/Local node/Local Node/","text":"TON Labs Local Node is a pre-configured Docker image with a simplified standalone node server instance designed only for debugging and testing. Note: TON Labs Local Node is not designed to interact with the regular TON network.","title":"Local Node"},{"location":"SDK/Local node/Node SE Giver/","text":"If you are using the local node (Node SE) for your projects, you can use its pre-deployed Giver to transfer Grams, deploy and run other contracts. On the start Node SE giver has 1.5 billion Grams when you first create the Node container. In the course of usage, the balance dries, so to restore it, you have to recreate the container with tondev CLI recreate command To access Node SE pre-deployed giver, use this address and ABI in your projects: const nodeSeGiverAddress = 'a46af093b38fcae390e9af5104a93e22e82c29bcb35bf88160e4478417028884'; const nodeSeGiverAbi = { ABI version : 1, functions : [ { name : constructor , inputs : [ ], outputs : [ ] }, { name : sendGrams , inputs : [ { name : dest , type : uint256 }, { name : amount , type : uint64 } ], outputs : [ ] } ], events : [ ], data : [ ] }; Usage example Check it on our ton-client-js tests. Declare get_grams_from_giver function, and then invoke it to transfer grams to account that you need. async function get_grams_from_giver(account) { const { contracts, queries } = tests.client; const result = await contracts.run({ address: nodeSeGiverAddress, functionName: 'sendGrams', abi: nodeSeGiverAbi, input: { dest: `0x${account}`, amount: 500000000 }, keyPair: null, }); } For your information we demonstrate the Giver's solidity code here: pragma solidity =0.5.0 0.6.0; contract Giver { constructor() public {} function sendGrams(address payable dest, uint64 amount) public { require(address(this).balance amount, 60); dest.transfer(amount); } }","title":"Node SE Giver"},{"location":"SDK/Local node/Node SE Giver/#usage-example","text":"Check it on our ton-client-js tests. Declare get_grams_from_giver function, and then invoke it to transfer grams to account that you need. async function get_grams_from_giver(account) { const { contracts, queries } = tests.client; const result = await contracts.run({ address: nodeSeGiverAddress, functionName: 'sendGrams', abi: nodeSeGiverAbi, input: { dest: `0x${account}`, amount: 500000000 }, keyPair: null, }); } For your information we demonstrate the Giver's solidity code here: pragma solidity =0.5.0 0.6.0; contract Giver { constructor() public {} function sendGrams(address payable dest, uint64 amount) public { require(address(this).balance amount, 60); dest.transfer(amount); } }","title":"Usage example"},{"location":"SDK/TON Labs Testnet/Testnet Giver/","text":"Preparation Prerequisites Install the latest version of Docker . See installation tips in the screenshots below: For Linux users, make sure that you are able to run docker as non-root user (see https://docs.docker.com/install/linux/linux-postinstall/ ); Tip : check this page for more Docker installation options https://phoenixnap.com/kb/how-to-install-docker-on-ubuntu-18-04 . Install Node.js 10.x or newer. Make sure that Docker daemon is running on your computer. To check its status, call docker ps . Note that it is recommended to have at least 2Gb of RAM to use Node SE efficiently. Basic Installation This is the easiest version. You can only call three commands to install the solution. First, install TON Labs CLI by running: npm install -g ton-dev-cli Important : If you get errors related to permissions when trying to install packages globally, you can try to fix them using the following options: https://docs.npmjs.com/resolving-eacces-permissions-errors-when-installing-packages-globally . Or call: sudo chown -R $(whoami) $(npm root -g) If you fail, run the command under sudo . Then setup your machine. The step is optional, because tondev start and tondev sol perform the step on demand (see below). tondev setup Run the Local Node Call the following command to run the local node instance (Node SE): tondev start Manual Installation If you have troubles with tondev CLI utility you can install all required components yourself with the following commands: Note that Windows and Linux use different slashes ( / vs. * * ) for system paths. Make sure to change them as needed in the paths to avoid errors. docker pull tonlabs/local-node docker pull tonlabs/compilers docker create -e USER_AGREEMENT=yes --name tonlabs-local-node -i -p80:80 tonlabs/local-node mkdir user home directory /.tonlabs/compilers/projects docker create -e USER_AGREEMENT=yes --name tonlabs-compilers -it --mount type=bind,dst=/projects,src= user home directory /.tonlabs/compilers/projects tonlabs/compilers docker start tonlabs-local-node docker start tonlabs-compilers Home directory may have one of the following formats: Windows: C:\\Users\\User1 MacOS: '/Users/johnDough' Linux: /home/johnDough \u200b Install Client Libraries Tip : go to the Getting Started section, to create your own environment and a test project from scratch according to detailed guidelines. Rust Add a dependency into your cargo manifest: [dependencies] ton-client-rs = 0.11.1 Call the following command: cargo update Node.js Call the following command to install Node.js client library (the recommended version comes first): dependencies : { ton-client-node-js : ^0.12.1 } Then execute (in the project folder): ~/ton-dev/hello$ npm install Or instead of steps 1 and 2 call: npm install ton-client-node-js Web Call the following command to install client library for web browsers: npm install ton-client-web-js React Native Call the following command to install client library for React Native: npm install ton-client-react-native-js Visit TON Dev for additional product, company community info.","title":"Testnet Giver"},{"location":"SDK/TON Labs Testnet/Testnet Giver/#preparation","text":"","title":"Preparation"},{"location":"SDK/TON Labs Testnet/Testnet Giver/#prerequisites","text":"Install the latest version of Docker . See installation tips in the screenshots below: For Linux users, make sure that you are able to run docker as non-root user (see https://docs.docker.com/install/linux/linux-postinstall/ ); Tip : check this page for more Docker installation options https://phoenixnap.com/kb/how-to-install-docker-on-ubuntu-18-04 . Install Node.js 10.x or newer. Make sure that Docker daemon is running on your computer. To check its status, call docker ps . Note that it is recommended to have at least 2Gb of RAM to use Node SE efficiently.","title":"Prerequisites"},{"location":"SDK/TON Labs Testnet/Testnet Giver/#basic-installation","text":"This is the easiest version. You can only call three commands to install the solution. First, install TON Labs CLI by running: npm install -g ton-dev-cli Important : If you get errors related to permissions when trying to install packages globally, you can try to fix them using the following options: https://docs.npmjs.com/resolving-eacces-permissions-errors-when-installing-packages-globally . Or call: sudo chown -R $(whoami) $(npm root -g) If you fail, run the command under sudo . Then setup your machine. The step is optional, because tondev start and tondev sol perform the step on demand (see below). tondev setup","title":"Basic Installation"},{"location":"SDK/TON Labs Testnet/Testnet Giver/#run-the-local-node","text":"Call the following command to run the local node instance (Node SE): tondev start","title":"Run the Local Node"},{"location":"SDK/TON Labs Testnet/Testnet Giver/#manual-installation","text":"If you have troubles with tondev CLI utility you can install all required components yourself with the following commands: Note that Windows and Linux use different slashes ( / vs. * * ) for system paths. Make sure to change them as needed in the paths to avoid errors. docker pull tonlabs/local-node docker pull tonlabs/compilers docker create -e USER_AGREEMENT=yes --name tonlabs-local-node -i -p80:80 tonlabs/local-node mkdir user home directory /.tonlabs/compilers/projects docker create -e USER_AGREEMENT=yes --name tonlabs-compilers -it --mount type=bind,dst=/projects,src= user home directory /.tonlabs/compilers/projects tonlabs/compilers docker start tonlabs-local-node docker start tonlabs-compilers Home directory may have one of the following formats: Windows: C:\\Users\\User1 MacOS: '/Users/johnDough' Linux: /home/johnDough \u200b","title":"Manual Installation"},{"location":"SDK/TON Labs Testnet/Testnet Giver/#install-client-libraries","text":"Tip : go to the Getting Started section, to create your own environment and a test project from scratch according to detailed guidelines.","title":"Install Client Libraries"},{"location":"SDK/TON Labs Testnet/Testnet Giver/#rust","text":"Add a dependency into your cargo manifest: [dependencies] ton-client-rs = 0.11.1 Call the following command: cargo update","title":"Rust"},{"location":"SDK/TON Labs Testnet/Testnet Giver/#nodejs","text":"Call the following command to install Node.js client library (the recommended version comes first): dependencies : { ton-client-node-js : ^0.12.1 } Then execute (in the project folder): ~/ton-dev/hello$ npm install Or instead of steps 1 and 2 call: npm install ton-client-node-js","title":"Node.js"},{"location":"SDK/TON Labs Testnet/Testnet Giver/#web","text":"Call the following command to install client library for web browsers: npm install ton-client-web-js","title":"Web"},{"location":"SDK/TON Labs Testnet/Testnet Giver/#react-native","text":"Call the following command to install client library for React Native: npm install ton-client-react-native-js Visit TON Dev for additional product, company community info.","title":"React Native"},{"location":"TON Blockchain/Gal Calculation Basics/","text":"Gas Calculation Basics TON Gas Implementation Specification Overview The entire state of TVM consists of the five components: stack control registers current continuation current codepage gas limits Collectively these are called SCCCG. The Gas component limits gas usage and \u0441ontains four signed 64-bit integers: the remaining gas: gr the current gas limit: gl the maximal gas limit: gm the gas credit: gc . The following is always true: 0 \u2264 gl \u2264 gm, gc \u2265 0, and gr \u2264 gl + gc gc is initialized by zero for internal messages, gr is initialized by gl + gc and gradually decreases, as the TVM runs. When gr becomes negative or if contract terminates with gc 0 , an out of gas exception is triggered. According to the original TON, for most primitives gas is calculated according to the following formula: Pb := 10 + b where b is the instruction length in bits. The same is true for TON Labs implementation. Apart from integer constants, the following expressions may appear: The total price of loading cells. Currently it is 100 gas units per cell. The total price of creating new Cells from Builders. Currently it is 500 gas units. Exception throwing. 50 gas units per exception. Tuple gas price. 1 gas unit for every tuple element. The usage of these additional integers remains unclear now. Research is underway. Global gas limits Global gas limits are values stored in the masterchain configuration contract. Global values are standard and do not change at contract deployment. Only validator consensus can modify them. The following values are now used for shardchains: Global_gas_price = 1000 Global_gas_limit = 1000000 Global_gas_credit = 10000 Global_block_gas_limit = 10000000 Gas-related TVM primitives These is the list of official TVM primitives used for gas-related operations: F800 \u2014 ACCEPT, sets current gas limit gl to its maximal allowed value gm, and resets the gas credit gc to zero, decreasing the value of gr by gc in the process. In other words, the current smart contract agrees to buy some gas to finish the current transaction. This action is required to process external messages, which bring no value (hence no gas) with themselves. F801 \u2014 SETGASLIMIT (g \u2013 ), sets current gas limit gl to the minimum of g and gm, and resets the gas credit gc to zero. If the gas consumed so far (including the present instruction) exceeds the resulting value of gl , an (unhandled) out of gas exception is thrown before setting new gas limits. Notice that SETGASLIMIT with an argument g \u2265 2 63 \u2212 1 is equivalent to ACCEPT. F802 \u2014 BUYGAS (x \u2013 ), computes the amount of gas that can be bought for x nanograms, and sets gl accordingly in the same way as SETGASLIMIT. F804 \u2014 GRAMTOGAS (x \u2013 g), computes the amount of gas that can be bought for x nanograms. If x is negative, returns 0. If g exceeds 2 63\u22121, it is replaced with this value. F805 \u2014 GASTOGRAM (g \u2013 x), computes the price of g gas in nanograms. F806\u2013F80F \u2014 Reserved for gas-related primitives. These are yet to be released. All of the above are operational in the TON TVM implementation. TON Labs Implementation The general gas formula is the same as specified by TON specifications. Overall, TON Labs nodes operate in compliance with the specification. For every executed primitive, the amount of gas is added to the virtual machine according to the specification formula. Gas value for every primitive is based on gr . Gas initialization types 1. Calling contract from another contract An internal message with a balance value is received. In this case, the following formulas are applied to determine limits: gm = min(account balance / gas price, global_gas_limit) gl = min(message value / gas price, global_gas_limit) gc = 0 gr = gc + gl By default gas costs are allocated to the caller contract that triggers the transaction with a message. Accepting is also available for internal contracts. If ACCEPT is not called, gas is taken from the caller contract according to the message value. In other words, the message value defines the current limit. The message value determines the starting TVM gas limit. So, to put it plain, if ACCEPT is not called, the message pays, if ACCEPT is used, additional gas can be bought by the target contract. This approach enables flexible contract design where either total gas is paid by the caller contract (but in this case it has to have enough gas at any moment of time) or the target contract also incurs costs. 2. Offchain contract call External messages do not carry balance values. In this case, the values are calculated according to the following formulas: gm = min(account balance / gas price, global_gas_limit) gl = 0 gc = min(gm, global_gas_credit) gr = gc + gl As external messages have no gas value, gas is credited to execute it. Target contracts have to cover costs by calling Accept to buy gas. If a contract returns an exception before the credit is given, no gas fee applies As the public code for node has just been released this documentation is likely to be updated.","title":"Gas Calculation Basics"},{"location":"TON Blockchain/Gal Calculation Basics/#gas-calculation-basics","text":"","title":"Gas Calculation Basics"},{"location":"TON Blockchain/Gal Calculation Basics/#ton-gas-implementation","text":"","title":"TON Gas Implementation"},{"location":"TON Blockchain/Gal Calculation Basics/#specification-overview","text":"The entire state of TVM consists of the five components: stack control registers current continuation current codepage gas limits Collectively these are called SCCCG. The Gas component limits gas usage and \u0441ontains four signed 64-bit integers: the remaining gas: gr the current gas limit: gl the maximal gas limit: gm the gas credit: gc . The following is always true: 0 \u2264 gl \u2264 gm, gc \u2265 0, and gr \u2264 gl + gc gc is initialized by zero for internal messages, gr is initialized by gl + gc and gradually decreases, as the TVM runs. When gr becomes negative or if contract terminates with gc 0 , an out of gas exception is triggered. According to the original TON, for most primitives gas is calculated according to the following formula: Pb := 10 + b where b is the instruction length in bits. The same is true for TON Labs implementation. Apart from integer constants, the following expressions may appear: The total price of loading cells. Currently it is 100 gas units per cell. The total price of creating new Cells from Builders. Currently it is 500 gas units. Exception throwing. 50 gas units per exception. Tuple gas price. 1 gas unit for every tuple element. The usage of these additional integers remains unclear now. Research is underway.","title":"Specification Overview"},{"location":"TON Blockchain/Gal Calculation Basics/#global-gas-limits","text":"Global gas limits are values stored in the masterchain configuration contract. Global values are standard and do not change at contract deployment. Only validator consensus can modify them. The following values are now used for shardchains: Global_gas_price = 1000 Global_gas_limit = 1000000 Global_gas_credit = 10000 Global_block_gas_limit = 10000000","title":"Global gas limits"},{"location":"TON Blockchain/Gal Calculation Basics/#gas-related-tvm-primitives","text":"These is the list of official TVM primitives used for gas-related operations: F800 \u2014 ACCEPT, sets current gas limit gl to its maximal allowed value gm, and resets the gas credit gc to zero, decreasing the value of gr by gc in the process. In other words, the current smart contract agrees to buy some gas to finish the current transaction. This action is required to process external messages, which bring no value (hence no gas) with themselves. F801 \u2014 SETGASLIMIT (g \u2013 ), sets current gas limit gl to the minimum of g and gm, and resets the gas credit gc to zero. If the gas consumed so far (including the present instruction) exceeds the resulting value of gl , an (unhandled) out of gas exception is thrown before setting new gas limits. Notice that SETGASLIMIT with an argument g \u2265 2 63 \u2212 1 is equivalent to ACCEPT. F802 \u2014 BUYGAS (x \u2013 ), computes the amount of gas that can be bought for x nanograms, and sets gl accordingly in the same way as SETGASLIMIT. F804 \u2014 GRAMTOGAS (x \u2013 g), computes the amount of gas that can be bought for x nanograms. If x is negative, returns 0. If g exceeds 2 63\u22121, it is replaced with this value. F805 \u2014 GASTOGRAM (g \u2013 x), computes the price of g gas in nanograms. F806\u2013F80F \u2014 Reserved for gas-related primitives. These are yet to be released. All of the above are operational in the TON TVM implementation.","title":"Gas-related TVM primitives"},{"location":"TON Blockchain/Gal Calculation Basics/#ton-labs-implementation","text":"The general gas formula is the same as specified by TON specifications. Overall, TON Labs nodes operate in compliance with the specification. For every executed primitive, the amount of gas is added to the virtual machine according to the specification formula. Gas value for every primitive is based on gr .","title":"TON Labs Implementation"},{"location":"TON Blockchain/Gal Calculation Basics/#gas-initialization-types","text":"1. Calling contract from another contract An internal message with a balance value is received. In this case, the following formulas are applied to determine limits: gm = min(account balance / gas price, global_gas_limit) gl = min(message value / gas price, global_gas_limit) gc = 0 gr = gc + gl By default gas costs are allocated to the caller contract that triggers the transaction with a message. Accepting is also available for internal contracts. If ACCEPT is not called, gas is taken from the caller contract according to the message value. In other words, the message value defines the current limit. The message value determines the starting TVM gas limit. So, to put it plain, if ACCEPT is not called, the message pays, if ACCEPT is used, additional gas can be bought by the target contract. This approach enables flexible contract design where either total gas is paid by the caller contract (but in this case it has to have enough gas at any moment of time) or the target contract also incurs costs. 2. Offchain contract call External messages do not carry balance values. In this case, the values are calculated according to the following formulas: gm = min(account balance / gas price, global_gas_limit) gl = 0 gc = min(gm, global_gas_credit) gr = gc + gl As external messages have no gas value, gas is credited to execute it. Target contracts have to cover costs by calling Accept to buy gas. If a contract returns an exception before the credit is given, no gas fee applies As the public code for node has just been released this documentation is likely to be updated.","title":"Gas initialization types"},{"location":"TON Blockchain/Lite Client Guide/","text":"Lite client This is a representation of the readme on the TON blockchain lite client available at the time of publication. Updated as new materials are available. This archive is a distribution of a preliminary version of the TON Blockchain Lite Client along with the relevant portions of the TON Blockchain Library. It is not necessarily representative of the totality of the TON Blockchain code developed so far; rather it is a simplified stable version, containing only those files that are necessary for compiling the Lite Client, and sometimes outdated versions of these files sufficient for this purpose. Use this software at your own risk; consult the DISCLAIMER for more information. The software is licensed under GNU Lesser General Public License version 2 or later; consult LICENSE.LGPL and LGPL.v2 for more information. If you ever use any of these source files to develop your own versions of this or other software, you must attach a comment with the contents of LGPL.v2 to the beginning of each source file taken from this archive. The software is likely to compile and work properly on most Linux systems. It should work on macOS and even Windows; however, we do not guarantee this for this preliminary version. BASIC COMPILATION AND INSTALLATION INSTRUCTIONS 1) Download and unpack the newest version of this archive, available at https://test.ton.org/download The TON Blockchain Test Network is updated quite often, so we cannot guarantee that older versions of the Lite Client will always work. Backward compatibility is not enforced at this development stage. 2) Install the newest versions of make, cmake (version 3.0.2 or later), OpenSSL (including C header files), and g++ or clang (or another C++14-compatible compiler as appropriate for your operating system). We strongly recommend installing OpenSSL version 1.1.1 or later for better performance, especially if you intend to run a Full Node or a Validator as well. 3) Suppose that you have unpacked this archive to directory ~/lite-client, where ~ is your home directory, and that you have created an empty directory ~/liteclient-build. Then run the following in a terminal on a Linux system: cd ~/liteclient-build cmake ~/lite-client cmake --build . --target lite-client You might also build some extra utilities useful for smart-contract development: cmake --build . --target fift cmake --build . --target func 4) Download the newest configuration file from https://test.ton.org/ton-lite-client-test1.config.json : wget https://test.ton.org/ton-lite-client-test1.config.json 5) Run the Lite Client: ./lite-client/lite-client -C ton-lite-client-test1.config.json If everything was installed successfully, the Lite Client will connect to a special server (a full node for the TON Blockchain Test Network #1) and will send some queries to the server. If you indicate a writeable \"database\" directory as an extra argument to the client, it will download and save the block and the state corresponding to the newest masterchain block: ./lite-client/lite-client -C ton-lite-client-test1.config.json -D ~/ton-db-dir Basic help info can be obtained by typing \"help\" into the Lite Client. Type \"quit\" or press Ctrl-C to exit. 6) Now you can create new smart contracts, examine the state of existing smart contracts, send external messages to smart contracts and so on. You can also use Fift (if you have compiled it) to compile, execute, and debug your smart contracts locally. More details on these activities, including step-by-step instructions for creating a simple wallet smart contract (along with its source code), may be found in the HOWTO file included in this archive. 7) Some documentation on the TON Blockchain and TON Virtual Machine may be found at the download page https://test.ton.org/download . Be aware that this documentation may not be completely in sync with the version currently employed by the Test Network, because some minor implementation details are likely to be changed during the final development and testing phases.","title":"Lite client"},{"location":"TON Blockchain/Lite Client Guide/#lite-client","text":"This is a representation of the readme on the TON blockchain lite client available at the time of publication. Updated as new materials are available. This archive is a distribution of a preliminary version of the TON Blockchain Lite Client along with the relevant portions of the TON Blockchain Library. It is not necessarily representative of the totality of the TON Blockchain code developed so far; rather it is a simplified stable version, containing only those files that are necessary for compiling the Lite Client, and sometimes outdated versions of these files sufficient for this purpose. Use this software at your own risk; consult the DISCLAIMER for more information. The software is licensed under GNU Lesser General Public License version 2 or later; consult LICENSE.LGPL and LGPL.v2 for more information. If you ever use any of these source files to develop your own versions of this or other software, you must attach a comment with the contents of LGPL.v2 to the beginning of each source file taken from this archive. The software is likely to compile and work properly on most Linux systems. It should work on macOS and even Windows; however, we do not guarantee this for this preliminary version.","title":"Lite client"},{"location":"TON Blockchain/Lite Client Guide/#basic-compilation-and-installation-instructions","text":"1) Download and unpack the newest version of this archive, available at https://test.ton.org/download The TON Blockchain Test Network is updated quite often, so we cannot guarantee that older versions of the Lite Client will always work. Backward compatibility is not enforced at this development stage. 2) Install the newest versions of make, cmake (version 3.0.2 or later), OpenSSL (including C header files), and g++ or clang (or another C++14-compatible compiler as appropriate for your operating system). We strongly recommend installing OpenSSL version 1.1.1 or later for better performance, especially if you intend to run a Full Node or a Validator as well. 3) Suppose that you have unpacked this archive to directory ~/lite-client, where ~ is your home directory, and that you have created an empty directory ~/liteclient-build. Then run the following in a terminal on a Linux system: cd ~/liteclient-build cmake ~/lite-client cmake --build . --target lite-client You might also build some extra utilities useful for smart-contract development: cmake --build . --target fift cmake --build . --target func 4) Download the newest configuration file from https://test.ton.org/ton-lite-client-test1.config.json : wget https://test.ton.org/ton-lite-client-test1.config.json 5) Run the Lite Client: ./lite-client/lite-client -C ton-lite-client-test1.config.json If everything was installed successfully, the Lite Client will connect to a special server (a full node for the TON Blockchain Test Network #1) and will send some queries to the server. If you indicate a writeable \"database\" directory as an extra argument to the client, it will download and save the block and the state corresponding to the newest masterchain block: ./lite-client/lite-client -C ton-lite-client-test1.config.json -D ~/ton-db-dir Basic help info can be obtained by typing \"help\" into the Lite Client. Type \"quit\" or press Ctrl-C to exit. 6) Now you can create new smart contracts, examine the state of existing smart contracts, send external messages to smart contracts and so on. You can also use Fift (if you have compiled it) to compile, execute, and debug your smart contracts locally. More details on these activities, including step-by-step instructions for creating a simple wallet smart contract (along with its source code), may be found in the HOWTO file included in this archive. 7) Some documentation on the TON Blockchain and TON Virtual Machine may be found at the download page https://test.ton.org/download . Be aware that this documentation may not be completely in sync with the version currently employed by the Test Network, because some minor implementation details are likely to be changed during the final development and testing phases.","title":"BASIC COMPILATION AND INSTALLATION INSTRUCTIONS"},{"location":"TON Blockchain/Replay Attack Protection/","text":"Replay Attack Protection All external messages must be protected against replay attacks. Otherwise, a malicious party can resend an external message obtained from blockchain and repeat a transaction for a smart contract. For example, a hacker can repeat a Gram transfer and bring an account balance to zero. For internal messages the risk of replay attacks is irrelevant, as they only can be generated inside blockchain by other contracts. Implementation Options Different approaches to implementing replay attack protection exist. None of them is a silver bullet, but there are several indicators applied to compare and evaluate them: Gas consumption Storage fees Race condition Usability Sequence number This is a very simple protection option. It implies that each protected contract stores a counter (i.e. 32bit integer) that is initially set to zero. An external message is then accepted by the contract only under condition that it contains a number equal to the current contract counter value. Each time a new message is accepted, the contract counter value is incremented by one. Pros: simple implementation in contracts; low gas and storage fees; Cons: To get the right sequence number off-chain, a client must request the contract state from blockchain before sending an external message. If the state is large, it can cause a network traffic overhead; Race condition issue that arises when there are multiple contract owners who can simultaneously call it. One owner can increment the contract counter value before this counter becomes available to the next owner; Less sensitive issue of a potential counter overflow in the future. In this case the TVM will throw an exception causing the owner to lose access to the contract. Timestamp Another simple protection option is adding a timestamp to every external message. It can be a 64-bit value in unixtime format. The contract must store the timestamp of the last accepted external message. When a new external message comes, the contract verifies the message timestamp. It must to be bigger than the previous message timestamp and less then now + interval . The interval value is necessary, because now does not stand for the current time, but indicates creation time of the relevant block. The interval can be equal the block generation period or bigger. Pros: very simple implementation; No need to request account state before sending external messages. Cons: Race condition issues remains unresolved as in case of sequence number implementation; Client time must be synchronized with blockchain time. Set of accepted messages Dictionary of randoms This option implies that every external message contains a random value, for example, a 32bit integer. A protected contract, in turn, stores previously used randoms in a dictionary, compares message randoms with it and rejects a message if there is a match detected. Pros: no need to request account state before sending an external message; No race condition; simultaneous access to contract of multiple parties is supported. Collisions are still possible when multiple clients have the same random, but chances can be minimized. Cons: consumes a lot of gas for dictionary write/read operations. Note that the gas fee will increase in the future; high storage fees for storing dictionary. Dictionary of messages with garbage collection This option implies that every external message contains an ' expire-at ' integer that defines the time when the message becomes invalid (i.e. expires). The contract, in turn, must store a dictionary with all recently accepted and not expired external messages. The key is a message hash, the value is the relevant 'expire-at' integer. The contract then rejects all messages that are already present in its dictionary. To avoid persistent data increase, a protected contract can delete messages with the expire-at value less than now from its dictionary. Pros: no need to request the account state before sending an external message; No race condition issues. Cons: Harder to implement compared to the above option with a dictionary of randoms; High gas fees caused by the need to access a dictionary; High storage fees, yet these can be reduced by deleting expired messages from the dictionary; Garbage collecting also involves some gas costs. Sessions Before sending requests to contract, a user creates a session with a contract by sending a create_session external message. The message contains a new session ID, its expired-at time and a starting sequence number. The contract stores a session dictionary. After a session is created, the user adds the session_id and the next session sequence number to every external message. For every external message (not create_session ) the contract checks that: the message session ID exists in dictionary the message sequence number is equal to the stored session number, and the now value is less then the expired-at value for session If all checks are passed successfully, the contract increments the stored sequence number for the session. In case of failure, the message is rejected. Also, expired sessions require some garbage collection. Pros: No need to request the account state before sending an external message; No race condition issues; No collisions. Cons: Harder to implement compared to all the options covered above; High gas fees; High storage fees; Need to use garbage collecting; Unsuitable for simple single-user contracts. Conclusion In TON Labs, we selected a lightweight and simple replay protection option; it will be implemented in the compiler by default and based on the timestamp approach. It is supposed to work well for single-user contracts, as well as for contracts without heavy race conditions. It is easy to use given that TON Labs SDK enables inserting a timestamp automatically on the client side. Also, there will be an option to redefine the default protection method by overloading a special contract function. This is how contract developers will be able to implement any protection option they seem fit.","title":"Replay Attack Protection"},{"location":"TON Blockchain/Replay Attack Protection/#replay-attack-protection","text":"All external messages must be protected against replay attacks. Otherwise, a malicious party can resend an external message obtained from blockchain and repeat a transaction for a smart contract. For example, a hacker can repeat a Gram transfer and bring an account balance to zero. For internal messages the risk of replay attacks is irrelevant, as they only can be generated inside blockchain by other contracts.","title":"Replay Attack Protection"},{"location":"TON Blockchain/Replay Attack Protection/#implementation-options","text":"Different approaches to implementing replay attack protection exist. None of them is a silver bullet, but there are several indicators applied to compare and evaluate them: Gas consumption Storage fees Race condition Usability","title":"Implementation Options"},{"location":"TON Blockchain/Replay Attack Protection/#sequence-number","text":"This is a very simple protection option. It implies that each protected contract stores a counter (i.e. 32bit integer) that is initially set to zero. An external message is then accepted by the contract only under condition that it contains a number equal to the current contract counter value. Each time a new message is accepted, the contract counter value is incremented by one. Pros: simple implementation in contracts; low gas and storage fees; Cons: To get the right sequence number off-chain, a client must request the contract state from blockchain before sending an external message. If the state is large, it can cause a network traffic overhead; Race condition issue that arises when there are multiple contract owners who can simultaneously call it. One owner can increment the contract counter value before this counter becomes available to the next owner; Less sensitive issue of a potential counter overflow in the future. In this case the TVM will throw an exception causing the owner to lose access to the contract.","title":"Sequence number"},{"location":"TON Blockchain/Replay Attack Protection/#timestamp","text":"Another simple protection option is adding a timestamp to every external message. It can be a 64-bit value in unixtime format. The contract must store the timestamp of the last accepted external message. When a new external message comes, the contract verifies the message timestamp. It must to be bigger than the previous message timestamp and less then now + interval . The interval value is necessary, because now does not stand for the current time, but indicates creation time of the relevant block. The interval can be equal the block generation period or bigger. Pros: very simple implementation; No need to request account state before sending external messages. Cons: Race condition issues remains unresolved as in case of sequence number implementation; Client time must be synchronized with blockchain time.","title":"Timestamp"},{"location":"TON Blockchain/Replay Attack Protection/#set-of-accepted-messages","text":"Dictionary of randoms This option implies that every external message contains a random value, for example, a 32bit integer. A protected contract, in turn, stores previously used randoms in a dictionary, compares message randoms with it and rejects a message if there is a match detected. Pros: no need to request account state before sending an external message; No race condition; simultaneous access to contract of multiple parties is supported. Collisions are still possible when multiple clients have the same random, but chances can be minimized. Cons: consumes a lot of gas for dictionary write/read operations. Note that the gas fee will increase in the future; high storage fees for storing dictionary. Dictionary of messages with garbage collection This option implies that every external message contains an ' expire-at ' integer that defines the time when the message becomes invalid (i.e. expires). The contract, in turn, must store a dictionary with all recently accepted and not expired external messages. The key is a message hash, the value is the relevant 'expire-at' integer. The contract then rejects all messages that are already present in its dictionary. To avoid persistent data increase, a protected contract can delete messages with the expire-at value less than now from its dictionary. Pros: no need to request the account state before sending an external message; No race condition issues. Cons: Harder to implement compared to the above option with a dictionary of randoms; High gas fees caused by the need to access a dictionary; High storage fees, yet these can be reduced by deleting expired messages from the dictionary; Garbage collecting also involves some gas costs.","title":"Set of accepted messages"},{"location":"TON Blockchain/Replay Attack Protection/#sessions","text":"Before sending requests to contract, a user creates a session with a contract by sending a create_session external message. The message contains a new session ID, its expired-at time and a starting sequence number. The contract stores a session dictionary. After a session is created, the user adds the session_id and the next session sequence number to every external message. For every external message (not create_session ) the contract checks that: the message session ID exists in dictionary the message sequence number is equal to the stored session number, and the now value is less then the expired-at value for session If all checks are passed successfully, the contract increments the stored sequence number for the session. In case of failure, the message is rejected. Also, expired sessions require some garbage collection. Pros: No need to request the account state before sending an external message; No race condition issues; No collisions. Cons: Harder to implement compared to all the options covered above; High gas fees; High storage fees; Need to use garbage collecting; Unsuitable for simple single-user contracts.","title":"Sessions"},{"location":"TON Blockchain/Replay Attack Protection/#conclusion","text":"In TON Labs, we selected a lightweight and simple replay protection option; it will be implemented in the compiler by default and based on the timestamp approach. It is supposed to work well for single-user contracts, as well as for contracts without heavy race conditions. It is easy to use given that TON Labs SDK enables inserting a timestamp automatically on the client side. Also, there will be an option to redefine the default protection method by overloading a special contract function. This is how contract developers will be able to implement any protection option they seem fit.","title":"Conclusion"},{"location":"TON Blockchain/Storage Fee Calculation/","text":"Storage Fee Calculation Every transaction in TON has a storage phase that implies a certain storage fee charged on an account balance. This fee is charged for the period between transactions and is calculated according to the following formula: Storage fee =(account.bits*global_bit_price+account.cells*global_cell_price)*period where: account.bits and account.cells stand for a number of bits and cells in the Account structure represented as tree of cells (including code and data). global_bit_price is a global configuration parameter; price for storing one bit. Currently in the testnet it is 1 nanogram. global_cell_price another global configuration parameter; price for storing one cell. Currently in the testnet it is 500 nanogram. period - number of seconds since previous storage fee payment. If the account balance is less than the due storage fee, the account is frozen and its balance is subtracted from storage fee and reduced to zero. Remaining storage fee is stored in account as debt","title":"Storage Fee Calculation"},{"location":"TON Blockchain/Storage Fee Calculation/#storage-fee-calculation","text":"Every transaction in TON has a storage phase that implies a certain storage fee charged on an account balance. This fee is charged for the period between transactions and is calculated according to the following formula: Storage fee =(account.bits*global_bit_price+account.cells*global_cell_price)*period where: account.bits and account.cells stand for a number of bits and cells in the Account structure represented as tree of cells (including code and data). global_bit_price is a global configuration parameter; price for storing one bit. Currently in the testnet it is 1 nanogram. global_cell_price another global configuration parameter; price for storing one cell. Currently in the testnet it is 500 nanogram. period - number of seconds since previous storage fee payment. If the account balance is less than the due storage fee, the account is frozen and its balance is subtracted from storage fee and reduced to zero. Remaining storage fee is stored in account as debt","title":"Storage Fee Calculation"},{"location":"TON Blockchain/TON Blockchain/","text":"TON Blockchain 1.1 Everything is a bag of cells 1.1.4. The sha256 hash of a cell. The sha256 hash of a cell c is recursively defined as the sha256 of the standard representation CellRepr(c) of the cell in question: \u200b Hash(c) := sha256(c) := sha256 CellRepr(c) Because cyclic cell references are not allowed (the relationships among all cells must constitute a directed acyclic graph, or DAG), the sha256 hash of a cell is always well-defined. Furthermore, because sha256 is tacitly assumed to be collision-resistant, we assume that all the cells that we encounter are completely determine by their hashes. In particular, the cell references of a cell c are completely determined by the hashes of the referenced cells, contained in the standard representation CellRepr(c) . Messages, message descriptors, and queues Under construction. First we add chapters we have to refer to from our product docs. 3.1 Address, currency, and message layout 3.1.7. Message layout. A message consists of its header followed by its body, or payload. The body is essentially arbitrary, to be interpreted by the destination smart contract. The message header is standard and is organized as follows: int_msg_info$0 ihr_disabled:Bool bounce:Bool src:MsgAddressInt dest:MsgAddressInt value:CurrencyCollection ihr_fee:Grams fwd_fee:Grams created_lt:uint64 created_at:uint32 = CommonMsgInfo; ext_in_msg_info$10 src:MsgAddressExt dest:MsgAddressInt import_fee:Grams = CommonMsgInfo; ext_out_msg_info$11 src:MsgAddressInt dest:MsgAddressExt created_lt:uint64 created_at:uint32 = CommonMsgInfo; tick_tock$_ tick:Bool tock:Bool = TickTock; _ split_depth:(Maybe (## 5)) special:(Maybe TickTock) code:(Maybe ^Cell) data:(Maybe ^Cell) library:(Maybe ^Cell) = StateInit; 56 3.1. Address, currency, and message layout message$_ {X:Type} info:CommonMsgInfo init:(Maybe (Either StateInit ^StateInit)) body:(Either X ^X) = Message X; The meaning of this scheme is as follows. Type Message X describes a message with the body (or payload) of type X. Its serialization starts with info of type CommonMsgInfo, which comes in three flavors: for internal messages, inbound external messages, and outbound external messages, respectively. All of them have a source address src and destination address dest, which are external or internal according to the chosen constructor. Apart from that, an internal message may bear some value in Grams and other defined currencies, and all messages generated inside the TON Blockchain have a logical creation time created_lt (cf. 1.4.6) and creation unixtime created_at, both automatically set by the generating transaction. The creation unixtime equals the creation unixtime of the block containing the generating transaction.","title":"TON Blockchain"},{"location":"TON Blockchain/TON Blockchain/#ton-blockchain","text":"","title":"TON Blockchain"},{"location":"TON Blockchain/TON Blockchain/#11-everything-is-a-bag-of-cells","text":"","title":"1.1 Everything is a bag of cells"},{"location":"TON Blockchain/TON Blockchain/#114-the-sha256-hash-of-a-cell","text":"The sha256 hash of a cell c is recursively defined as the sha256 of the standard representation CellRepr(c) of the cell in question: \u200b Hash(c) := sha256(c) := sha256 CellRepr(c) Because cyclic cell references are not allowed (the relationships among all cells must constitute a directed acyclic graph, or DAG), the sha256 hash of a cell is always well-defined. Furthermore, because sha256 is tacitly assumed to be collision-resistant, we assume that all the cells that we encounter are completely determine by their hashes. In particular, the cell references of a cell c are completely determined by the hashes of the referenced cells, contained in the standard representation CellRepr(c) . Messages, message descriptors, and queues Under construction. First we add chapters we have to refer to from our product docs.","title":"1.1.4. The sha256 hash of a cell."},{"location":"TON Blockchain/TON Blockchain/#31-address-currency-and-message-layout","text":"","title":"3.1 Address, currency, and message layout"},{"location":"TON Blockchain/TON Blockchain/#317-message-layout","text":"A message consists of its header followed by its body, or payload. The body is essentially arbitrary, to be interpreted by the destination smart contract. The message header is standard and is organized as follows: int_msg_info$0 ihr_disabled:Bool bounce:Bool src:MsgAddressInt dest:MsgAddressInt value:CurrencyCollection ihr_fee:Grams fwd_fee:Grams created_lt:uint64 created_at:uint32 = CommonMsgInfo; ext_in_msg_info$10 src:MsgAddressExt dest:MsgAddressInt import_fee:Grams = CommonMsgInfo; ext_out_msg_info$11 src:MsgAddressInt dest:MsgAddressExt created_lt:uint64 created_at:uint32 = CommonMsgInfo; tick_tock$_ tick:Bool tock:Bool = TickTock; _ split_depth:(Maybe (## 5)) special:(Maybe TickTock) code:(Maybe ^Cell) data:(Maybe ^Cell) library:(Maybe ^Cell) = StateInit; 56 3.1. Address, currency, and message layout message$_ {X:Type} info:CommonMsgInfo init:(Maybe (Either StateInit ^StateInit)) body:(Either X ^X) = Message X; The meaning of this scheme is as follows. Type Message X describes a message with the body (or payload) of type X. Its serialization starts with info of type CommonMsgInfo, which comes in three flavors: for internal messages, inbound external messages, and outbound external messages, respectively. All of them have a source address src and destination address dest, which are external or internal according to the chosen constructor. Apart from that, an internal message may bear some value in Grams and other defined currencies, and all messages generated inside the TON Blockchain have a logical creation time created_lt (cf. 1.4.6) and creation unixtime created_at, both automatically set by the generating transaction. The creation unixtime equals the creation unixtime of the block containing the generating transaction.","title":"3.1.7. Message layout."},{"location":"TON Blockchain/TON Virtual Machine/","text":"Introduction The primary purpose of the Telegram Open Network Virtual Machine (TON VM or TVM) is to execute smart-contract code in the TON Blockchain. TVM must support all operations required to parse incoming messages and persistent data, and to create new messages and modify persistent data. Additionally, TVM must meet the following requirements: It must provide for possible future extensions and improvements while retaining backward compatibility and interoperability, because the code of a smart contract, once committed into the blockchain, must continue working in a predictable manner regardless of any future modifications to the VM. It must strive to attain high \u201c(virtual) machine code\u201d density, so that the code of a typical smart contract occupies as little persistent blockchain storage as possible. It must be completely deterministic. In other words, each run of the same code with the same input data must produce the same result, regardless of specific software and hardware used.* The design of TVM is guided by these requirements. While this document describes a preliminary and experimental version of TVM,** the backward compatibility mechanisms built into the system allow us to be relatively unconcerned with the efficiency of the operation encoding used for TVM code in this preliminary version. TVM is not intended to be implemented in hardware (e.g., in a specialized microprocessor chip); rather, it should be implemented in software running on conventional hardware. This consideration lets us incorporate some highlevel concepts and operations in TVM that would require convoluted microcode in a hardware implementation but pose no significant problems for a software implementation. Such operations are useful for achieving high code density and minimizing the byte (or storage cell) profile of smart-contract code when deployed in the TON Blockchain. *For example, there are no floating-point arithmetic operations (which could be efficiently implemented using hardware-supported double type on most modern CPUs) present in TVM, because the result of performing such operations is dependent on the specific underlying hardware implementation and rounding mode settings. Instead, TVM supports special integer arithmetic operations, which can be used to simulate fixed-point arithmetic if needed. **The production version will likely require some tweaks and modifications prior to launch, which will become apparent only after using the experimental version in the test environment for some time. Overview This chapter provides an overview of the main features and design principles of TVM. More detail on each topic is provided in subsequent chapters. 1.0 Notation for bitstrings The following notation is used for bit strings (or bitstrings) \u2014i.e., finite strings consisting of binary digits (bits), 0 and 1\u2014throughout this document. 1.0.1. Hexadecimal notation for bitstrings. When the length of a bitstring is a multiple of four, we subdivide it into groups of four bits and represent each group by one of sixteen hexadecimal digits 0\u20139, A\u2013F in the usual manner: 016 \u2194 0000, 116 \u2194 0001, . . . , F16 \u2194 1111. The resulting hexadecimal string is our equivalent representation for the original binary string. 1.0.2. Bitstrings of lengths not divisible by four. If the length of a binary string is not divisible by four, we augment it by one 1 and several (maybe zero) 0s at the end, so that its length becomes divisible by four, and then transform it into a string of hexadecimal digits as described above. To indicate that such a transformation has taken place, a special \u201ccompletion tag\u201d _ is added to the end of the hexadecimal string. The reverse transformation (applied if the completion tag is present) consists in first replacing each hexadecimal digit by four corresponding bits, and then removing all trailing zeroes (if any) and the last 1 immediately preceding them (if the resulting bitstring is non-empty at this point). Notice that there are several admissible hexadecimal representations for the same bitstring. Among them, the shortest one is \u201ccanonical\u201d. It can be deterministically obtained by the above procedure. For example, 8A corresponds to binary string 10001010, while 8A_ and 8A0_ both correspond to 100010. An empty bitstring may be represented by either \u2018\u2019, \u20188_\u2019, \u20180_\u2019, \u2018 \u2019, or \u201800 \u2019. 1.0.3. Emphasizing that a string is a hexadecimal representation of a bitstring. Sometimes we need to emphasize that a string of hexadecimal digits (with or without a _ at the end) is the hexadecimal representation of a bitstring. In such cases, we either prepend x to the resulting string (e.g., x8A), or prepend x{ and append } (e.g., x{2D9_}, which is 00101101100). This should not be confused with hexadecimal numbers, usually prepended by 0x (e.g., 0x2D9 or 0x2d9, which is the integer 729). 1.0.4. Serializing a bitstring into a sequence of octets. When a bitstring needs to be represented as a sequence of 8-bit bytes (octets), which take values in integers 0 . . . 255, this is achieved essentially in the same fashion as above: we split the bitstring into groups of eight bits and interpret each group as the binary representation of an integer 0 . . . 255. If the length of the bitstring is not a multiple of eight, the bitstring is augmented by a binary 1 and up to seven binary 0s before being split into groups. The fact that such a completion has been applied is usually reflected by a \u201ccompletion tag\u201d bit. For instance, 00101101100 corresponds to the sequence of two octets (0x2d, 0x90) (hexadecimal), or (45, 144) (decimal), along with a completion tag bit equal to 1 (meaning that the completion has been applied), which must be stored separately. In some cases, it is more convenient to assume the completion is enabled by default rather than store an additional completion tag bit separately. Under such conventions, 8n-bit strings are rep 1.1 TVM is a stack machine First of all, TVM is a stack machine. This means that, instead of keeping values in some \u201cvariables\u201d or \u201cgeneral-purpose registers\u201d, they are kept in a (LIFO) stack, at least from the \u201clow-level\u201d (TVM) perspective. Most operations and user-defined functions take their arguments from the top of the stack, and replace them with their result. For example, the integer addition primitive (built-in operation) ADD does not take any arguments describing which registers or immediate values should be added together and where the result should be stored. Instead, the two top values are taken from the stack, they are added together, and their sum is pushed into the stack in their place. 1.1.1. TVM values. The entities that can be stored in the TVM stack will be called TVM values, or simply values for brevity. They belong to one of several predefined value types. Each value belongs to exactly one value type. The values are always kept on the stack along with tags uniquely determining their types, and all built-in TVM operations (or primitives) only accept values of predefined types. For example, the integer addition primitive ADD accepts only two integer values, and returns one integer value as a result. One cannot supply ADD with two strings instead of two integers expecting it to concatenate these strings or to implicitly transform the strings into their decimal integer values; any attempt to do so will result in a run-time type-checking exception. 1.1.2. Static typing, dynamic typing, and run-time type checking. In some respects TVM performs a kind of dynamic typing using run-time type checking. However, this does not make the TVM code a \u201cdynamically typed language\u201d like PHP or Javascript, because all primitives accept values and return results of predefined (value) types, each value belongs to strictly one type, and values are never implicitly converted from one type to another. If, on the other hand, one compares the TVM code to the conventional microprocessor machine code, one sees that the TVM mechanism of value tagging prevents, for example, using the address of a string as a number\u2014 or, potentially even more disastrously, using a number as the address of a string\u2014thus eliminating the possibility of all sorts of bugs and security vulnerabilities related to invalid memory accesses, usually leading to memory corruption and segmentation faults. This property is highly desirable for a VM used to execute smart contracts in a blockchain. In this respect, TVM\u2019s insistence on tagging all values with their appropriate types, instead of reinterpreting the bit sequence in a register depending on the needs of the operation it is used in, is just an additional run-time type-safety mechanism. An alternative would be to somehow analyze the smart-contract code for type correctness and type safety before allowing its execution in the VM, or even before allowing it to be uploaded into the blockchain as the code of a smart contract. Such a static analysis of code for a Turing-complete machine appears to be a time-consuming and non-trivial problem (likely to be equivalent to the stopping problem for Turing machines), something we would rather avoid in a blockchain smart-contract context. One should bear in mind that one always can implement compilers from statically typed high-level smart-contract languages into the TVM code (and we do expect that most smart contracts for TON will be written in such languages), just as one can compile statically typed languages into conventional machine code (e.g., x86 architecture). If the compiler works correctly, the resulting machine code will never generate any run-time type-checking exceptions. All type tags attached to values processed by TVM will always have expected values and may be safely ignored during the analysis of the resulting TVM code, apart from the fact that the run-time generation and verification of these type tags by TVM will slightly slow down the execution of the TVM code. 1.1.3. Preliminary list of value types. A preliminary list of value types supported by TVM is as follows: Integer \u2014 Signed 257-bit integers, representing integer numbers in the range \u22122 256 . . . 2 256 \u2212 1, as well as a special \u201cnot-a-number\u201d value NaN. Cell \u2014 A TVM cell consists of at most 1023 bits of data, and of at most four references to other cells. All persistent data (including TVM code) in the TON Blockchain is represented as a collection of TVM cells (cf. [1, 2.5.14]). \u2022 Tuple \u2014 An ordered collection of up to 255 components, having arbitrary value types, possibly distinct. May be used to represent nonpersistent values of arbitrary algebraic data types. Null \u2014 A type with exactly one value \u22a5, used for representing empty lists, empty branches of binary trees, absence of return value in some situations, and so on. \u2022 Slice \u2014 A TVM cell slice, or slice for short, is a contiguous \u201csub-cell\u201d of an existing cell, containing some of its bits of data and some of its references. Essentially, a slice is a read-only view for a subcell of a cell. Slices are used for unpacking data previously stored (or serialized) in a cell or a tree of cells. Builder \u2014 A TVM cell builder, or builder for short, is an \u201cincomplete\u201d cell that supports fast operations of appending bitstrings and cell references at its end. Builders are used for packing (or serializing) data from the top of the stack into new cells (e.g., before transferring them to persistent storage). Continuation \u2014 Represents an \u201cexecution token\u201d for TVM, which may be invoked (executed) later. As such, it generalizes function addresses (i.e., function pointers and references), subroutine return addresses, instruction pointer addresses, exception handler addresses, closures, partial applications, anonymous functions, and so on. This list of value types is incomplete and may be extended in future revisions of TVM without breaking the old TVM code, due mostly to the fact that all originally defined primitives accept only values of types known to them and will fail (generate a type-checking exception) if invoked on values of new types. Furthermore, existing value types themselves can also be extended in the future: for example, 257-bit Integer might become 513-bit LongInteger , with originally defined arithmetic primitives failing if either of the arguments or the result does not fit into the original subtype Integer. Backward compatibility with respect to the introduction of new value types and extension of existing value types will be discussed in more detail later (cf. 5.1.4). 1.2 Categories of TVM instructions TVM instructions, also called primitives and sometimes (built-in) operations, are the smallest operations atomically performed by TVM that can be present in the TVM code. They fall into several categories, depending on the types of values (cf. 1.1.3 ) they work on. The most important of these categories are: Stack (manipulation) primitives \u2014 Rearrange data in the TVM stack, so that the other primitives and user-defined functions can later be called with correct arguments. Unlike most other primitives, they are polymorphic, i.e., work with values of arbitrary types. Tuple (manipulation) primitives \u2014 Construct, modify, and decompose Tuples. Similarly to the stack primitives, they are polymorphic. Constant or literal primitives \u2014 Push into the stack some \u201cconstant\u201d or \u201cliteral\u201d values embedded into the TVM code itself, thus providing arguments to the other primitives. They are somewhat similar to stack primitives, but are less generic because they work with values of specific types. Arithmetic primitives \u2014 Perform the usual integer arithmetic operations on values of type Integer. Cell (manipulation) primitives \u2014 Create new cells and store data in them (cell creation primitives) or read data from previously created cells (cell parsing primitives). Because all memory and persistent storage of TVM consists of cells, these cell manipulation primitives actually correspond to \u201cmemory access instructions\u201d of other architectures. Cell creation primitives usually work with values of type Builder, while cell parsing primitives work with Slices. Continuation and control flow primitives \u2014 Create and modify Continuations, as well as execute existing Continuations in different ways, including conditional and repeated execution. Custom or application-specific primitives \u2014 Efficiently perform specific high-level actions required by the application (in our case, the TON Blockchain), such as computing hash functions, performing elliptic curve cryptography, sending new blockchain messages, creating new smart contracts, and so on. These primitives correspond to standard library functions rather than microprocessor instructions. 1.3 Control registers While TVM is a stack machine, some rarely changed values needed in almost all functions are better passed in certain special registers, and not near the top of the stack. Otherwise, a prohibitive number of stack reordering operations would be required to manage all these values. To this end, the TVM model includes, apart from the stack, up to 16 special control registers, denoted by c0 to c15, or c(0) to c(15). The original version of TVM makes use of only some of these registers; the rest may be supported later. 1.3.1. Values kept in control registers. The values kept in control registers are of the same types as those kept on the stack. However, some control registers accept only values of specific types, and any attempt to load a value of a different type will lead to an exception. 1.3.2. List of control registers. The original version of TVM defines and uses the following control registers: c0 \u2014 Contains the next continuation or return continuation (similar to the subroutine return address in conventional designs). This value must be a Continuation. c1 \u2014 Contains the alternative (return) continuation; this value must be a Continuation. It is used in some (experimental) control flow primitives, allowing TVM to define and call \u201csubroutines with two exit points\u201d. \u2022 c2 \u2014 Contains the exception handler. This value is a Continuation, invoked whenever an exception is triggered. c3 \u2014 Contains the current dictionary, essentially a hashmap containing the code of all functions used in the program. For reasons explained later in 4.6, this value is also a Continuation, not a Cell as one might expect. c4 \u2014 Contains the root of persistent data, or simply the data. This value is a Cell. When the code of a smart contract is invoked, c4 points to the root cell of its persistent data kept in the blockchain state. If the smart contract needs to modify this data, it changes c4 before returning. c5 \u2014 Contains the output actions. It is also a Cell initialized by a reference to an empty cell, but its final value is considered one of the smart contract outputs. For instance, the SENDMSG primitive, specific for the TON Blockchain, simply inserts the message into a list stored in the output actions. c7 \u2014 Contains the root of temporary data. It is a Tuple, initialized by a reference to an empty Tuple before invoking the smart contract and discarded after its termination. More control registers may be defined in the future for specific TON Blockchain or high-level programming language purposes, if necessary. 1.4 Total state of TVM (SCCCG) The total state of TVM consists of the following components: Stack (cf. 1.1 ) \u2014 Contains zero or more values (cf. 1.1.1 ), each belonging to one of value types listed in 1.1.3 . Control registers c0\u2013c15 \u2014 Contain some specific values as described in 1.3.2 . (Only seven control registers are used in the current version.) Current continuation cc \u2014 Contains the current continuation (i.e., the code that would be normally executed after the current primitive is completed). This component is similar to the instruction pointer register (ip) in other architectures. Current codepage cp \u2014 A special signed 16-bit integer value that selects the way the next TVM opcode will be decoded. For example, future versions of TVM might use different codepages to add new opcodes while preserving backward compatibility. Gas limits gas \u2014 Contains four signed 64-bit integers: the current gas limit gl , the maximal gas limit gm, the remaining gas gr, and the gas credit gc. Always 0 \u2264 gl \u2264 gm, gc \u2265 0, and gr \u2264 gl + gc; gc is usually initialized by zero, gr is initialized by gl + gc and gradually decreases as the TVM runs. When gr becomes negative or if the final value of gr is less than gc, an out of gas exception is triggered. Notice that there is no \u201creturn stack\u201d containing the return addresses of all previously called but unfinished functions. Instead, only control register c0 is used. The reason for this will be explained later in 4.1.9. Also notice that there are no general-purpose registers, because TVM is a stack machine (cf. 1.1 ). So the above list, which can be summarized as \u201cstack, control, continuation, codepage, and gas\u201d (SCCCG), similarly to the classical SECD machine state (\u201cstack, environment, control, dump\u201d), is indeed the total state of TVM. 1.5 Integer arithmetic All arithmetic primitives of TVM operate on several arguments of type Integer, taken from the top of the stack, and return their results, of the same type, into the stack. Recall that Integer represents all integer values in the range \u22122^256 \u2264 x 2^256, and additionally contains a special value NaN (\u201cnota-number\u201d). If one of the results does not fit into the supported range of integers\u2014 or if one of the arguments is a NaN\u2014then this result or all of the results are replaced by a NaN, and (by default) an integer overflow exception is generated. However, special \u201cquiet\u201d versions of arithmetic operations will simply produce NaNs and keep going. If these NaNs end up being used in a \u201cnon-quiet\u201d arithmetic operation, or in a non-arithmetic operation, an integer overflow exception will occur. 1.5.1. Absence of automatic conversion of integers. Notice that TVM Integer s are \u201cmathematical\u201d integers, and not 257-bit strings interpreted differently depending on the primitive used, as is common for other machine code designs. For example, TVM has only one multiplication primitive MUL, rather than two (MUL for unsigned multiplication and IMUL for signed multiplication) as occurs, for example, in the popular x86 architecture. 1.5.2. Automatic overflow checks. Notice that all TVM arithmetic primitives perform overflow checks of the results. If a result does not fit into the Integer type, it is replaced by a NaN, and (usually) an exception occurs. In particular, the result is not automatically reduced modulo 2^256 or 2^257, as is common for most hardware machine code architectures. 1.5.3. Custom overflow checks. In addition to automatic overflow checks, TVM includes custom overflow checks, performed by primitives FITS n and UFITS n, where 1 \u2264 n \u2264 256. These primitives check whether the value on (the top of) the stack is an integer x in the range \u22122 n\u22121 \u2264 x 2 n\u22121 or 0 \u2264 x 2 n , respectively, and replace the value with a NaN and (optionally) generate an integer overflow exception if this is not the case. This greatly simplifies the implementation of arbitrary n-bit integer types, signed or unsigned: the programmer or the compiler must insert appropriate FITS or UFITS primitives either after each arithmetic operation (which is more reasonable, but requires more checks) or before storing computed values and returning them from functions. This is important for smart contracts, where unexpected integer overflows happen to be among the most common source of bugs. 1.5.4. Reduction modulo 2^n . TVM also has a primitive MODPOW2 n, which reduces the integer at the top of the stack modulo 2 n , with the result ranging from 0 to 2^n \u2212 1. 1.5.5. Integer is 257-bit, not 256-bit. One can understand now why TVM\u2019s Integer is (signed) 257-bit, not 256-bit. The reason is that it is the smallest integer type containing both signed 256-bit integers and unsigned 256-bit integers, which does not require automatic reinterpreting of the same 256-bit string depending on the operation used (cf. 1.5.1 ). 1.5.6. Division and rounding. The most important division primitives are DIV, MOD, and DIVMOD. All of them take two numbers from the stack, x and y (y is taken from the top of the stack, and x is originally under it), compute the quotient q and remainder r of the division of x by y (i.e., two integers such that x = yq + r and |r| |y|), and return either q, r, or both of them. If y is zero, then all of the expected results are replaced by NaNs, and (usually) an integer overflow exception is generated. The implementation of division in TVM somewhat differs from most other implementations with regards to rounding. By default, these primitives round to \u2212\u221e, meaning that q = bx/yc, and r has the same sign as y. (Most conventional implementations of division use \u201crounding to zero\u201d instead, meaning that r has the same sign as x.) Apart from this \u201cfloor rounding\u201d, two other rounding modes are available, called \u201cceiling rounding\u201d (with q = dx/ye, and r and y having opposite signs) and \u201cnearest rounding\u201d (with q = bx/y + 1/2c and |r| \u2264 |y|/2). These rounding modes are selected by using other division primitives, with letters C and R appended to their mnemonics. For example, DIVMODR computes both the quotient and the remainder using rounding to the nearest integer. 1.5.7. Combined multiply-divide, multiply-shift, and shift-divide operations. To simplify implementation of fixed-point arithmetic, TVM supports combined multiply-divide, multiply-shift, and shift-divide operations with double-length (i.e., 514-bit) intermediate product. For example, MULDIVMODR takes three integer arguments from the stack, a, b, and c, first computes ab using a 514-bit intermediate result, and then divides ab by c using rounding to the nearest integer. If c is zero or if the quotient does not fit into Integer, either two NaNs are returned, or an integer overflow exception is generated, depending on whether a quiet version of the operation has been used. Otherwise, both the quotient and the remainder are pushed into the stack. The Stack This chapter contains a general discussion and comparison of register and stack machines, expanded further in Appendix C, and describes the two main classes of stack manipulation primitives employed by TVM: the basic and the compound stack manipulation primitives. An informal explanation of their sufficiency for all stack reordering required for correctly invoking other primitives and user-defined functions is also provided. Finally, the problem of efficiently implementing TVM stack manipulation primitives is discussed in 2.3 . 2.1 Stack calling conventions A stack machine, such as TVM, uses the stack\u2014and especially the values near the top of the stack\u2014to pass arguments to called functions and primitives (such as built-in arithmetic operations) and receive their results. This section discusses the TVM stack calling conventions, introduces some notation, and compares TVM stack calling conventions with those of certain register machines. 2.1.1. Notation for \u201cstack registers\u201d. Recall that a stack machine, as opposed to a more conventional register machine, lacks general-purpose registers. However, one can treat the values near the top of the stack as a kind of \u201cstack registers\u201d. We denote by s0 or s(0) the value at the top of the stack, by s1 or s(1) the value immediately under it, and so on. The total number of values in the stack is called its depth. If the depth of the stack is n, then s(0), s(1), . . . , s(n \u2212 1) are well-defined, while s(n) and all subsequent s(i) with i n are not. Any attempt to use s(i) with i \u2265 n should produce a stack underflow exception. A compiler, or a human programmer in \u201cTVM code\u201d, would use these \u201cstack registers\u201d to hold all declared variables and intermediate values, similarly to the way general-purpose registers are used on a register machine. 2.1.2. Pushing and popping values. When a value x is pushed into a stack of depth n, it becomes the new s0; at the same time, the old s0 becomes the new s1, the old s1\u2014the new s2, and so on. The depth of the resulting stack is n + 1. Similarly, when a value x is popped from a stack of depth n \u2265 1, it is the old value of s0 (i.e., the old value at the top of the stack). After this, it is removed from the stack, and the old s1 becomes the new s0 (the new value at the top of the stack), the old s2 becomes the new s1, and so on. The depth of the resulting stack is n \u2212 1. If originally n = 0, then the stack is empty, and a value cannot be popped from it. If a primitive attempts to pop a value from an empty stack, a stack underflow exception occurs. 2.1.3. Notation for hypothetical general-purpose registers. In order to compare stack machines with sufficiently general register machines, we will denote the general-purpose registers of a register machine by r0, r1, and so on, or by r(0), r(1), . . . , r(n \u2212 1) , where n is the total number of registers. When we need a specific value of n, we will use n = 16, corresponding to the very popular x86-64 architecture. 2.1.4. The top-of-stack register s0 vs. the accumulator register r0. Some register machine architectures require one of the arguments for most arithmetic and logical operations to reside in a special register called the accumulator. In our comparison, we will assume that the accumulator is the general-purpose register r0; otherwise we could simply renumber the registers. In this respect, the accumulator is somewhat similar to the top-ofstack \u201cregister\u201d s0 of a stack machine, because virtually all operations of a stack machine both use s0 as one of their arguments and return their result as s0. 2.1.5. Register calling conventions. When compiled for a register machine, high-level language functions usually receive their arguments in certain registers in a predefined order. If there are too many arguments, these functions take the remainder from the stack (yes, a register machine usually has a stack, too!). Some register calling conventions pass no arguments in registers at all, however, and only use the stack (for example, the original calling conventions used in implementations of Pascal and C, although modern implementations of C use some registers as well). For simplicity, we will assume that up to m \u2264 n function arguments are passed in registers, and that these registers are r0, r1, . . . , r(m \u2212 1) , in that order (if some other registers are used, we can simply renumber them). Our inclusion of r0 here creates a minor conflict with our assumption that the accumulator register, if present, is also r0; for simplicity, we will resolve this problem by assuming that the first argument to a function is passed in the accumulator. 2.1.6. Order of function arguments. If a function or primitive requires m arguments x1, . . . , xm , they are pushed by the caller into the stack in the same order, starting from x1. Therefore, when the function or primitive is invoked, its first argument x1 is in s(m \u2212 1), its second argument x2 is in s(m \u2212 2), and so on. The last argument xm is in s0 (i.e., at the top of the stack). It is the called function or primitive\u2019s responsibility to remove its arguments from the stack. In this respect the TVM stack calling conventions\u2014obeyed, at least, by TMV primitives\u2014match those of Pascal and Forth, and are the opposite of those of C (in which the arguments are pushed into the stack in the reverse order, and are removed by the caller after it regains control, not the callee). Of course, an implementation of a high-level language for TVM might choose some other calling conventions for its functions, different from the default ones. This might be useful for certain functions\u2014for instance, if the total number of arguments depends on the value of the first argument, as happens for \u201cvariadic functions\u201d such as scanf and printf. In such cases, the first one or several arguments are better passed near the top of the stack, not somewhere at some unknown location deep in the stack. 2.1.7. Arguments to arithmetic primitives on register machines. On a stack machine, built-in arithmetic primitives (such as ADD or DIVMOD) follow the same calling conventions as user-defined functions. In this respect, user-defined functions (for example, a function computing the square root of a number) might be considered as \u201cextensions\u201d or \u201ccustom upgrades\u201d of the stack machine. This is one of the clearest advantages of stack machines (and of stack programming languages such as Forth) compared to register machines. In contrast, arithmetic instructions (built-in operations) on register machines usually get their parameters from general-purpose registers encoded in the full opcode. A binary operation, such as SUB, thus requires two arguments, r(i) and r(j), with i and j specified by the instruction. A register r(k) for storing the result also must be specified. Arithmetic operations can take several possible forms, depending on whether i, j, and k are allowed to take arbitrary values: Three-address form \u2014 Allows the programmer to arbitrarily choose not only the two source registers r(i) and r(j), but also a separate destination register r(k). This form is common for most RISC processors, and for the XMM and AVX SIMD instruction sets in the x86-64 architecture. Two-address form \u2014 Uses one of the two operand registers (usually r(i)) to store the result of an operation, so that k = i is never indicated explicitly. Only i and j are encoded inside the instruction. This is the most common form of arithmetic operations on register machines, and is quite popular on microprocessors (including the x86 family). One-address form \u2014 Always takes one of the arguments from the accumulator r0, and stores the result in r0 as well; then i = k = 0, and only j needs to be specified by the instruction. This form is used by some simpler microprocessors (such as Intel 8080). Note that this flexibility is available only for built-in operations, but not for user-defined functions. In this respect, register machines are not as easily \u201cupgradable\u201d as stack machines. For instance, if one writes a function for extracting square roots, this function will always accept its argument and return its result in the same registers, in contrast with a hypothetical built-in square root instruction, which could allow the programmer to arbitrarily choose the source and destination registers. Therefore, a user-defined function is tremendously less flexible than a built-in instruction on a register machine. 2.1.8. Return values of functions. In stack machines such as TVM, when a function or primitive needs to return a result value, it simply pushes it into the stack (from which all arguments to the function have already been removed). Therefore, the caller will be able to access the result value through the top-of-stack \u201cregister\u201d s0. This is in complete accordance with Forth calling conventions, but differs slightly from Pascal and C calling conventions, where the accumulator register r0 is normally used for the return value. 2.1.9. Returning several values. Some functions might want to return several values y1, . . . , yk , with k not necessarily equal to one. In these cases, the k return values are pushed into the stack in their natural order, starting from y1. For example, the \u201cdivide with remainder\u201d primitive DIVMOD needs to return two values, the quotient q and the remainder r. Therefore, DIVMOD pushes q and r into the stack, in that order, so that the quotient is available return values in their place, by convention leaving all deeper values intact. Then the resulting stack, again in its entirety, is returned to the caller. Most TVM primitives behave in this way, and we expect most user-defined functions to be implemented under such conventions. However, TVM provides mechanisms to specify how many arguments must be passed to a called function (cf. 4.1.10 ). When these mechanisms are employed, the specified number of values are moved from the caller\u2019s stack into the (usually initially empty) stack of the called function, while deeper values remain in the caller\u2019s stack and are inaccessible to the callee. The caller can also specify how many return values it expects from the called function. Such argument-checking mechanisms might be useful, for example, for a library function that calls user-provided functions passed as arguments to it. 2.3 Efficiency of stack manipulation primitives 2.3.5. Absence of circular references. One might attempt to create a circular reference between two cells, A and B, as follows: first create A and write some data into it; then create B and write some data into it, along with a reference to previously constructed cell A; finally, add a reference to B into A. While it may seem that after this sequence of operations we obtain a cell A, which refers to B, which in turn refers to A, this is not the case. In fact, we obtain a new cell A0 , which contains a copy of the data originally stored into cell A along with a reference to cell B, which contains a reference to (the original) cell A. In this way the transparent copy-on-write mechanism and the \u201ceverything is a value\u201d paradigm enable us to create new cells using only previously constructed cells, thus forbidding the appearance of circular references. This property also applies to all other data structures: for instance, the absence of circular references enables TVM to use reference counting to immediately free unused memory instead of relying on garbage collectors. Similarly, this property is crucial for storing data in the TON Blockchain. 3. Cell Memory and Persistent Storage This chapter briefly describes TVM cells, used to represent all data structures inside the TVM memory and its persistent storage, and the basic operations used to create cells, write (or serialize) data into them, and read (or deserialize) data from them. 3.1 Generalities on Cells This section presents a classification and general descriptions of cell types. 3.1.1. TVM memory and persistent storage consist of cells. Recall that the TVM memory and persistent storage consist of (TVM) cells. Each cell contains up to 1023 bits of data and up to four references to other cells. Circular references are forbidden and cannot be created by means of TVM (cf. 2.3.5 ). In this way, all cells kept in TVM memory and persistent storage constitute a directed acyclic graph (DAG). 3.1.2. Ordinary and exotic cells. Apart from the data and references, a cell has a cell type, encoded by an integer \u22121. . . 255. A cell of type \u22121 is called ordinary; such cells do not require any special processing. Cells of other types are called exotic, and may be loaded\u2014automatically replaced by other cells when an attempt to deserialize them (i.e., to convert them into a Slice by a CTOS instruction) is made. They may also exhibit a non-trivial behavior when their hashes are computed. The most common use for exotic cells is to represent some other cells\u2014for instance, cells present in an external library, or pruned from the original tree of cells when a Merkle proof has been created. The type of an exotic cell is stored as the first eight bits of its data. If an exotic cell has less than eight data bits, it is invalid. 3.1.3. The level of a cell. Every cell c has another attribute Lvl(c) called its (de Brujn) level, which currently takes integer values in the range 0. . . 3. The level of an ordinary cell is always equal to the maximum of the levels of all its children ci : \u200b Lvl(c) = max Lvl(ci) , where 1\u2264i\u2264r for an ordinary cell c containing r references to cells c1, . . . , cr. If r = 0, Lvl(c) = 0. Exotic cells may have different rules for setting their level. A cell\u2019s level affects the number of higher hashes it has. More precisely, a level l cell has l higher hashes Hash1(c), . . . , Hashl(c) in addition to its representation hash Hash(c) = Hash\u221e(c). Cells of non-zero level appear inside Merkle proofs and Merkle updates, after some branches of the tree of cells representing a value of an abstract data type are pruned 3.1.4 Standard cell representation. When a cell needs to be transferred by a network protocol or stored in a disk file, it must be serialized. The standard representation CellRepr(c) = CellRepr\u221e(c) of a cell c as an octet (byte) sequence is constructed as follows: \\1. Two descriptor bytes d1 and d2 are serialized first. Byte d1 equals r+8s+32l , where 0 \u2264 r \u2264 4 is the quantity of cell references contained in the cell, 0 \u2264 l \u2264 3 is the level of the cell, and 0 \u2264 s \u2264 1 is 1 for exotic cells and 0 for ordinary cells. Byte d2 equals bb/8c+db/8e , where 0 \u2264 b \u2264 1023 is the quantity of data bits in c. \\2. Then the data bits are serialized as db/8e 8-bit octets (bytes). If b is not a multiple of eight, a binary 1 and up to six binary 0s are appended to the data bits. After that, the data is split into db/8e eight-bit groups, and each group is interpreted as an unsigned big-endian integer 0 . . . 255 and stored into an octet. \\3. Finally, each of the r cell references is represented by 32 bytes containing the 256-bit representation hash Hash(ci) , explained below in 3.1.5 , of the cell ci referred to. In this way, 2 + db/8e + 32r bytes of CellRepr(c) are obtained. 3.1.5. The representation hash of a cell. The 256-bit representation hash or simply hash Hash(c) of a cell c is recursively defined as the sha256 of the standard representation of the cell c: \u200b Hash(c) := sha256 := CellRepr(c) Notice that cyclic cell references are not allowed and cannot be created by means of the TVM (cf. 2.3.5 ), so this recursion always ends, and the representation hash of any cell is well-defined. 3.1.6. The higher hashes of a cell. Recall that a cell c of level l has l higher hashes Hashi(c) , 1 \u2264 i \u2264 l , as well. Exotic cells have their own rules for computing their higher hashes. Higher hashes Hashi(c) of an ordinary cell c are computed similarly to its representation hash, but using the higher hashes Hashi(cj) of its children cj instead of their representation hashes Hash(cj) . By convention, we set Hash\u221e(c) := Hash(c) , and Hashi(c) := Hash\u221e(c) = Hash(c) for all i l. 12 3.1.7. Types of exotic cells. TVM currently supports the following cell types: Type \u22121: Ordinary cell \u2014 Contains up to 1023 bits of data and up to four cell references. Type 1: Pruned branch cell c \u2014 May have any level 1 \u2264 l \u2264 3 . It contains exactly 8 + 256l data bits: first an 8-bit integer equal to 1 (representing the cell\u2019s type), then its l higher hashes Hash1(c), . . . , Hashl(c) . The level l of a pruned branch cell may be called its de Brujn index, because it determines the outer Merkle proof or Merkle update during the construction of which the branch has been pruned. An attempt to load a pruned branch cell usually leads to an exception. Type 2: Library reference cell \u2014 Always has level 0, and contains 8+256 data bits, including its 8-bit type integer 2 and the representation hash Hash(c0) of the library cell being referred to. When loaded, a library reference cell may be transparently replaced by the cell it refers to, if found in the current library context. Type 3: Merkle proof cell c \u2014 Has exactly one reference c1 and level 0 \u2264 l \u2264 3, which must be one less than the level of its only child c1: Lvl(c) = max(Lvl(c1) \u2212 1, 0) The 8 + 256 data bits of a Merkle proof cell contain its 8-bit type integer 3, followed by Hash1(c1) (assumed to be equal to Hash(c1) if Lvl(c1) = 0 ). The higher hashes Hashi(c) of c are computed similarly to the higher hashes of an ordinary cell, but with Hashi+1(c1) used instead of Hashi(c1) . When loaded, a Merkle proof cell is replaced by c1. Type 4: Merkle update cell c \u2014 Has two children c1 and c2. Its level 0 \u2264 l \u2264 3 is given by Lvl(c) = max(Lvl(c1) \u2212 1 , Lvl(c2) \u2212 1, 0) (4) A Merkle update behaves like a Merkle proof for both c1 and c2, and contains 8 + 256 + 256 data bits with Hash1(c1) and Hash1(c2) . However, an extra requirement is that all pruned branch cells c 0 that are descendants of c2 and are bound by c must also be descendants of c1^13 .When a Merkle update cell is loaded, it is replaced by c2. 3.2 Data manipulation instructions and cells The next large group of TVM instructions consists of data manipulation instructions, also known as cell manipulation instructions or simply cell instructions. They correspond to memory access instructions of other architectures. 3.2.1. Classes of cell manipulation instructions. The TVM cell instructions are naturally subdivided into two principal classes: \u2022 Cell creation instructions or serialization instructions, used to construct new cells from values previously kept in the stack and previously constructed cells. \u2022 Cell parsing instructions or deserialization instructions, used to extract data previously stored into cells by cell creation instructions. Additionally, there are exotic cell instructions used to create and inspect exotic cells (cf. 3.1.2 ), which in particular are used to represent pruned branches of Merkle proofs and Merkle proofs themselves. 3.2.2. Builder and Slice values. Cell creation instructions usually work with Builder values, which can be kept only in the stack (cf. 1.1.3 ). Such values represent partially constructed cells, for which fast operations for appending bitstrings, integers, other cells, and references to other cells can be defined. Similarly, cell parsing instructions make heavy use of Slice values, which represent either the remainder of a partially parsed cell, or a value (subcell) residing inside such a cell and extracted from it by a parsing instruction. 4. Control Flow, Continuations, and Exceptions This chapter describes continuations, which may represent execution tokens and exception handlers in TVM. Continuations are deeply involved with the control flow of a TVM program; in particular, subroutine calls and conditional and iterated execution are implemented in TVM using special primitives that accept one or more continuations as their arguments. We conclude this chapter with a discussion of the problem of recursion and of families of mutually recursive functions, exacerbated by the fact that cyclic references are not allowed in TVM data structures (including TVM code). 4.1. Continuations and subroutines 4.1.10. Determining the number of arguments passed to and/or return values accepted from a subroutine. Similarly to JMPX and RET, CALLX also has special (rarely used) forms, which allow us to explicitly specify the number n 00 of arguments passed from the current stack to the called subroutine (by default, n 00 equals the depth of the current stack, i.e., it is passed in its entirety). Furthermore, a second number n 000 can be specified, used to set nargs of the modified cc continuation before storing it into the new c0; the new nargs equals the depth of the old stack minus n 00 plus n 000 . This means that the caller is willing to pass exactly n 00 arguments to the called subroutine, and is willing to accept exactly n 000 results in their stead. Such forms of CALLX and RET are mostly intended for library functions that accept functional arguments and want to invoke them safely. Another application is related to the \u201cvirtualization support\u201d of TVM, which enables TVM code to run other TVM code inside a \u201cvirtual TVM machine\u201d. Such virtualization techniques might be useful for implementing sophisticated payment channels in the TON Blockchain (cf. 5 ]). Appendix A A.1 Gas prices The gas price for most primitives equals the basic gas price, computed as Pb := 10 + b + 5r , where b is the instruction length in bits and r is the number of cell references included in the instruction. When the gas price of an instruction differs from this basic price, it is indicated in parentheses after its mnemonics, either as (x), meaning that the total gas price equals x, or as (+x), meaning Pb + x. Apart from integer constants, the following expressions may appear: Cr \u2014 The total price of \u201creading\u201d cells (i.e., transforming cell references into cell slices). Currently equal to 20 gas units per cell. L \u2014 The total price of loading cells. Depends on the loading action required. Bw \u2014 The total price of creating new Builders. Currently equal to 100 gas units per builder. Cw \u2014 The total price of creating new Cells from Builders). Currently equal to 100 gas units per cell. A.4.2. Constant slices, continuations, cells, and references. Most of the instructions listed below push literal slices, continuations, cells, and cell references, stored as immediate arguments to the instruction. Therefore, if the immediate argument is absent or too short, an \u201cinvalid or too short opcode\u201d exception (code 6) is thrown. 88 \u2014 PUSHREF, pushes the first reference of cc.code into the stack as a Cell (and removes this reference from the current continuation). 89 \u2014 PUSHREFSLICE, similar to PUSHREF, but converts the cell into a Slice. 8A \u2014 PUSHREFCONT, similar to PUSHREFSLICE, but makes a simple ordinary Continuation out of the cell. 8Bxsss \u2014 PUSHSLICE sss, pushes the (prefix) subslice of cc.code consisting of its first 8x + 4 bits and no references (i.e., essentially a bitstring), where 0 \u2264 x \u2264 15. A completion tag is assumed, meaning that all trailing zeroes and the last binary one (if present) are removed from this bitstring. If the original bitstring consists only of zeroes, an empty slice will be pushed. 8B08 \u2014 PUSHSLICE x8_, pushes an empty slice (bitstring \u2018\u2019). 8B04 \u2014 PUSHSLICE x4_, pushes bitstring \u20180\u2019. 8B0C \u2014 PUSHSLICE xC_, pushes bitstring \u20181\u2019. 8Crxxssss \u2014 PUSHSLICE ssss, pushes the (prefix) subslice of cc.code consisting of its first 1 \u2264 r + 1 \u2264 4 references and up to first 8xx + 1 bits of data, with 0 \u2264 xx \u2264 31. A completion tag is also assumed. 8C01 is equivalent to PUSHREFSLICE. 8Drxxsssss \u2014 PUSHSLICE sssss, pushes the subslice of cc.code consisting of 0 \u2264 r \u2264 4 references and up to 8xx + 6 bits of data, with 0 \u2264 xx \u2264 127. A completion tag is assumed. 8DE_ \u2014 unused (reserved). 8F_rxxcccc \u2014 PUSHCONT cccc, where cccc is the simple ordinary continuation made from the first 0 \u2264 r \u2264 3 references and the first 0 \u2264 xx \u2264 127 bytes of cc.code. 9xccc \u2014 PUSHCONT ccc, pushes an x-byte continuation for 0 \u2264 x \u2264 15.","title":"Introduction"},{"location":"TON Blockchain/TON Virtual Machine/#introduction","text":"The primary purpose of the Telegram Open Network Virtual Machine (TON VM or TVM) is to execute smart-contract code in the TON Blockchain. TVM must support all operations required to parse incoming messages and persistent data, and to create new messages and modify persistent data. Additionally, TVM must meet the following requirements: It must provide for possible future extensions and improvements while retaining backward compatibility and interoperability, because the code of a smart contract, once committed into the blockchain, must continue working in a predictable manner regardless of any future modifications to the VM. It must strive to attain high \u201c(virtual) machine code\u201d density, so that the code of a typical smart contract occupies as little persistent blockchain storage as possible. It must be completely deterministic. In other words, each run of the same code with the same input data must produce the same result, regardless of specific software and hardware used.* The design of TVM is guided by these requirements. While this document describes a preliminary and experimental version of TVM,** the backward compatibility mechanisms built into the system allow us to be relatively unconcerned with the efficiency of the operation encoding used for TVM code in this preliminary version. TVM is not intended to be implemented in hardware (e.g., in a specialized microprocessor chip); rather, it should be implemented in software running on conventional hardware. This consideration lets us incorporate some highlevel concepts and operations in TVM that would require convoluted microcode in a hardware implementation but pose no significant problems for a software implementation. Such operations are useful for achieving high code density and minimizing the byte (or storage cell) profile of smart-contract code when deployed in the TON Blockchain. *For example, there are no floating-point arithmetic operations (which could be efficiently implemented using hardware-supported double type on most modern CPUs) present in TVM, because the result of performing such operations is dependent on the specific underlying hardware implementation and rounding mode settings. Instead, TVM supports special integer arithmetic operations, which can be used to simulate fixed-point arithmetic if needed. **The production version will likely require some tweaks and modifications prior to launch, which will become apparent only after using the experimental version in the test environment for some time.","title":"Introduction"},{"location":"TON Blockchain/TON Virtual Machine/#overview","text":"This chapter provides an overview of the main features and design principles of TVM. More detail on each topic is provided in subsequent chapters.","title":"Overview"},{"location":"TON Blockchain/TON Virtual Machine/#10-notation-for-bitstrings","text":"The following notation is used for bit strings (or bitstrings) \u2014i.e., finite strings consisting of binary digits (bits), 0 and 1\u2014throughout this document.","title":"1.0 Notation for bitstrings"},{"location":"TON Blockchain/TON Virtual Machine/#101-hexadecimal-notation-for-bitstrings","text":"When the length of a bitstring is a multiple of four, we subdivide it into groups of four bits and represent each group by one of sixteen hexadecimal digits 0\u20139, A\u2013F in the usual manner: 016 \u2194 0000, 116 \u2194 0001, . . . , F16 \u2194 1111. The resulting hexadecimal string is our equivalent representation for the original binary string.","title":"1.0.1. Hexadecimal notation for bitstrings."},{"location":"TON Blockchain/TON Virtual Machine/#102-bitstrings-of-lengths-not-divisible-by-four","text":"If the length of a binary string is not divisible by four, we augment it by one 1 and several (maybe zero) 0s at the end, so that its length becomes divisible by four, and then transform it into a string of hexadecimal digits as described above. To indicate that such a transformation has taken place, a special \u201ccompletion tag\u201d _ is added to the end of the hexadecimal string. The reverse transformation (applied if the completion tag is present) consists in first replacing each hexadecimal digit by four corresponding bits, and then removing all trailing zeroes (if any) and the last 1 immediately preceding them (if the resulting bitstring is non-empty at this point). Notice that there are several admissible hexadecimal representations for the same bitstring. Among them, the shortest one is \u201ccanonical\u201d. It can be deterministically obtained by the above procedure. For example, 8A corresponds to binary string 10001010, while 8A_ and 8A0_ both correspond to 100010. An empty bitstring may be represented by either \u2018\u2019, \u20188_\u2019, \u20180_\u2019, \u2018 \u2019, or \u201800 \u2019.","title":"1.0.2. Bitstrings of lengths not divisible by four."},{"location":"TON Blockchain/TON Virtual Machine/#103-emphasizing-that-a-string-is-a-hexadecimal-representation-of-a-bitstring","text":"Sometimes we need to emphasize that a string of hexadecimal digits (with or without a _ at the end) is the hexadecimal representation of a bitstring. In such cases, we either prepend x to the resulting string (e.g., x8A), or prepend x{ and append } (e.g., x{2D9_}, which is 00101101100). This should not be confused with hexadecimal numbers, usually prepended by 0x (e.g., 0x2D9 or 0x2d9, which is the integer 729).","title":"1.0.3. Emphasizing that a string is a hexadecimal representation of a bitstring."},{"location":"TON Blockchain/TON Virtual Machine/#104-serializing-a-bitstring-into-a-sequence-of-octets","text":"When a bitstring needs to be represented as a sequence of 8-bit bytes (octets), which take values in integers 0 . . . 255, this is achieved essentially in the same fashion as above: we split the bitstring into groups of eight bits and interpret each group as the binary representation of an integer 0 . . . 255. If the length of the bitstring is not a multiple of eight, the bitstring is augmented by a binary 1 and up to seven binary 0s before being split into groups. The fact that such a completion has been applied is usually reflected by a \u201ccompletion tag\u201d bit. For instance, 00101101100 corresponds to the sequence of two octets (0x2d, 0x90) (hexadecimal), or (45, 144) (decimal), along with a completion tag bit equal to 1 (meaning that the completion has been applied), which must be stored separately. In some cases, it is more convenient to assume the completion is enabled by default rather than store an additional completion tag bit separately. Under such conventions, 8n-bit strings are rep","title":"1.0.4. Serializing a bitstring into a sequence of octets."},{"location":"TON Blockchain/TON Virtual Machine/#11-tvm-is-a-stack-machine","text":"First of all, TVM is a stack machine. This means that, instead of keeping values in some \u201cvariables\u201d or \u201cgeneral-purpose registers\u201d, they are kept in a (LIFO) stack, at least from the \u201clow-level\u201d (TVM) perspective. Most operations and user-defined functions take their arguments from the top of the stack, and replace them with their result. For example, the integer addition primitive (built-in operation) ADD does not take any arguments describing which registers or immediate values should be added together and where the result should be stored. Instead, the two top values are taken from the stack, they are added together, and their sum is pushed into the stack in their place.","title":"1.1 TVM is a stack machine"},{"location":"TON Blockchain/TON Virtual Machine/#111-tvm-values","text":"The entities that can be stored in the TVM stack will be called TVM values, or simply values for brevity. They belong to one of several predefined value types. Each value belongs to exactly one value type. The values are always kept on the stack along with tags uniquely determining their types, and all built-in TVM operations (or primitives) only accept values of predefined types. For example, the integer addition primitive ADD accepts only two integer values, and returns one integer value as a result. One cannot supply ADD with two strings instead of two integers expecting it to concatenate these strings or to implicitly transform the strings into their decimal integer values; any attempt to do so will result in a run-time type-checking exception.","title":"1.1.1. TVM values."},{"location":"TON Blockchain/TON Virtual Machine/#112-static-typing-dynamic-typing-and-run-time-type-checking","text":"In some respects TVM performs a kind of dynamic typing using run-time type checking. However, this does not make the TVM code a \u201cdynamically typed language\u201d like PHP or Javascript, because all primitives accept values and return results of predefined (value) types, each value belongs to strictly one type, and values are never implicitly converted from one type to another. If, on the other hand, one compares the TVM code to the conventional microprocessor machine code, one sees that the TVM mechanism of value tagging prevents, for example, using the address of a string as a number\u2014 or, potentially even more disastrously, using a number as the address of a string\u2014thus eliminating the possibility of all sorts of bugs and security vulnerabilities related to invalid memory accesses, usually leading to memory corruption and segmentation faults. This property is highly desirable for a VM used to execute smart contracts in a blockchain. In this respect, TVM\u2019s insistence on tagging all values with their appropriate types, instead of reinterpreting the bit sequence in a register depending on the needs of the operation it is used in, is just an additional run-time type-safety mechanism. An alternative would be to somehow analyze the smart-contract code for type correctness and type safety before allowing its execution in the VM, or even before allowing it to be uploaded into the blockchain as the code of a smart contract. Such a static analysis of code for a Turing-complete machine appears to be a time-consuming and non-trivial problem (likely to be equivalent to the stopping problem for Turing machines), something we would rather avoid in a blockchain smart-contract context. One should bear in mind that one always can implement compilers from statically typed high-level smart-contract languages into the TVM code (and we do expect that most smart contracts for TON will be written in such languages), just as one can compile statically typed languages into conventional machine code (e.g., x86 architecture). If the compiler works correctly, the resulting machine code will never generate any run-time type-checking exceptions. All type tags attached to values processed by TVM will always have expected values and may be safely ignored during the analysis of the resulting TVM code, apart from the fact that the run-time generation and verification of these type tags by TVM will slightly slow down the execution of the TVM code.","title":"1.1.2. Static typing, dynamic typing, and run-time type checking."},{"location":"TON Blockchain/TON Virtual Machine/#113-preliminary-list-of-value-types","text":"A preliminary list of value types supported by TVM is as follows: Integer \u2014 Signed 257-bit integers, representing integer numbers in the range \u22122 256 . . . 2 256 \u2212 1, as well as a special \u201cnot-a-number\u201d value NaN. Cell \u2014 A TVM cell consists of at most 1023 bits of data, and of at most four references to other cells. All persistent data (including TVM code) in the TON Blockchain is represented as a collection of TVM cells (cf. [1, 2.5.14]). \u2022 Tuple \u2014 An ordered collection of up to 255 components, having arbitrary value types, possibly distinct. May be used to represent nonpersistent values of arbitrary algebraic data types. Null \u2014 A type with exactly one value \u22a5, used for representing empty lists, empty branches of binary trees, absence of return value in some situations, and so on. \u2022 Slice \u2014 A TVM cell slice, or slice for short, is a contiguous \u201csub-cell\u201d of an existing cell, containing some of its bits of data and some of its references. Essentially, a slice is a read-only view for a subcell of a cell. Slices are used for unpacking data previously stored (or serialized) in a cell or a tree of cells. Builder \u2014 A TVM cell builder, or builder for short, is an \u201cincomplete\u201d cell that supports fast operations of appending bitstrings and cell references at its end. Builders are used for packing (or serializing) data from the top of the stack into new cells (e.g., before transferring them to persistent storage). Continuation \u2014 Represents an \u201cexecution token\u201d for TVM, which may be invoked (executed) later. As such, it generalizes function addresses (i.e., function pointers and references), subroutine return addresses, instruction pointer addresses, exception handler addresses, closures, partial applications, anonymous functions, and so on. This list of value types is incomplete and may be extended in future revisions of TVM without breaking the old TVM code, due mostly to the fact that all originally defined primitives accept only values of types known to them and will fail (generate a type-checking exception) if invoked on values of new types. Furthermore, existing value types themselves can also be extended in the future: for example, 257-bit Integer might become 513-bit LongInteger , with originally defined arithmetic primitives failing if either of the arguments or the result does not fit into the original subtype Integer. Backward compatibility with respect to the introduction of new value types and extension of existing value types will be discussed in more detail later (cf. 5.1.4).","title":"1.1.3. Preliminary list of value types."},{"location":"TON Blockchain/TON Virtual Machine/#12-categories-of-tvm-instructions","text":"TVM instructions, also called primitives and sometimes (built-in) operations, are the smallest operations atomically performed by TVM that can be present in the TVM code. They fall into several categories, depending on the types of values (cf. 1.1.3 ) they work on. The most important of these categories are: Stack (manipulation) primitives \u2014 Rearrange data in the TVM stack, so that the other primitives and user-defined functions can later be called with correct arguments. Unlike most other primitives, they are polymorphic, i.e., work with values of arbitrary types. Tuple (manipulation) primitives \u2014 Construct, modify, and decompose Tuples. Similarly to the stack primitives, they are polymorphic. Constant or literal primitives \u2014 Push into the stack some \u201cconstant\u201d or \u201cliteral\u201d values embedded into the TVM code itself, thus providing arguments to the other primitives. They are somewhat similar to stack primitives, but are less generic because they work with values of specific types. Arithmetic primitives \u2014 Perform the usual integer arithmetic operations on values of type Integer. Cell (manipulation) primitives \u2014 Create new cells and store data in them (cell creation primitives) or read data from previously created cells (cell parsing primitives). Because all memory and persistent storage of TVM consists of cells, these cell manipulation primitives actually correspond to \u201cmemory access instructions\u201d of other architectures. Cell creation primitives usually work with values of type Builder, while cell parsing primitives work with Slices. Continuation and control flow primitives \u2014 Create and modify Continuations, as well as execute existing Continuations in different ways, including conditional and repeated execution. Custom or application-specific primitives \u2014 Efficiently perform specific high-level actions required by the application (in our case, the TON Blockchain), such as computing hash functions, performing elliptic curve cryptography, sending new blockchain messages, creating new smart contracts, and so on. These primitives correspond to standard library functions rather than microprocessor instructions.","title":"1.2 Categories of TVM instructions"},{"location":"TON Blockchain/TON Virtual Machine/#13-control-registers","text":"While TVM is a stack machine, some rarely changed values needed in almost all functions are better passed in certain special registers, and not near the top of the stack. Otherwise, a prohibitive number of stack reordering operations would be required to manage all these values. To this end, the TVM model includes, apart from the stack, up to 16 special control registers, denoted by c0 to c15, or c(0) to c(15). The original version of TVM makes use of only some of these registers; the rest may be supported later.","title":"1.3 Control registers"},{"location":"TON Blockchain/TON Virtual Machine/#131-values-kept-in-control-registers","text":"The values kept in control registers are of the same types as those kept on the stack. However, some control registers accept only values of specific types, and any attempt to load a value of a different type will lead to an exception.","title":"1.3.1. Values kept in control registers."},{"location":"TON Blockchain/TON Virtual Machine/#132-list-of-control-registers","text":"The original version of TVM defines and uses the following control registers: c0 \u2014 Contains the next continuation or return continuation (similar to the subroutine return address in conventional designs). This value must be a Continuation. c1 \u2014 Contains the alternative (return) continuation; this value must be a Continuation. It is used in some (experimental) control flow primitives, allowing TVM to define and call \u201csubroutines with two exit points\u201d. \u2022 c2 \u2014 Contains the exception handler. This value is a Continuation, invoked whenever an exception is triggered. c3 \u2014 Contains the current dictionary, essentially a hashmap containing the code of all functions used in the program. For reasons explained later in 4.6, this value is also a Continuation, not a Cell as one might expect. c4 \u2014 Contains the root of persistent data, or simply the data. This value is a Cell. When the code of a smart contract is invoked, c4 points to the root cell of its persistent data kept in the blockchain state. If the smart contract needs to modify this data, it changes c4 before returning. c5 \u2014 Contains the output actions. It is also a Cell initialized by a reference to an empty cell, but its final value is considered one of the smart contract outputs. For instance, the SENDMSG primitive, specific for the TON Blockchain, simply inserts the message into a list stored in the output actions. c7 \u2014 Contains the root of temporary data. It is a Tuple, initialized by a reference to an empty Tuple before invoking the smart contract and discarded after its termination. More control registers may be defined in the future for specific TON Blockchain or high-level programming language purposes, if necessary.","title":"1.3.2. List of control registers."},{"location":"TON Blockchain/TON Virtual Machine/#14-total-state-of-tvm-scccg","text":"The total state of TVM consists of the following components: Stack (cf. 1.1 ) \u2014 Contains zero or more values (cf. 1.1.1 ), each belonging to one of value types listed in 1.1.3 . Control registers c0\u2013c15 \u2014 Contain some specific values as described in 1.3.2 . (Only seven control registers are used in the current version.) Current continuation cc \u2014 Contains the current continuation (i.e., the code that would be normally executed after the current primitive is completed). This component is similar to the instruction pointer register (ip) in other architectures. Current codepage cp \u2014 A special signed 16-bit integer value that selects the way the next TVM opcode will be decoded. For example, future versions of TVM might use different codepages to add new opcodes while preserving backward compatibility. Gas limits gas \u2014 Contains four signed 64-bit integers: the current gas limit gl , the maximal gas limit gm, the remaining gas gr, and the gas credit gc. Always 0 \u2264 gl \u2264 gm, gc \u2265 0, and gr \u2264 gl + gc; gc is usually initialized by zero, gr is initialized by gl + gc and gradually decreases as the TVM runs. When gr becomes negative or if the final value of gr is less than gc, an out of gas exception is triggered. Notice that there is no \u201creturn stack\u201d containing the return addresses of all previously called but unfinished functions. Instead, only control register c0 is used. The reason for this will be explained later in 4.1.9. Also notice that there are no general-purpose registers, because TVM is a stack machine (cf. 1.1 ). So the above list, which can be summarized as \u201cstack, control, continuation, codepage, and gas\u201d (SCCCG), similarly to the classical SECD machine state (\u201cstack, environment, control, dump\u201d), is indeed the total state of TVM.","title":"1.4 Total state of TVM (SCCCG)"},{"location":"TON Blockchain/TON Virtual Machine/#15-integer-arithmetic","text":"All arithmetic primitives of TVM operate on several arguments of type Integer, taken from the top of the stack, and return their results, of the same type, into the stack. Recall that Integer represents all integer values in the range \u22122^256 \u2264 x 2^256, and additionally contains a special value NaN (\u201cnota-number\u201d). If one of the results does not fit into the supported range of integers\u2014 or if one of the arguments is a NaN\u2014then this result or all of the results are replaced by a NaN, and (by default) an integer overflow exception is generated. However, special \u201cquiet\u201d versions of arithmetic operations will simply produce NaNs and keep going. If these NaNs end up being used in a \u201cnon-quiet\u201d arithmetic operation, or in a non-arithmetic operation, an integer overflow exception will occur.","title":"1.5 Integer arithmetic"},{"location":"TON Blockchain/TON Virtual Machine/#151-absence-of-automatic-conversion-of-integers","text":"Notice that TVM Integer s are \u201cmathematical\u201d integers, and not 257-bit strings interpreted differently depending on the primitive used, as is common for other machine code designs. For example, TVM has only one multiplication primitive MUL, rather than two (MUL for unsigned multiplication and IMUL for signed multiplication) as occurs, for example, in the popular x86 architecture.","title":"1.5.1. Absence of automatic conversion of integers."},{"location":"TON Blockchain/TON Virtual Machine/#152-automatic-overflow-checks","text":"Notice that all TVM arithmetic primitives perform overflow checks of the results. If a result does not fit into the Integer type, it is replaced by a NaN, and (usually) an exception occurs. In particular, the result is not automatically reduced modulo 2^256 or 2^257, as is common for most hardware machine code architectures.","title":"1.5.2. Automatic overflow checks."},{"location":"TON Blockchain/TON Virtual Machine/#153-custom-overflow-checks","text":"In addition to automatic overflow checks, TVM includes custom overflow checks, performed by primitives FITS n and UFITS n, where 1 \u2264 n \u2264 256. These primitives check whether the value on (the top of) the stack is an integer x in the range \u22122 n\u22121 \u2264 x 2 n\u22121 or 0 \u2264 x 2 n , respectively, and replace the value with a NaN and (optionally) generate an integer overflow exception if this is not the case. This greatly simplifies the implementation of arbitrary n-bit integer types, signed or unsigned: the programmer or the compiler must insert appropriate FITS or UFITS primitives either after each arithmetic operation (which is more reasonable, but requires more checks) or before storing computed values and returning them from functions. This is important for smart contracts, where unexpected integer overflows happen to be among the most common source of bugs.","title":"1.5.3. Custom overflow checks."},{"location":"TON Blockchain/TON Virtual Machine/#154-reduction-modulo-2n","text":"TVM also has a primitive MODPOW2 n, which reduces the integer at the top of the stack modulo 2 n , with the result ranging from 0 to 2^n \u2212 1.","title":"1.5.4. Reduction modulo 2^n ."},{"location":"TON Blockchain/TON Virtual Machine/#155-integer-is-257-bit-not-256-bit","text":"One can understand now why TVM\u2019s Integer is (signed) 257-bit, not 256-bit. The reason is that it is the smallest integer type containing both signed 256-bit integers and unsigned 256-bit integers, which does not require automatic reinterpreting of the same 256-bit string depending on the operation used (cf. 1.5.1 ).","title":"1.5.5. Integer is 257-bit, not 256-bit."},{"location":"TON Blockchain/TON Virtual Machine/#156-division-and-rounding","text":"The most important division primitives are DIV, MOD, and DIVMOD. All of them take two numbers from the stack, x and y (y is taken from the top of the stack, and x is originally under it), compute the quotient q and remainder r of the division of x by y (i.e., two integers such that x = yq + r and |r| |y|), and return either q, r, or both of them. If y is zero, then all of the expected results are replaced by NaNs, and (usually) an integer overflow exception is generated. The implementation of division in TVM somewhat differs from most other implementations with regards to rounding. By default, these primitives round to \u2212\u221e, meaning that q = bx/yc, and r has the same sign as y. (Most conventional implementations of division use \u201crounding to zero\u201d instead, meaning that r has the same sign as x.) Apart from this \u201cfloor rounding\u201d, two other rounding modes are available, called \u201cceiling rounding\u201d (with q = dx/ye, and r and y having opposite signs) and \u201cnearest rounding\u201d (with q = bx/y + 1/2c and |r| \u2264 |y|/2). These rounding modes are selected by using other division primitives, with letters C and R appended to their mnemonics. For example, DIVMODR computes both the quotient and the remainder using rounding to the nearest integer.","title":"1.5.6. Division and rounding."},{"location":"TON Blockchain/TON Virtual Machine/#157-combined-multiply-divide-multiply-shift-and-shift-divide-operations","text":"To simplify implementation of fixed-point arithmetic, TVM supports combined multiply-divide, multiply-shift, and shift-divide operations with double-length (i.e., 514-bit) intermediate product. For example, MULDIVMODR takes three integer arguments from the stack, a, b, and c, first computes ab using a 514-bit intermediate result, and then divides ab by c using rounding to the nearest integer. If c is zero or if the quotient does not fit into Integer, either two NaNs are returned, or an integer overflow exception is generated, depending on whether a quiet version of the operation has been used. Otherwise, both the quotient and the remainder are pushed into the stack.","title":"1.5.7. Combined multiply-divide, multiply-shift, and shift-divide operations."},{"location":"TON Blockchain/TON Virtual Machine/#the-stack","text":"This chapter contains a general discussion and comparison of register and stack machines, expanded further in Appendix C, and describes the two main classes of stack manipulation primitives employed by TVM: the basic and the compound stack manipulation primitives. An informal explanation of their sufficiency for all stack reordering required for correctly invoking other primitives and user-defined functions is also provided. Finally, the problem of efficiently implementing TVM stack manipulation primitives is discussed in 2.3 .","title":"The Stack"},{"location":"TON Blockchain/TON Virtual Machine/#21-stack-calling-conventions","text":"A stack machine, such as TVM, uses the stack\u2014and especially the values near the top of the stack\u2014to pass arguments to called functions and primitives (such as built-in arithmetic operations) and receive their results. This section discusses the TVM stack calling conventions, introduces some notation, and compares TVM stack calling conventions with those of certain register machines.","title":"2.1 Stack calling conventions"},{"location":"TON Blockchain/TON Virtual Machine/#211-notation-for-stack-registers","text":"Recall that a stack machine, as opposed to a more conventional register machine, lacks general-purpose registers. However, one can treat the values near the top of the stack as a kind of \u201cstack registers\u201d. We denote by s0 or s(0) the value at the top of the stack, by s1 or s(1) the value immediately under it, and so on. The total number of values in the stack is called its depth. If the depth of the stack is n, then s(0), s(1), . . . , s(n \u2212 1) are well-defined, while s(n) and all subsequent s(i) with i n are not. Any attempt to use s(i) with i \u2265 n should produce a stack underflow exception. A compiler, or a human programmer in \u201cTVM code\u201d, would use these \u201cstack registers\u201d to hold all declared variables and intermediate values, similarly to the way general-purpose registers are used on a register machine.","title":"2.1.1. Notation for \u201cstack registers\u201d."},{"location":"TON Blockchain/TON Virtual Machine/#212-pushing-and-popping-values","text":"When a value x is pushed into a stack of depth n, it becomes the new s0; at the same time, the old s0 becomes the new s1, the old s1\u2014the new s2, and so on. The depth of the resulting stack is n + 1. Similarly, when a value x is popped from a stack of depth n \u2265 1, it is the old value of s0 (i.e., the old value at the top of the stack). After this, it is removed from the stack, and the old s1 becomes the new s0 (the new value at the top of the stack), the old s2 becomes the new s1, and so on. The depth of the resulting stack is n \u2212 1. If originally n = 0, then the stack is empty, and a value cannot be popped from it. If a primitive attempts to pop a value from an empty stack, a stack underflow exception occurs.","title":"2.1.2. Pushing and popping values."},{"location":"TON Blockchain/TON Virtual Machine/#213-notation-for-hypothetical-general-purpose-registers","text":"In order to compare stack machines with sufficiently general register machines, we will denote the general-purpose registers of a register machine by r0, r1, and so on, or by r(0), r(1), . . . , r(n \u2212 1) , where n is the total number of registers. When we need a specific value of n, we will use n = 16, corresponding to the very popular x86-64 architecture.","title":"2.1.3. Notation for hypothetical general-purpose registers."},{"location":"TON Blockchain/TON Virtual Machine/#214-the-top-of-stack-register-s0-vs-the-accumulator-register-r0","text":"Some register machine architectures require one of the arguments for most arithmetic and logical operations to reside in a special register called the accumulator. In our comparison, we will assume that the accumulator is the general-purpose register r0; otherwise we could simply renumber the registers. In this respect, the accumulator is somewhat similar to the top-ofstack \u201cregister\u201d s0 of a stack machine, because virtually all operations of a stack machine both use s0 as one of their arguments and return their result as s0.","title":"2.1.4. The top-of-stack register s0 vs. the accumulator register r0."},{"location":"TON Blockchain/TON Virtual Machine/#215-register-calling-conventions","text":"When compiled for a register machine, high-level language functions usually receive their arguments in certain registers in a predefined order. If there are too many arguments, these functions take the remainder from the stack (yes, a register machine usually has a stack, too!). Some register calling conventions pass no arguments in registers at all, however, and only use the stack (for example, the original calling conventions used in implementations of Pascal and C, although modern implementations of C use some registers as well). For simplicity, we will assume that up to m \u2264 n function arguments are passed in registers, and that these registers are r0, r1, . . . , r(m \u2212 1) , in that order (if some other registers are used, we can simply renumber them). Our inclusion of r0 here creates a minor conflict with our assumption that the accumulator register, if present, is also r0; for simplicity, we will resolve this problem by assuming that the first argument to a function is passed in the accumulator.","title":"2.1.5. Register calling conventions."},{"location":"TON Blockchain/TON Virtual Machine/#216-order-of-function-arguments","text":"If a function or primitive requires m arguments x1, . . . , xm , they are pushed by the caller into the stack in the same order, starting from x1. Therefore, when the function or primitive is invoked, its first argument x1 is in s(m \u2212 1), its second argument x2 is in s(m \u2212 2), and so on. The last argument xm is in s0 (i.e., at the top of the stack). It is the called function or primitive\u2019s responsibility to remove its arguments from the stack. In this respect the TVM stack calling conventions\u2014obeyed, at least, by TMV primitives\u2014match those of Pascal and Forth, and are the opposite of those of C (in which the arguments are pushed into the stack in the reverse order, and are removed by the caller after it regains control, not the callee). Of course, an implementation of a high-level language for TVM might choose some other calling conventions for its functions, different from the default ones. This might be useful for certain functions\u2014for instance, if the total number of arguments depends on the value of the first argument, as happens for \u201cvariadic functions\u201d such as scanf and printf. In such cases, the first one or several arguments are better passed near the top of the stack, not somewhere at some unknown location deep in the stack.","title":"2.1.6. Order of function arguments."},{"location":"TON Blockchain/TON Virtual Machine/#217-arguments-to-arithmetic-primitives-on-register-machines","text":"On a stack machine, built-in arithmetic primitives (such as ADD or DIVMOD) follow the same calling conventions as user-defined functions. In this respect, user-defined functions (for example, a function computing the square root of a number) might be considered as \u201cextensions\u201d or \u201ccustom upgrades\u201d of the stack machine. This is one of the clearest advantages of stack machines (and of stack programming languages such as Forth) compared to register machines. In contrast, arithmetic instructions (built-in operations) on register machines usually get their parameters from general-purpose registers encoded in the full opcode. A binary operation, such as SUB, thus requires two arguments, r(i) and r(j), with i and j specified by the instruction. A register r(k) for storing the result also must be specified. Arithmetic operations can take several possible forms, depending on whether i, j, and k are allowed to take arbitrary values: Three-address form \u2014 Allows the programmer to arbitrarily choose not only the two source registers r(i) and r(j), but also a separate destination register r(k). This form is common for most RISC processors, and for the XMM and AVX SIMD instruction sets in the x86-64 architecture. Two-address form \u2014 Uses one of the two operand registers (usually r(i)) to store the result of an operation, so that k = i is never indicated explicitly. Only i and j are encoded inside the instruction. This is the most common form of arithmetic operations on register machines, and is quite popular on microprocessors (including the x86 family). One-address form \u2014 Always takes one of the arguments from the accumulator r0, and stores the result in r0 as well; then i = k = 0, and only j needs to be specified by the instruction. This form is used by some simpler microprocessors (such as Intel 8080). Note that this flexibility is available only for built-in operations, but not for user-defined functions. In this respect, register machines are not as easily \u201cupgradable\u201d as stack machines. For instance, if one writes a function for extracting square roots, this function will always accept its argument and return its result in the same registers, in contrast with a hypothetical built-in square root instruction, which could allow the programmer to arbitrarily choose the source and destination registers. Therefore, a user-defined function is tremendously less flexible than a built-in instruction on a register machine.","title":"2.1.7. Arguments to arithmetic primitives on register machines."},{"location":"TON Blockchain/TON Virtual Machine/#218-return-values-of-functions","text":"In stack machines such as TVM, when a function or primitive needs to return a result value, it simply pushes it into the stack (from which all arguments to the function have already been removed). Therefore, the caller will be able to access the result value through the top-of-stack \u201cregister\u201d s0. This is in complete accordance with Forth calling conventions, but differs slightly from Pascal and C calling conventions, where the accumulator register r0 is normally used for the return value.","title":"2.1.8. Return values of functions."},{"location":"TON Blockchain/TON Virtual Machine/#219-returning-several-values","text":"Some functions might want to return several values y1, . . . , yk , with k not necessarily equal to one. In these cases, the k return values are pushed into the stack in their natural order, starting from y1. For example, the \u201cdivide with remainder\u201d primitive DIVMOD needs to return two values, the quotient q and the remainder r. Therefore, DIVMOD pushes q and r into the stack, in that order, so that the quotient is available return values in their place, by convention leaving all deeper values intact. Then the resulting stack, again in its entirety, is returned to the caller. Most TVM primitives behave in this way, and we expect most user-defined functions to be implemented under such conventions. However, TVM provides mechanisms to specify how many arguments must be passed to a called function (cf. 4.1.10 ). When these mechanisms are employed, the specified number of values are moved from the caller\u2019s stack into the (usually initially empty) stack of the called function, while deeper values remain in the caller\u2019s stack and are inaccessible to the callee. The caller can also specify how many return values it expects from the called function. Such argument-checking mechanisms might be useful, for example, for a library function that calls user-provided functions passed as arguments to it.","title":"2.1.9. Returning several values."},{"location":"TON Blockchain/TON Virtual Machine/#23-efficiency-of-stack-manipulation-primitives","text":"","title":"2.3 Efficiency of stack manipulation primitives"},{"location":"TON Blockchain/TON Virtual Machine/#235-absence-of-circular-references","text":"One might attempt to create a circular reference between two cells, A and B, as follows: first create A and write some data into it; then create B and write some data into it, along with a reference to previously constructed cell A; finally, add a reference to B into A. While it may seem that after this sequence of operations we obtain a cell A, which refers to B, which in turn refers to A, this is not the case. In fact, we obtain a new cell A0 , which contains a copy of the data originally stored into cell A along with a reference to cell B, which contains a reference to (the original) cell A. In this way the transparent copy-on-write mechanism and the \u201ceverything is a value\u201d paradigm enable us to create new cells using only previously constructed cells, thus forbidding the appearance of circular references. This property also applies to all other data structures: for instance, the absence of circular references enables TVM to use reference counting to immediately free unused memory instead of relying on garbage collectors. Similarly, this property is crucial for storing data in the TON Blockchain.","title":"2.3.5. Absence of circular references."},{"location":"TON Blockchain/TON Virtual Machine/#3-cell-memory-and-persistent-storage","text":"This chapter briefly describes TVM cells, used to represent all data structures inside the TVM memory and its persistent storage, and the basic operations used to create cells, write (or serialize) data into them, and read (or deserialize) data from them.","title":"3. Cell Memory and Persistent Storage"},{"location":"TON Blockchain/TON Virtual Machine/#31-generalities-on-cells","text":"This section presents a classification and general descriptions of cell types.","title":"3.1 Generalities on Cells"},{"location":"TON Blockchain/TON Virtual Machine/#311-tvm-memory-and-persistent-storage-consist-of-cells","text":"Recall that the TVM memory and persistent storage consist of (TVM) cells. Each cell contains up to 1023 bits of data and up to four references to other cells. Circular references are forbidden and cannot be created by means of TVM (cf. 2.3.5 ). In this way, all cells kept in TVM memory and persistent storage constitute a directed acyclic graph (DAG).","title":"3.1.1. TVM memory and persistent storage consist of cells."},{"location":"TON Blockchain/TON Virtual Machine/#312-ordinary-and-exotic-cells","text":"Apart from the data and references, a cell has a cell type, encoded by an integer \u22121. . . 255. A cell of type \u22121 is called ordinary; such cells do not require any special processing. Cells of other types are called exotic, and may be loaded\u2014automatically replaced by other cells when an attempt to deserialize them (i.e., to convert them into a Slice by a CTOS instruction) is made. They may also exhibit a non-trivial behavior when their hashes are computed. The most common use for exotic cells is to represent some other cells\u2014for instance, cells present in an external library, or pruned from the original tree of cells when a Merkle proof has been created. The type of an exotic cell is stored as the first eight bits of its data. If an exotic cell has less than eight data bits, it is invalid.","title":"3.1.2. Ordinary and exotic cells."},{"location":"TON Blockchain/TON Virtual Machine/#313-the-level-of-a-cell","text":"Every cell c has another attribute Lvl(c) called its (de Brujn) level, which currently takes integer values in the range 0. . . 3. The level of an ordinary cell is always equal to the maximum of the levels of all its children ci : \u200b Lvl(c) = max Lvl(ci) , where 1\u2264i\u2264r for an ordinary cell c containing r references to cells c1, . . . , cr. If r = 0, Lvl(c) = 0. Exotic cells may have different rules for setting their level. A cell\u2019s level affects the number of higher hashes it has. More precisely, a level l cell has l higher hashes Hash1(c), . . . , Hashl(c) in addition to its representation hash Hash(c) = Hash\u221e(c). Cells of non-zero level appear inside Merkle proofs and Merkle updates, after some branches of the tree of cells representing a value of an abstract data type are pruned","title":"3.1.3. The level of a cell."},{"location":"TON Blockchain/TON Virtual Machine/#314-standard-cell-representation","text":"When a cell needs to be transferred by a network protocol or stored in a disk file, it must be serialized. The standard representation CellRepr(c) = CellRepr\u221e(c) of a cell c as an octet (byte) sequence is constructed as follows: \\1. Two descriptor bytes d1 and d2 are serialized first. Byte d1 equals r+8s+32l , where 0 \u2264 r \u2264 4 is the quantity of cell references contained in the cell, 0 \u2264 l \u2264 3 is the level of the cell, and 0 \u2264 s \u2264 1 is 1 for exotic cells and 0 for ordinary cells. Byte d2 equals bb/8c+db/8e , where 0 \u2264 b \u2264 1023 is the quantity of data bits in c. \\2. Then the data bits are serialized as db/8e 8-bit octets (bytes). If b is not a multiple of eight, a binary 1 and up to six binary 0s are appended to the data bits. After that, the data is split into db/8e eight-bit groups, and each group is interpreted as an unsigned big-endian integer 0 . . . 255 and stored into an octet. \\3. Finally, each of the r cell references is represented by 32 bytes containing the 256-bit representation hash Hash(ci) , explained below in 3.1.5 , of the cell ci referred to. In this way, 2 + db/8e + 32r bytes of CellRepr(c) are obtained.","title":"3.1.4 Standard cell representation."},{"location":"TON Blockchain/TON Virtual Machine/#315-the-representation-hash-of-a-cell","text":"The 256-bit representation hash or simply hash Hash(c) of a cell c is recursively defined as the sha256 of the standard representation of the cell c: \u200b Hash(c) := sha256 := CellRepr(c) Notice that cyclic cell references are not allowed and cannot be created by means of the TVM (cf. 2.3.5 ), so this recursion always ends, and the representation hash of any cell is well-defined.","title":"3.1.5. The representation hash of a cell."},{"location":"TON Blockchain/TON Virtual Machine/#316-the-higher-hashes-of-a-cell","text":"Recall that a cell c of level l has l higher hashes Hashi(c) , 1 \u2264 i \u2264 l , as well. Exotic cells have their own rules for computing their higher hashes. Higher hashes Hashi(c) of an ordinary cell c are computed similarly to its representation hash, but using the higher hashes Hashi(cj) of its children cj instead of their representation hashes Hash(cj) . By convention, we set Hash\u221e(c) := Hash(c) , and Hashi(c) := Hash\u221e(c) = Hash(c) for all i l. 12","title":"3.1.6. The higher hashes of a cell."},{"location":"TON Blockchain/TON Virtual Machine/#317-types-of-exotic-cells","text":"TVM currently supports the following cell types: Type \u22121: Ordinary cell \u2014 Contains up to 1023 bits of data and up to four cell references. Type 1: Pruned branch cell c \u2014 May have any level 1 \u2264 l \u2264 3 . It contains exactly 8 + 256l data bits: first an 8-bit integer equal to 1 (representing the cell\u2019s type), then its l higher hashes Hash1(c), . . . , Hashl(c) . The level l of a pruned branch cell may be called its de Brujn index, because it determines the outer Merkle proof or Merkle update during the construction of which the branch has been pruned. An attempt to load a pruned branch cell usually leads to an exception. Type 2: Library reference cell \u2014 Always has level 0, and contains 8+256 data bits, including its 8-bit type integer 2 and the representation hash Hash(c0) of the library cell being referred to. When loaded, a library reference cell may be transparently replaced by the cell it refers to, if found in the current library context. Type 3: Merkle proof cell c \u2014 Has exactly one reference c1 and level 0 \u2264 l \u2264 3, which must be one less than the level of its only child c1: Lvl(c) = max(Lvl(c1) \u2212 1, 0) The 8 + 256 data bits of a Merkle proof cell contain its 8-bit type integer 3, followed by Hash1(c1) (assumed to be equal to Hash(c1) if Lvl(c1) = 0 ). The higher hashes Hashi(c) of c are computed similarly to the higher hashes of an ordinary cell, but with Hashi+1(c1) used instead of Hashi(c1) . When loaded, a Merkle proof cell is replaced by c1. Type 4: Merkle update cell c \u2014 Has two children c1 and c2. Its level 0 \u2264 l \u2264 3 is given by Lvl(c) = max(Lvl(c1) \u2212 1 , Lvl(c2) \u2212 1, 0) (4) A Merkle update behaves like a Merkle proof for both c1 and c2, and contains 8 + 256 + 256 data bits with Hash1(c1) and Hash1(c2) . However, an extra requirement is that all pruned branch cells c 0 that are descendants of c2 and are bound by c must also be descendants of c1^13 .When a Merkle update cell is loaded, it is replaced by c2.","title":"3.1.7. Types of exotic cells."},{"location":"TON Blockchain/TON Virtual Machine/#32-data-manipulation-instructions-and-cells","text":"The next large group of TVM instructions consists of data manipulation instructions, also known as cell manipulation instructions or simply cell instructions. They correspond to memory access instructions of other architectures.","title":"3.2 Data manipulation instructions and cells"},{"location":"TON Blockchain/TON Virtual Machine/#321-classes-of-cell-manipulation-instructions","text":"The TVM cell instructions are naturally subdivided into two principal classes: \u2022 Cell creation instructions or serialization instructions, used to construct new cells from values previously kept in the stack and previously constructed cells. \u2022 Cell parsing instructions or deserialization instructions, used to extract data previously stored into cells by cell creation instructions. Additionally, there are exotic cell instructions used to create and inspect exotic cells (cf. 3.1.2 ), which in particular are used to represent pruned branches of Merkle proofs and Merkle proofs themselves.","title":"3.2.1. Classes of cell manipulation instructions."},{"location":"TON Blockchain/TON Virtual Machine/#322-builder-and-slice-values","text":"Cell creation instructions usually work with Builder values, which can be kept only in the stack (cf. 1.1.3 ). Such values represent partially constructed cells, for which fast operations for appending bitstrings, integers, other cells, and references to other cells can be defined. Similarly, cell parsing instructions make heavy use of Slice values, which represent either the remainder of a partially parsed cell, or a value (subcell) residing inside such a cell and extracted from it by a parsing instruction.","title":"3.2.2. Builder and Slice values."},{"location":"TON Blockchain/TON Virtual Machine/#4-control-flow-continuations-and-exceptions","text":"This chapter describes continuations, which may represent execution tokens and exception handlers in TVM. Continuations are deeply involved with the control flow of a TVM program; in particular, subroutine calls and conditional and iterated execution are implemented in TVM using special primitives that accept one or more continuations as their arguments. We conclude this chapter with a discussion of the problem of recursion and of families of mutually recursive functions, exacerbated by the fact that cyclic references are not allowed in TVM data structures (including TVM code).","title":"4. Control Flow, Continuations, and Exceptions"},{"location":"TON Blockchain/TON Virtual Machine/#41-continuations-and-subroutines","text":"","title":"4.1. Continuations and subroutines"},{"location":"TON Blockchain/TON Virtual Machine/#4110-determining-the-number-of-arguments-passed-to-andor-return-values-accepted-from-a-subroutine","text":"Similarly to JMPX and RET, CALLX also has special (rarely used) forms, which allow us to explicitly specify the number n 00 of arguments passed from the current stack to the called subroutine (by default, n 00 equals the depth of the current stack, i.e., it is passed in its entirety). Furthermore, a second number n 000 can be specified, used to set nargs of the modified cc continuation before storing it into the new c0; the new nargs equals the depth of the old stack minus n 00 plus n 000 . This means that the caller is willing to pass exactly n 00 arguments to the called subroutine, and is willing to accept exactly n 000 results in their stead. Such forms of CALLX and RET are mostly intended for library functions that accept functional arguments and want to invoke them safely. Another application is related to the \u201cvirtualization support\u201d of TVM, which enables TVM code to run other TVM code inside a \u201cvirtual TVM machine\u201d. Such virtualization techniques might be useful for implementing sophisticated payment channels in the TON Blockchain (cf. 5 ]).","title":"4.1.10. Determining the number of arguments passed to and/or return values accepted from a subroutine."},{"location":"TON Blockchain/TON Virtual Machine/#appendix","text":"","title":"Appendix"},{"location":"TON Blockchain/TON Virtual Machine/#a","text":"","title":"A"},{"location":"TON Blockchain/TON Virtual Machine/#a1-gas-prices","text":"The gas price for most primitives equals the basic gas price, computed as Pb := 10 + b + 5r , where b is the instruction length in bits and r is the number of cell references included in the instruction. When the gas price of an instruction differs from this basic price, it is indicated in parentheses after its mnemonics, either as (x), meaning that the total gas price equals x, or as (+x), meaning Pb + x. Apart from integer constants, the following expressions may appear: Cr \u2014 The total price of \u201creading\u201d cells (i.e., transforming cell references into cell slices). Currently equal to 20 gas units per cell. L \u2014 The total price of loading cells. Depends on the loading action required. Bw \u2014 The total price of creating new Builders. Currently equal to 100 gas units per builder. Cw \u2014 The total price of creating new Cells from Builders). Currently equal to 100 gas units per cell.","title":"A.1  Gas prices"},{"location":"TON Blockchain/TON Virtual Machine/#a42-constant-slices-continuations-cells-and-references","text":"Most of the instructions listed below push literal slices, continuations, cells, and cell references, stored as immediate arguments to the instruction. Therefore, if the immediate argument is absent or too short, an \u201cinvalid or too short opcode\u201d exception (code 6) is thrown. 88 \u2014 PUSHREF, pushes the first reference of cc.code into the stack as a Cell (and removes this reference from the current continuation). 89 \u2014 PUSHREFSLICE, similar to PUSHREF, but converts the cell into a Slice. 8A \u2014 PUSHREFCONT, similar to PUSHREFSLICE, but makes a simple ordinary Continuation out of the cell. 8Bxsss \u2014 PUSHSLICE sss, pushes the (prefix) subslice of cc.code consisting of its first 8x + 4 bits and no references (i.e., essentially a bitstring), where 0 \u2264 x \u2264 15. A completion tag is assumed, meaning that all trailing zeroes and the last binary one (if present) are removed from this bitstring. If the original bitstring consists only of zeroes, an empty slice will be pushed. 8B08 \u2014 PUSHSLICE x8_, pushes an empty slice (bitstring \u2018\u2019). 8B04 \u2014 PUSHSLICE x4_, pushes bitstring \u20180\u2019. 8B0C \u2014 PUSHSLICE xC_, pushes bitstring \u20181\u2019. 8Crxxssss \u2014 PUSHSLICE ssss, pushes the (prefix) subslice of cc.code consisting of its first 1 \u2264 r + 1 \u2264 4 references and up to first 8xx + 1 bits of data, with 0 \u2264 xx \u2264 31. A completion tag is also assumed. 8C01 is equivalent to PUSHREFSLICE. 8Drxxsssss \u2014 PUSHSLICE sssss, pushes the subslice of cc.code consisting of 0 \u2264 r \u2264 4 references and up to 8xx + 6 bits of data, with 0 \u2264 xx \u2264 127. A completion tag is assumed. 8DE_ \u2014 unused (reserved). 8F_rxxcccc \u2014 PUSHCONT cccc, where cccc is the simple ordinary continuation made from the first 0 \u2264 r \u2264 3 references and the first 0 \u2264 xx \u2264 127 bytes of cc.code. 9xccc \u2014 PUSHCONT ccc, pushes an x-byte continuation for 0 \u2264 x \u2264 15.","title":"A.4.2. Constant slices, continuations, cells, and references."},{"location":"TON Blockchain/TON Whitepaper/","text":"TON Whitepaper A Brief Description of TON Components The Telegram Open Network (TON) is a combination of the following components: A flexible multi-blockchain platform (TON Blockchain; cf. Chapter 2 ), capable of processing millions of transactions per second, with Turingcomplete smart contracts, upgradable formal blockchain specifications, multi-cryptocurrency value transfer, support for micropayment channels and off-chain payment networks. TON Blockchain presents some new and unique features, such as the \u201cself-healing\u201d vertical blockchain mechanism (cf. 2.1.17 ) and Instant Hypercube Routing (cf. 2.4.20 ), which enable it to be fast, reliable, scalable and self-consistent at the same time. A peer-to-peer network (TON P2P Network, or just TON Network; cf. Chapter 3 ), used for accessing the TON Blockchain, sending transaction candidates, and receiving updates about only those parts of the blockchain a client is interested in (e.g., those related to the client\u2019s accounts and smart contracts), but also able to support arbitrary distributed services, blockchain-related or not. A distributed file storage technology (TON Storage; cf. 4.1.8 ), accessible through TON Network, used by the TON Blockchain to store archive copies of blocks and status data (snapshots), but also available for storing arbitrary files for users or other services running on the platform, with torrent-like access technology. A network proxy/anonymizer layer (TON Proxy; cf. 4.1.11 and 3.1.6 ), similar to the I 2P (Invisible Internet Project), used to hide the identity and IP addresses of TON Network nodes if necessary (e.g., nodes committing transactions from accounts with large amounts of cryptocurrency, or high-stake blockchain validator nodes who wish to hide their exact IP address and geographical location as a measure against DDoS attacks). A Kademlia-like distributed hash table (TON DHT; cf. 3.2 ), used as a \u201ctorrent tracker\u201d for TON Storage (cf. 3.2.10 ), as an \u201cinput tunnel locator\u201d for TON Proxy (cf. 3.2.14 ), and as a service locator for TON Services (cf. 3.2.12 ). A platform for arbitrary services (TON Services; cf. Chapter 4 ), residing in and available through TON Network and TON Proxy, with formalized interfaces (cf. 4.3.14 ) enabling browser-like or smartphone application interaction. These formal interfaces and persistent service entry points can be published in the TON Blockchain (cf. 4.3.17 ); actual nodes providing service at any given moment can be looked up through the TON DHT starting from information published in the TON Blockchain (cf. 3.2.12 ). Services may create smart contracts in the TON Blockchain to offer some guarantees to their clients (cf. 4.1.7 ). TON DNS (cf. 4.3.1 ), a service for assigning human-readable names to accounts, smart contracts, services and network nodes. TON Payments (cf. Chapter 5 ), a platform for micropayments, micropayment channels and a micropayment channel network. It can be used for fast off-chain value transfers, and for paying for services powered by TON Services. TON will allow easy integration with third-party messaging and social networking applications, thus making blockchain technologies and distributed services finally available and accessible to ordinary users (cf. 4.3.24 ), rather than just to a handful of early cryptocurrency adopters. We will provide an example of such an integration in another of our projects, the Telegram Messenger (cf. 4.3.19 ). While the TON Blockchain is the core of the TON project, and the other components might be considered as playing a supportive role for the blockchain, they turn out to have useful and interesting functionality by themselves. Combined, they allow the platform to host more versatile applications than it would be possible by just using the TON Blockchain (cf. 2.9.13 and 4.1 ). Introduction The aim of this text is to provide a first description of the Telegram Open Network (TON) and related blockchain, peer-to-peer, distributed storage and service hosting technologies. To reduce the size of this document to reasonable proportions, we focus mainly on the unique and defining features of the TON platform that are important for it to achieve its stated goals. The Telegram Open Network (TON) is a fast, secure and scalable blockchain and network project, capable of handling millions of transactions per second if necessary, and both user-friendly and service provider-friendly. We aim for it to be able to host all reasonable applications currently proposed and conceived. One might think about TON as a huge distributed supercomputer, or rather a huge \u201csuperserver\u201d, intended to host and provide a variety of services. This text is not intended to be the ultimate reference with respect to all implementation details. Some particulars are likely to change during the development and testing phases. TON Blockchain 2.1 TON Blockchain as a Collection of 2-Blockchains The TON Blockchain is actually a collection of blockchains (even a collection of blockchains of blockchains, or 2-blockchains\u2014this point will be clarified later in 2.1.17 ), because no single blockchain project is capable of achieving our goal of processing millions of transactions per second, as opposed to the now-standard dozens of transactions per second. 2.1.1. List of blockchain types. The blockchains in this collection are: The unique master blockchain, or masterchain for short, containing general information about the protocol and the current values of its parameters, the set of validators and their stakes, the set of currently active workchains and their \u201cshards\u201d, and, most importantly, the set of hashes of the most recent blocks of all workchains and shardchains. Several (up to 2^32) working blockchains, or workchains for short, which are actually the \u201cworkhorses\u201d, containing the value-transfer and smartcontract transactions. Different workchains may have different \u201crules\u201d, meaning different formats of account addresses, different formats of transactions, different virtual machines (VMs) for smart contracts, different basic cryptocurrencies and so on. However, they all must satisfy certain basic interoperability criteria to make interaction between different workchains possible and relatively simple. In this respect, the TON Blockchain is heterogeneous (cf. 2.8.8 ), similarly to the EOS (cf. 2.9.7 ) and PolkaDot (cf. 2.9.8 ) projects. Each workchain is in turn subdivided into up to 2^60 shard blockchains, or shardchains for short, having the same rules and block format as the workchain itself, but responsible only for a subset of accounts, depending on several first (most significant) bits of the account address. In other words, a form of sharding is built into the system (cf. 2.8.12 ). Because all these shardchains share a common block format and rules, the TON Blockchain is homogeneous in this respect (cf. 2.8.8 ), similarly to what has been discussed in one of Ethereum scaling proposals.* * https://github.com/ethereum/wiki/wiki/Sharding-FAQ Each block in a shardchain (and in the masterchain) is actually not just a block, but a small blockchain. Normally, this \u201cblock blockchain\u201d or \u201cvertical blockchain\u201d consists of exactly one block, and then we might think this is just the corresponding block of the shardchain (also called \u201chorizontal blockchain\u201d in this situation). However, if it becomes necessary to fix incorrect shardchain blocks, a new block is committed into the \u201cvertical blockchain\u201d, containing either the replacement for the invalid \u201chorizontal blockchain\u201d block, or a \u201cblock difference\u201d, containing only a description of those parts of the previous version of this block that need to be changed. This is a TON-specific mechanism to replace detected invalid blocks without making a true fork of all shardchains involved; it will be explained in more detail in 2.1.17 . For now, we just remark that each shardchain (and the masterchain) is not a conventional blockchain, but a blockchain of blockchains, or 2D-blockchain, or just a 2-blockchain. 2.1.2. Infinite Sharding Paradigm. Almost all blockchain sharding proposals are \u201ctop-down\u201d: one first imagines a single blockchain, and then discusses how to split it into several interacting shardchains to improve performance and achieve scalability. The TON approach to sharding is \u201cbottom-up\u201d, explained as follows. Imagine that sharding has been taken to its extreme, so that exactly one account or smart contract remains in each shardchain. Then we have a huge number of \u201caccount-chains\u201d, each describing the state and state transitions of only one account, and sending value-bearing messages to each other to transfer value and information. Of course, it is impractical to have hundreds of millions of blockchains, with updates (i.e., new blocks) usually appearing quite rarely in each of them. In order to implement them more efficiently, we group these \u201caccount-chains\u201d into \u201cshardchains\u201d, so that each block of the shardchain is essentially a collection of blocks of account-chains that have been assigned to this shard. Thus the \u201caccount-chains\u201d have only a purely virtual or logical existence inside the \u201cshardchains\u201d. We call this perspective the Infinite Sharding Paradigm . It explains many of the design decisions for the TON Blockchain. 2.1.3. Messages. Instant Hypercube Routing. The Infinite Sharding Paradigm instructs us to regard each account (or smart contract) as if it were in its own shardchain by itself. Then the only way one account might affect the state of another is by sending a message to it (this is a special instance of the so-called Actor model, with accounts as Actors; cf. 2.4.2 ). Therefore, a system of messages between accounts (and shardchains, because the source and destination accounts are, generally speaking, located in different shardchains) is of paramount importance to a scalable system such as the TON Blockchain. In fact, a novel feature of the TON Blockchain, called Instant Hypercube Routing (cf. 2.4.20 ), enables it to deliver and process a message created in a block of one shardchain into the very next block of the destination shardchain, regardless of the total number of shardchains in the system. 2.1.4. Quantity of masterchains, workchains and shardchains. A TON Blockchain contains exactly one masterchain. However, the system can potentially accommodate up to 2^32 workchains, each subdivided into up to 2^60 shardchains. 2.1.5. Workchains can be virtual blockchains, not true blockchains. Because a workchain is usually subdivided into shardchains, the existence of the workchain is \u201cvirtual\u201d, meaning that it is not a true blockchain in the sense of the general definition provided in 2.2.1 below, but just a collection of shardchains. When only one shardchain corresponds to a workchain, this unique shardchain may be identified with the workchain, which in this case becomes a \u201ctrue\u201d blockchain, at least for some time, thus gaining a superficial similarity to customary single-blockchain design. However, the Infinite Sharding Paradigm (cf. 2.1.2 ) tells us that this similarity is indeed superficial: it is just a coincidence that the potentially huge number of \u201caccountchains\u201d can temporarily be grouped into one blockchain. 2.1.6. Identification of workchains. Each workchain is identified by its number or workchain identifier (workchain_id : uint32) , which is simply an unsigned 32-bit integer. Workchains are created by special transactions in the masterchain, defining the (previously unused) workchain identifier and the formal description of the workchain, sufficient at least for the interaction of this workchain with other workchains and for superficial verification of this workchain\u2019s blocks. 2.1.7. Creation and activation of new workchains. The creation of a new workchain may be initiated by essentially any member of the community, ready to pay the (high) masterchain transaction fees required to publish the formal specification of a new workchain. However, in order for the new workchain to become active, a two-thirds consensus of validators is required, because they will need to upgrade their software to process blocks of the new workchain, and signal their readiness to work with the new workchain by special masterchain transactions. The party interested in the activation of the new workchain might provide some incentive for the validators to support the new workchain by means of some rewards distributed by a smart contract. 2.1.8. Identification of shardchains. Each shardchain is identified by a couple (w, s) = (workchain_id,shard_prefix) , where workchain_id : uint32 identifies the corresponding workchain, and shard_prefix : 2^0...60 is a bit string of length at most 60, defining the subset of accounts for which this shardchain is responsible. Namely, all accounts with account_id starting with shard_prefix (i.e., having shard_prefix as most significant bits) will be assigned to this shardchain. 2.1.9. Identification of account-chains. Recall that account-chains have only a virtual existence (cf. 2.1.2 ). However, they have a natural identifier\u2014 namely, (workchain_id, account_id)\u2014because any account-chain contains information about the state and updates of exactly one account (either a simple account or smart contract\u2014the distinction is unimportant here). 2.1.10. Dynamic splitting and merging of shardchains; cf. 2.7 . A less sophisticated system might use static sharding\u2014for example, by using the top eight bits of the account_id to select one of 256 pre-defined shards. An important feature of the TON Blockchain is that it implements dynamic sharding, meaning that the number of shards is not fixed. Instead, shard (w, s) can be automatically subdivided into shards (w, s.0) and (w, s.1) if some formal conditions are met (essentially, if the transaction load on the original shard is high enough for a prolonged period of time). Conversely, if the load stays too low for some period of time, the shards (w, s.0) and (w, s.1) can be automatically merged back into shard (w, s). Initially, only one shard (w, \u2205) is created for workchain *w* . Later, it is subdivided into more shards, if and when this becomes necessary (cf. 2.7.6 and 2.7.8 ). 2.1.11. Basic workchain or Workchain Zero. While up to 2^32 workchains can be defined with their specific rules and transactions, we initially define only one, with workchain_id = 0 . This workchain, called Workchain Zero or the basic workchain, is the one used to work with TON smart contracts and transfer TON coins, also known as Grams (cf. Appendix A ). Most applications are likely to require only Workchain Zero. Shardchains of the basic workchain will be called basic shardchains. 2.1.12. Block generation intervals. We expect a new block to be generated in each shardchain and the masterchain approximately once every five seconds. This will lead to reasonably small transaction confirmation times. New blocks of all shardchains are generated approximately simultaneously; a new block of the masterchain is generated approximately one second later, because it must contain the hashes of the latest blocks of all shardchains. 2.1.13. Using the masterchain to make workchains and shardchains tightly coupled. Once the hash of a block of a shardchain is incorporated into a block of the masterchain, that shardchain block and all its ancestors are considered \u201ccanonical\u201d, meaning that they can be referenced from the subsequent blocks of all shardchains as something fixed and immutable. In fact, each new shardchain block contains a hash of the most recent masterchain block, and all shardchain blocks referenced from that masterchain block are considered immutable by the new block. Essentially, this means that a transaction or a message committed in a shardchain block may be safely used in the very next blocks of the other shardchains, without needing to wait for, say, twenty confirmations (i.e., twenty blocks generated after the original block in the same blockchain) before forwarding a message or taking other actions based on a previous transaction, as is common in most proposed \u201cloosely-coupled\u201d systems (cf. 2.8.14 ), such as EOS. This ability to use transactions and messages in other shardchains a mere five seconds after being committed is one of the reasons we believe our \u201ctightly-coupled\u201d system, the first of its kind, will be able to deliver unprecedented performance (cf. 2.8.12 and 2.8.14 ). 2.1.14. Masterchain block hash as a global state. According to 2.1.13 , the hash of the last masterchain block completely determines the overall state of the system from the perspective of an external observer. One does not need to monitor the state of all shardchains separately. 2.1.15. Generation of new blocks by validators; cf. 2.6 . The TON Blockchain uses a Proof-of-Stake (PoS) approach for generating new blocks in the shardchains and the masterchain. This means that there is a set of, say, up to a few hundred validators\u2014special nodes that have deposited stakes (large amounts of TON coins) by a special masterchain transaction to be eligible for new block generation and validation. Then a smaller subset of validators is assigned to each shard (w, s) in a deterministic pseudorandom way, changing approximately every 1024 blocks. This subset of validators suggests and reaches consensus on what the next shardchain block would be, by collecting suitable proposed transactions from the clients into new valid block candidates. For each block, there is a pseudorandomly chosen order on the validators to determine whose block candidate has the highest priority to be committed at each turn. Validators and other nodes check the validity of the proposed block candidates; if a validator signs an invalid block candidate, it may be automatically punished by losing part or all of its stake, or by being suspended from the set of validators for some time. After that, the validators should reach consensus on the choice of the next block, essentially by an efficient variant of the BFT (Byzantine Fault Tolerant; cf. 2.8.4 ) consensus protocol, similar to PBFT [ 4 ] or Honey Badger BFT [ 11 ]. If consensus is reached, a new block is created, and validators divide between themselves the transaction fees for the transactions included, plus some newly-created (\u201cminted\u201d) coins. Each validator can be elected to participate in several validator subsets; in this case, it is expected to run all validation and consensus algorithms in parallel. After all new shardchain blocks are generated or a timeout is passed, a new masterchain block is generated, including the hashes of the latest blocks of all shardchains. This is done by BFT consensus of all validators.* More detail on the TON PoS approach and its economical model is provided in section 2.6 . *Actually, two-thirds by stake is enough to achieve consensus, but an effort is made to collect as many signatures as possible. 2.1.16. Forks of the masterchain. A complication that arises from our tightly-coupled approach is that switching to a different fork in the masterchain will almost necessarily require switching to another fork in at least some of the shardchains. On the other hand, as long as there are no forks in the masterchain, no forks in the shardchain are even possible, because no blocks in the alternative forks of the shardchains can become \u201ccanonical\u201d by having their hashes incorporated into a masterchain block. The general rule is that if masterchain block B' is a predecessor of B, B' includes hash Hash(B' w,s) of (w, s)-shardchain block B' w,s, and B includes hash Hash(Bw,s), then B'w,s must be a predecessor of Bw,s; otherwise, the masterchain block B is invalid. We expect masterchain forks to be rare, next to non-existent, because in the BFT paradigm adopted by the TON Blockchain they can happen only in the case of incorrect behavior by a majority of validators (cf. 2.6.1 and 2.6.15 ), which would imply significant stake losses by the offenders. Therefore, no true forks in the shardchains should be expected. Instead, if an invalid shardchain block is detected, it will be corrected by means of the \u201cvertical blockchain\u201d mechanism of the 2-blockchain (cf. 2.1.17 ), which can achieve this goal without forking the \u201chorizontal blockchain\u201d (i.e., the shardchain). The same mechanism can be used to fix non-fatal mistakes in the masterchain blocks as well. 2.1.17. Correcting invalid shardchain blocks. Normally, only valid shardchain blocks will be committed, because validators assigned to the shardchain must reach a two-thirds Byzantine consensus before a new block can be committed. However, the system must allow for detection of previously committed invalid blocks and their correction. Of course, once an invalid shardchain block is found\u2014either by a validator (not necessarily assigned to this shardchain) or by a \u201cfisherman\u201d (any node of the system that made a certain deposit to be able to raise questions about block validity; cf. 2.6.4 )\u2014the invalidity claim and its proof are committed into the masterchain, and the validators that have signed the invalid block are punished by losing part of their stake and/or being temporarily suspended from the set of validators (the latter measure is important for the case of an attacker stealing the private signing keys of an otherwise benign validator). However, this is not sufficient, because the overall state of the system (TON Blockchain) turns out to be invalid because of the invalid shardchain block previously committed. This invalid block must be replaced by a newer valid version. Most systems would achieve this by \u201crolling back\u201d to the last block before the invalid one in this shardchain and the last blocks unaffected by messages propagated from the invalid block in each of the other shardchains, and creating a new fork from these blocks. This approach has the disadvantage that a large number of otherwise correct and committed transactions are suddenly rolled back, and it is unclear whether they will be included later at all. The TON Blockchain solves this problem by making each \u201cblock\u201d of each shardchain and of the masterchain (\u201chorizontal blockchains\u201d) a small blockchain (\u201cvertical blockchain\u201d) by itself, containing different versions of this \u201cblock\u201d, or their \u201cdifferences\u201d. Normally, the vertical blockchain consists of exactly one block, and the shardchain looks like a classical blockchain. However, once the invalidity of a block is confirmed and committed into a masterchain block, the \u201cvertical blockchain\u201d of the invalid block is allowed to grow by a new block in the vertical direction, replacing or editing the invalid block. The new block is generated by the current validator subset for the shardchain in question. The rules for a new \u201cvertical\u201d block to be valid are quite strict. In particular, if a virtual \u201caccount-chain block\u201d (cf. 2.1.2 ) contained in the invalid block is valid by itself, it must be left unchanged by the new vertical block. Once a new \u201cvertical\u201d block is committed on top of the invalid block, its hash is published in a new masterchain block (or rather in a new \u201cvertical\u201d block, lying above the original masterchain block where the hash of the invalid shardchain block was originally published), and the changes are propagated further to any shardchain blocks referring to the previous version of this block (e.g., those having received messages from the incorrect block). This is fixed by committing new \u201cvertical\u201d blocks in vertical blockchains for all blocks previously referring to the \u201cincorrect\u201d block; new vertical blocks will refer to the most recent (corrected) versions instead. Again, strict rules forbid changing account-chains that are not really affected (i.e., that receive the same messages as in the previous version). In this way, fixing an incorrect block generates \u201cripples\u201d that are ultimately propagated towards the most recent blocks of all affected shardchains; these changes are reflected in new \u201cvertical\u201d masterchain blocks as well. Once the \u201chistory rewriting\u201d ripples reach the most recent blocks, the new shardchain blocks are generated in one version only, being successors of the newest block versions only. This means that they will contain references to the correct (most recent) vertical blocks from the very beginning. The masterchain state implicitly defines a map transforming the hash of the first block of each \u201cvertical\u201d blockchain into the hash of its latest version. This enables a client to identify and locate any vertical blockchain by the hash of its very first (and usually the only) block. 2.1.18. TON coins and multi-currency workchains. The TON Blockchain supports up to 2^32 different \u201ccryptocurrencies\u201d, \u201ccoins\u201d, or \u201ctokens\u201d, distinguished by a 32-bit currency_id . New cryptocurrencies can be added by special transactions in the masterchain. Each workchain has a basic cryptocurrency, and can have several additional cryptocurrencies. There is one special cryptocurrency with currency_id = 0 , namely, the TON coin, also known as the Gram (cf. Appendix A). It is the basic cryptocurrency of Workchain Zero. It is also used for transaction fees and validator stakes. In principle, other workchains may collect transaction fees in other tokens. In this case, some smart contract for automated conversion of these transaction fees into Grams should be provided. 2.1.19. Messaging and value transfer. Shardchains belonging to the same or different workchains may send messages to each other. While the exact form of the messages allowed depends on the receiving workchain and receiving account (smart contract), there are some common fields making inter-workchain messaging possible. In particular, each message may have some value attached, in the form of a certain amount of Grams (TON coins) and/or other registered cryptocurrencies, provided they are declared as acceptable cryptocurrencies by the receiving workchain. The simplest form of such messaging is a value transfer from one (usually not a smart-contract) account to another. 2.1.20. TON Virtual Machine. The TON Virtual Machine, also abbreviated as TON VM or TVM , is the virtual machine used to execute smart-contract code in the masterchain and in the basic workchain. Other workchains may use other virtual machines alongside or instead of the TVM. Here we list some of its features. They are discussed further in 2.3.12 , 2.3.14 and elsewhere. TVM represents all data as a collection of (TVM) cells (cf. 2.3.14 ). Each cell contains up to 128 data bytes and up to 4 references to other cells. As a consequence of the \u201ceverything is a bag of cells\u201d philosophy (cf. 2.5.14 ), this enables TVM to work with all data related to the TON Blockchain, including blocks and blockchain global state if necessary. TVM can work with values of arbitrary algebraic data types (cf. 2.3.12 ), represented as trees or directed acyclic graphs of TVM cells. However, it is agnostic towards the existence of algebraic data types; it just works with cells. TVM has built-in support for hashmaps (cf. 2.3.7 ). TVM is a stack machine. Its stack keeps either 64-bit integers or cell references. 64-bit, 128-bit and 256-bit arithmetic is supported. All n-bit arithmetic operations come in three flavors: for unsigned integers, for signed integers and for integers modulo 2^n (no automatic overflow checks in the latter case). TVM has unsigned and signed integer conversion from n-bit to m-bit, for all 0 \u2264 m, n \u2264 256, with overflow checks. All arithmetic operations perform overflow checks by default, greatly simplifying the development of smart contracts. TVM has \u201cmultiply-then-shift\u201d and \u201cshift-then-divide\u201d arithmetic operations with intermediate values computed in a larger integer type; this simplifies implementing fixed-point arithmetic. TVM offers support for bit strings and byte strings. Support for 256-bit Elliptic Curve Cryptography (ECC) for some predefined curves, including Curve25519, is present. Support for Weil pairings on some elliptic curves, useful for fast implementation of zk-SNARKs, is also present. Support for popular hash functions, including sha256, is present. TVM can work with Merkle proofs (cf. 5.1.9 ). TVM offers support for \u201clarge\u201d or \u201cglobal\u201d smart contracts. Such smart contracts must be aware of sharding (cf. 2.3.18 and 2.3.16 ). Usual (local) smart contracts can be sharding-agnostic. TVM supports closures. A \u201cspineless tagless G-machine\u201d [ 13 ] can be easily implemented inside TVM. Several high-level languages can be designed for TVM, in addition to the \u201cTVM assembly\u201d. All these languages will have static types and will support algebraic data types. We envision the following possibilities: A Java-like imperative language, with each smart contract resembling a separate class. A lazy functional language (think of Haskell). An eager functional language (think of ML). 2.1.21. Configurable parameters. An important feature of the TON Blockchain is that many of its parameters are configurable. This means that they are part of the masterchain state, and can be changed by certain special proposal/vote/result transactions in the masterchain, without any need for hard forks. Changing such parameters will require collecting two-thirds of validator votes and more than half of the votes of all other participants who would care to take part in the voting process in favor of the proposal. 2.2 Generalities on Blockchains 2.2.1. General blockchain definition. In general, any (true) blockchain is a sequence of blocks , each block B containing a reference blk-prev(B) to the previous block (usually by including the hash of the previous block into the header of the current block), and a list of transactions. Each transaction describes some transformation of the global blockchain state ; the transactions listed in a block are applied sequentially to compute the new state starting from the old state, which is the resulting state after the evaluation of the previous block. 2.2.2. Relevance for the TON Blockchain. Recall that the TON Blockchain is not a true blockchain, but a collection of 2-blockchains (i.e., of blockchains of blockchains; cf. 2.1.1 ), so the above is not directly applicable to it. However, we start with these generalities on true blockchains to use them as building blocks for our more sophisticated constructions. 2.2.3. Blockchain instance and blockchain type. One often uses the word blockchain to denote both a general blockchain type and its specific blockchain instances, defined as sequences of blocks satisfying certain conditions. For example, 2.2.1 refers to blockchain instances. In this way, a blockchain type is usually a \u201csubtype\u201d of the type Block\u2217 of lists (i.e., finite sequences) of blocks, consisting of those sequences of blocks that satisfy certain compatibility and validity conditions: \u200b Blockchain \u2282 Block* (1) A better way to define Blockchain would be to say that Blockchain is a dependent couple type , consisting of couples (B, v), with first component B : Block\u2217 being of type Block\u2217 (i.e., a list of blocks), and the second component v : isValidBc(B) being a proof or a witness of the validity of B. In this way, \u200b Blockchain \u2261 \u03a3*(B:Block\u2217 )* isValidBc(B) (2) We use here the notation for dependent sums of types borrowed from [ 16 ]. 2.2.4. Dependent type theory, Coq and TL. Note that we are using (Martin-L\u00f6f) dependent type theory here, similar to that used in the Coq proof assistant. A simplified version of dependent type theory is also used in TL (Type Language) , * which will be used in the formal specification of the TON Blockchain to describe the serialization of all data structures and the layouts of blocks, transactions, and the like. In fact, dependent type theory gives a useful formalization of what a proof is, and such formal proofs (or their serializations) might become handy when one needs to provide proof of invalidity for some block, for example. * https://coq.inria.fr ** https://core.telegram.org/mtproto/TL 2.2.5. TL, or the Type Language. Since TL (Type Language) will be used in the formal specifications of TON blocks, transactions, and network datagrams, it warrants a brief discussion. TL is a language suitable for description of dependent algebraic types,which are allowed to have numeric (natural) and type parameters. Each type is described by means of several constructors. Each constructor has a (human-readable) identifier and a name, which is a bit string (32-bit integer by default). Apart from that, the definition of a constructor contains a list of fields along with their types. A collection of constructor and type definitions is called a TL-scheme. It is usually kept in one or several files with the suffix .tl. An important feature of TL-schemes is that they determine an unambiguous way of serializing and deserializing values (or objects) of algebraic types defined. Namely, when a value needs to be serialized into a stream of bytes, first the name of the constructor used for this value is serialized. Recursively computed serializations of each field follow. The description of a previous version of TL, suitable for serializing arbitrary objects into sequences of 32-bit integers, is available at https://core.telegram.org/mtproto/ TL. A new version of TL, called TL-B, is being developed for the purpose of describing the serialization of objects used by the TON Project. This new version can serialize objects into streams of bytes and even bits (not just 32-bit integers), and offers support for serialization into a tree of TVM cells (cf. 2.3.14 ). A description of TL-B will be a part of the formal specification of the TON Blockchain. 2.2.6. Blocks and transactions as state transformation operators. Normally, any blockchain (type) Blockchain has an associated global state (type) State, and a transaction (type) Transaction. The semantics of a blockchain are to a large extent determined by the transaction application function: \u200b ev_trans0 : Transaction \u00d7 State \u2192 State^? (3) Here X^? denotes Maybe X, the result of applying the Maybe monad to type X. This is similar to our use of X^\u2217 for List X . Essentially, a value of type X^? is either a value of type X or a special value \u22a5 indicating the absence of an actual value (think about a null pointer). In our case, we use State^? instead of State as the result type because a transaction may be invalid if invoked from certain original states (think about attempting to withdraw from an account more money than it is actually there). We might prefer a curried version of ev_trans' : \u200b ev_trans : Transaction \u2192 State \u2192 State^? (4) Because a block is essentially a list of transactions, the block evaluation function \u200b ev_block : Block \u2192 State \u2192 State? (5) can be derived from ev_trans. It takes a block *B : Block* and the previous blockchain state *s : State* (which might include the hash of the previous block) and computes the next blockchain state s' = ev_block(B)(s) : State , which is either a true state or a special value \u22a5 indicating that the next state cannot be computed (i.e., that the block is invalid if evaluated from the starting state given\u2014for example, the block includes a transaction trying to debit an empty account.) 2.2.7. Block sequence numbers. Each block B in the blockchain can be referred to by its sequence number blk-seqno(B) , starting from zero for the very first block, and incremented by one whenever passing to the next block. More formally, \u200b blk-seqno(B) = blk-seqno (blk-prev(B)) + 1 (6) Notice that the sequence number does not identify a block uniquely in the presence of forks. 2.2.8. Block hashes. Another way of referring to a block B is by its hash *blk-hash(B)* , which is actually the hash of the header of block B (however, the header of the block usually contains hashes that depend on all content of block B ). Assuming that there are no collisions for the hash function used (or at least that they are very improbable), a block is uniquely identified by its hash. 2.2.9. Hash assumption. During formal analysis of blockchain algorithms, we assume that there are no collisions for the k-bit hash function Hash : Bytes* \u2192 2^k used: \u200b Hash(s) = Hash(s') \u21d2 s = s' for any s, s' \u2208 Bytes* (7) Here Bytes = {0 . . . 255} = 2 ^8 is the type of bytes, or the set of all byte values, and Bytes\u2217 is the type or set of arbitrary (finite) lists of bytes; while 2 = {0, 1} is the bit type, and 2^ k is the set (or actually the type) of all k-bit sequences (i.e., of k-bit numbers). Of course, (7) is impossible mathematically, because a map from an infinite set to a finite set cannot be injective. A more rigorous assumption would be \u200b \u2200s, s' : s =/= s' , P (Hash(s) = Hash(s')) = 2^\u2212k (8) However, this is not so convenient for the proofs. If (8) is used at most N times in a proof with 2 ^\u2212k*N \u2208 for some small \u2208 (say, \u2208 = 10^\u221218), we can reason as if (7) were true, provided we accept a failure probability \u2208 (i.e., the final conclusions will be true with probability at least 1 \u2212 \u2208). Final remark: in order to make the probability statement of (8) really rigorous, one must introduce a probability distribution on the set Bytes * of all byte sequences. A way of doing this is by assuming all byte sequences of the same length l equiprobable, and setting the probability of observing a sequence of length l equal to p^l \u2212 p^l+1 for some p \u2192 1\u2212. Then (8) should be understood as a limit of conditional probability P (Hash(s) = Hash(s')|s =/= s') when p tends to one from below. 2.2.10. Hash used for the TON Blockchain. We are using the 256-bit sha256 hash for the TON Blockchain for the time being. If it turns out to be weaker than expected, it can be replaced by another hash function in the future. The choice of the hash function is a configurable parameter of the protocol, so it can be changed without hard forks as explained in 2.1.21 2.3 Blockchain State, Accounts and Hashmaps We have noted above that any blockchain defines a certain global state, and each block and each transaction defines a transformation of this global state. Here we describe the global state used by TON blockchain 2.3.1. Account IDs. The basic account IDs used by TON blockchains\u2014 or at least by its masterchain and Workchain Zero\u2014are 256-bit integers, assumed to be public keys for 256-bit Elliptic Curve Cryptography (ECC) for a specific elliptic curve. In this way, \u200b account_id : Account = uint256 = 2^256 (9) Here Account is the account type, while account_id : Account is a specific variable of type Account . Other workchains can use other account ID formats, 256-bit or otherwise. For example, one can use Bitcoin-style account IDs, equal to sha256 of an ECC public key. However, the bit length l of an account ID must be fixed during the creation of the workchain (in the masterchain), and it must be at least 64, because the first 64 bits of account_id are used for sharding and message routing. 2.3.2. Main component: Hashmaps. The principal component of the TON blockchain state is a hashmap. In some cases we consider (partially defined) \u201cmaps\u201d h : 2 ^n -- 2 ^m. More generally, we might be interested in hashmaps h : 2 ^n -- X for a composite type X. However, the source (or index) type is almost always 2 ^n . Sometimes, we have a \u201cdefault value\u201d empty : X, and the hashmap h : 2^n \u2192 X is \u201cinitialized\u201d by its \u201cdefault value\u201d i \u2192 empty. 2.3.3. Example: TON account balances. An important example is given by TON account balances. It is a hashmap balance : \u200b Account \u2192 uint*128* (10) mapping Account = 2^256 into a Gram (TON coin) balance of type uint128 = 2^128. This hashmap has a default value of zero, meaning that initially (before the first block is processed) the balance of all accounts is zero. 2.3.4. Example: smart-contract persistent storage. Another example is given by smart-contract persistent storage, which can be (very approximately) represented as a hashmap storage : \u200b 2^256 -- 2^256 (11) This hashmap also has a default value of zero, meaning that uninitialized cells of persistent storage are assumed to be zero. 2.3.5. Example: persistent storage of all smart contracts. Because we have more than one smart contract, distinguished by account_id , each having its separate persistent storage, we must actually have a hashmap \u200b Storage : Account -- (2^256 -- 2^256) (12) mapping account_id of a smart contract into its persistent storage. 2.3.6. Hashmap type. The hashmap is not just an abstract (partially defined) function 2^n -- X; it has a specific representation. Therefore, we suppose that we have a special hashmap type \u200b *Hashmap(n, X) : Type* (13) corresponding to a data structure encoding a (partial) map 2^n-- X. We can also write \u200b Hashmap(n : nat)(X : Type) : Type (14) or \u200b Hashmap : nat \u2192 Type \u2192 Type (15) We can always transform h : Hashmap(n, X) into a map hget(h) : 2^n \u2192 X^? . Henceforth, we usually write h[i] instead of hget(h)(i): \u200b h[i] :\u2261 hget(h)(i) : X^? for any i : **2**^n , h : Hashmap(n, X) (16) 2.3.7. Definition of hashmap type as a Patricia tree. Logically, one might define Hashmap(n, X) as an (incomplete) binary tree of depth n with edge labels 0 and 1 and with values of type X in the leaves. Another way to describe the same structure would be as a (bitwise) trie for binary strings of length equal to n. In practice, we prefer to use a compact representation of this trie, by compressing each vertex having only one child with its parent. The resulting representation is known as a Patricia tree or a binary radix tree. Each intermediate vertex now has exactly two children, labeled by two non-empty binary strings, beginning with zero for the left child and with one for the right child. In other words, there are two types of (non-root) nodes in a Patricia tree: Leaf(x), containing value x of type X. Node(l, sl , r, sr), where l is the (reference to the) left child or subtree, sl is the bitstring labeling the edge connecting this vertex to its left child (always beginning with 0), r is the right subtree, and sr is the bitstring labeling the edge to the right child (always beginning with 1). A third type of node, to be used only once at the root of the Patricia tree, is also necessary: Root(n, s0, t), where n is the common length of index bitstrings of Hashmap(n, X), s0 is the common prefix of all index bitstrings, and t is a reference to a Leaf or a Node. If we want to allow the Patricia tree to be empty, a fourth type of (root) node would be used: EmptyRoot(n), where n is the common length of all index bitstrings. We define the height of a Patricia tree by height (Leaf(x))= 0 (17) HEIGHT Node(*l, sl , r, sr*)= height(*l*) + len(*sl*) = height(*r*) + len(*sr*) (18) HEIGHT Root(*n, s0, t*)= len(*s0*) + height(*t*) = *n* (19) The last two expressions in each of the last two formulas must be equal. We use Patricia trees of height n to represent values of type Hashmap(n, X) . If there are N leaves in the tree (i.e., our hashmap contains N values), then there are exactly N \u2212 1 intermediate vertices. Inserting a new value always involves splitting an existing edge by inserting a new vertex in the middle and adding a new leaf as the other child of this new vertex. Deleting a value from a hashmap does the opposite: a leaf and its parent are deleted, and the parent\u2019s parent and its other child become directly linked 2.3.8. Merkle-Patricia trees. When working with blockchains, we want to be able to compare Patricia trees (i.e., hash maps) and their subtrees, by reducing them to a single hash value. The classical way of achieving this is given by the Merkle tree. Essentially, we want to describe a way of hashing objects h of type Hashmap(n, X) with the aid of a hash function Hash defined for binary strings, provided we know how to compute hashes Hash(x) of objects x : X (e.g., by applying the hash function Hash to a binary serialization of object x). One might define Hash(h) recursively as follows: Hash Leaf(x) := Hash(x) (20) Hash Node(*l, sl , r, sr*) := Hash Hash(*l*). Hash(*r*). code(*sl*). code(*sr*) (21) Hash Root(*n, s0, t*) := Hash code(*n*). code(*s0*). Hash(*t*) (22) Here s.t denotes the concatenation of (bit) strings s and t , and code( s ) is a prefix code for all bit strings s . For example, one might encode 0 by 10, 1 by 11, and the end of the string by 0.* We will see later (cf. 2.3.12 and 2.3.14 ) that this is a (slightly tweaked) version of recursively defined hashes for values of arbitrary (dependent) algebraic types. *One can show that this encoding is optimal for approximately half of all edge labels of a Patricia tree with random or consecutive indices. Remaining edge labels are likely to be long (i.e., almost 256 bits long). Therefore, a nearly optimal encoding for edge labels is to use the above code with prefix 0 for \u201cshort\u201d bit strings, and encode 1, then nine bits containing length l = |s| of bitstring s, and then the l bits of s for \u201clong\u201d bitstrings (with l \u2265 10). 2.3.9. Recomputing Merkle tree hashes. This way of recursively defining Hash(h), called a Merkle tree hash, has the advantage that, if one explicitly stores Hash(h') along with each node h' (resulting in a structure called a Merkle tree , or, in our case, a Merkle\u2013Patricia tree ), one needs to recompute only at most n hashes when an element is added to, deleted from or changed in the hashmap. In this way, if one represents the global blockchain state by a suitable Merkle tree hash, it is easy to recompute this state hash after each transaction. 2.3.10. Merkle proofs. Under the assumption (7) of \u201cinjectivity\u201d of the chosen hash function Hash, one can construct a proof that, for a given value z of Hash(h), h : Hashmap(n, X), one has hget(h)(i) = x for some i : 2^n and x : X. Such a proof will consist of the path in the Merkle\u2013Patricia tree from the leaf corresponding to i to the root, augmented by the hashes of all siblings of all nodes occurring on this path. In this way, a light node knowing only the value of Hash(h) for some hashmap h (e.g., smart-contract persistent storage or global blockchain state) might request from a full node * not only the value x = h[i] = hget(h)(i), but such a value along with a Merkle proof starting from the already known value Hash(h). Then, under assumption (7), the light node can check for itself that x is indeed the correct value of h[i]. In some cases, the client may want to obtain the value y = Hash(x) = Hash(h[i]) instead\u2014for example, if x itself is very large (e.g., a hashmap itself). Then a Merkle proof for (i, y) can be provided instead. If x is a hashmap as well, then a second Merkle proof starting from y = Hash(x) may be obtained from a full node, to provide a value x[j] = h[i][j] or just its hash. *A light node is a node that does not keep track of the full state of a shardchain; instead, it keeps minimal information such as the hashes of the several most recent blocks, and relies on information obtained from full nodes when it becomes necessary to inspect some parts of the full state. **A full node is a node keeping track of the complete up-to-date state of the shardchain in question. 2.3.11. Importance of Merkle proofs for a multi-chain system such as TON. Notice that a node normally cannot be a full node for all shardchains existing in the TON environment. It usually is a full node only for some shardchains\u2014for instance, those containing its own account, a smart contract it is interested in, or those that this node has been assigned to be a validator of. For other shardchains, it must be a light node\u2014otherwise the storage, computing and network bandwidth requirements would be prohibitive. This means that such a node cannot directly check assertions about the state of other shardchains; it must rely on Merkle proofs obtained from full nodes for those shardchains, which is as safe as checking by itself unless (7) fails (i.e., a hash collision is found). 2.3.12. Peculiarities of TON VM. The TON VM or TVM (Telegram Virtual Machine), used to run smart contracts in the masterchain and Workchain Zero, is considerably different from customary designs inspired by the EVM (Ethereum Virtual Machine): it works not just with 256-bit integers, but actually with (almost) arbitrary \u201crecords\u201d, \u201cstructures\u201d, or \u201csum-product types\u201d, making it more suitable to execute code written in high-level (especially functional) languages. Essentially, TVM uses tagged data types, not unlike those used in implementations of Prolog or Erlang. One might imagine first that the state of a TVM smart contract is not just a hashmap 2 ^256 \u2192 2 ^256, or Hashmap(256, 2 ^256), but (as a first step) Hashmap(256, X), where X is a type with several constructors, enabling it to store, apart from 256-bit integers, other data structures, including other hashmaps Hashmap(256, X) in particular. This would mean that a cell of TVM (persistent or temporary) storage\u2014or a variable or an element of an array in a TVM smart-contract code\u2014may contain not only an integer, but a whole new hashmap. Of course, this would mean that a cell contains not just 256 bits, but also, say, an 8-bit tag, describing how these 256 bits should be interpreted. In fact, values do not need to be precisely 256-bit. The value format used by TVM consists of a sequence of raw bytes and references to other structures, mixed in arbitrary order, with some descriptor bytes inserted in suitable locations to be able to distinguish pointers from raw data (e.g., strings or integers); cf. 2.3.14 . This raw value format may be used to implement arbitrary sum-product algebraic types. In this case, the value would contain a raw byte first, describing the \u201cconstructor\u201d being used (from the perspective of a high-level language), and then other \u201cfields\u201d or \u201cconstructor arguments\u201d, consisting of raw bytes and references to other structures depending on the constructor chosen (cf. 2.2.5 ). However, TVM does not know anything about the correspondence between constructors and their arguments; the mixture of bytes and references is explicitly described by certain descriptor bytes.* The Merkle tree hashing is extended to arbitrary such structures: to compute the hash of such a structure, all references are recursively replaced by hashes of objects referred to, and then the hash of the resulting byte string (descriptor bytes included) is computed. In this way, the Merkle tree hashing for hashmaps, described in 2.3.8, is just a special case of hashing for arbitrary (dependent) algebraic data types, applied to type Hashmap(n, X) with two constructors.** *These two descriptor bytes, present in any TVM cell, describe only the total number of references and the total number of raw bytes; references are kept together either before or after all raw bytes. **Actually, Leaf and Node are constructors of an auxiliary type, HashmapAux(n, X). Type Hashmap(n, X) has constructors Root and EmptyRoot, with Root containing a value of type HashmapAux(n, X). 2.3.13. Persistent storage of TON smart contracts. Persistent storage of a TON smart contract essentially consists of its \u201cglobal variables\u201d, preserved between calls to the smart contract. As such, it is just a \u201cproduct\u201d, \u201ctuple\u201d, or \u201crecord\u201d type, consisting of fields of the correct types, corresponding to one global variable each. If there are too many global variables, they cannot fit into one TON cell because of the global restriction on TON cell size. In such a case, they are split into several records and organized into a tree, essentially becoming a \u201cproduct of products\u201d or \u201cproduct of products of products\u201d type instead of just a product type. 2.3.14. TVM Cells. Ultimately, the TON VM keeps all data in a collection of (TVM) cells. Each cell contains two descriptor bytes first, indicating how many bytes of raw data are present in this cell (up to 128) and how many references to other cells are present (up to four). Then these raw data bytes and references follow. Each cell is referenced exactly once, so we might have included in each cell a reference to its \u201cparent\u201d (the only cell referencing this one). However, this reference need not be explicit. In this way, the persistent data storage cells of a TON smart contract are organized into a tree,* with a reference to the root of this tree kept in the smart-contract description. If necessary, a Merkle tree hash of this entire persistent storage is recursively computed, starting from the leaves and then simply replacing all references in a cell with the recursively computed hashes of the referenced cells, and subsequently computing the hash of the byte string thus obtained. *Logically; the \u201cbag of cells\u201d representation described in 2.5.5 identifies all duplicate cells, transforming this tree into a directed acyclic graph (dag) when serialized. 2.3.15. Generalized Merkle proofs for values of arbitrary algebraic types. Because the TON VM represents a value of arbitrary algebraic type by means of a tree consisting of (TVM) cells, and each cell has a well-defined (recursively computed) Merkle hash, depending in fact on the whole subtree rooted in this cell, we can provide \u201cgeneralized Merkle proofs\u201d for (parts of) values of arbitrary algebraic types, intended to prove that a certain subtree of a tree with a known Merkle hash takes a specific value or a value with a specific hash. This generalizes the approach of 2.3.10 , where only Merkle proofs for x[i] = y have been considered. 2.3.16. Support for sharding in TON VM data structures. We have just outlined how the TON VM, without being overly complicated, supports arbitrary (dependent) algebraic data types in high-level smart-contract languages. However, sharding of large (or global) smart contracts requires special support on the level of TON VM. To this end, a special version of the hashmap type has been added to the system, amounting to a \u201cmap\u201d Account 9 -- X. This \u201cmap\u201d might seem equivalent to Hashmap(m, X), where Account = 2^m. However, when a shard is split in two, or two shards are merged, such hashmaps are automatically split in two, or merged back, so as to keep only those keys that belong to the corresponding shard. 2.3.17. Payment for persistent storage. A noteworthy feature of the TON Blockchain is the payment exacted from smart contracts for storing their persistent data (i.e., for enlarging the total state of the blockchain). It works as follows: Each block declares two rates, nominated in the principal currency of the blockchain (usually the Gram): the price for keeping one cell in the persistent storage, and the price for keeping one raw byte in some cell of the persistent storage. Statistics on the total numbers of cells and bytes used by each account are stored as part of its state, so by multiplying these numbers by the two rates declared in the block header, we can compute the payment to be deducted from the account balance for keeping its data between the previous block and the current one. However, payment for persistent storage usage is not exacted for every account and smart contract in each block; instead, the sequence number of the block where this payment was last exacted is stored in the account data, and when any action is done with the account (e.g., a value transfer or a message is received and processed by a smart contract), the storage usage payment for all blocks since the previous such payment is deducted from the account balance before performing any further actions. If the account\u2019s balance would become negative after this, the account is destroyed. A workchain may declare some number of raw data bytes per account to be \u201cfree\u201d (i.e., not participating in the persistent storage payments) in order to make \u201csimple\u201d accounts, which keep only their balance in one or two cryptocurrencies, exempt from these constant payments. Notice that, if nobody sends any messages to an account, its persistent storage payments are not collected, and it can exist indefinitely. However, anybody can send, for instance, an empty message to destroy such an account. A small incentive, collected from part of the original balance of the account to be destroyed, can be given to the sender of such a message. We expect, however, that the validators would destroy such insolvent accounts for free, simply to decrease the global blockchain state size and to avoid keeping large amounts of data without compensation. Payments collected for keeping persistent data are distributed among the validators of the shardchain or the masterchain (proportionally to their stakes in the latter case). 2.3.18. Local and global smart contracts; smart-contract instances. A smart contract normally resides just in one shard, selected according to the smart contract\u2019s account_id, similarly to an \u201cordinary\u201d account. This is usually sufficient for most applications. However, some \u201chigh-load\u201d smart contracts may want to have an \u201cinstance\u201d in each shardchain of some workchain. To achieve this, they must propagate their creating transaction into all shardchains, for instance, by committing this transaction into the \u201croot\u201d shardchain (w, \u2205) of the workchain w and paying a large commission. * This action effectively creates instances of the smart contract in each shard, with separate balances. Originally, the balance transferred in the creating transaction is distributed simply by giving the instance in shard (w, s) the 2^\u2212|s| part of the total balance. When a shard splits into two child shards, balances of all instances of global smart contracts are split in half; when two shards merge, balances are added together. In some cases, splitting/merging instances of global smart contracts may involve (delayed) execution of special methods of these smart contracts. By default, the balances are split and merged as described above, and some special \u201caccount-indexed\u201d hashmaps are also automatically split and merged (cf. 2.3.16). *A more expensive alternative is to publish such a \u201cglobal\u201d smart contract in the masterchain. **This is a sort of \u201cbroadcast\u201d feature for all shards, and as such, it must be quite expensive. 2.3.19. Limiting splitting of smart contracts. A global smart contract may limit its splitting depth d upon its creation, in order to make persistent storage expenses more predictable. This means that, if shardchain (w, s) with |s| \u2265 d splits in two, only one of two new shardchains inherits an instance of the smart contract. This shardchain is chosen deterministically: each global smart contract has some \u201caccount_id\u201d , which is essentially the hash of its creating transaction, and its instances have the same account_id with the first \u2264 d bits replaced by suitable values needed to fall into the correct shard. This account_id selects which shard will inherit the smart-contract instance after splitting. 2.3.20. Account/Smart-contract state. We can summarize all of the above to conclude that an account or smart-contract state consists of the following: A balance in the principal currency of the blockchain A balance in other currencies of the blockchain Smart-contract code (or its hash) Smart-contract persistent data (or its Merkle hash) Statistics on the number of persistent storage cells and raw bytes used The last time (actually, the masterchain block number) when payment for smart-contract persistent storage was collected The public key needed to transfer currency and send messages from this account (optional; by default equal to account_id itself). In some cases, more sophisticated signature checking code may be located here, similar to what is done for Bitcoin transaction outputs; then the account_id will be equal to the hash of this code. We also need to keep somewhere, either in the account state or in some other account-indexed hashmap, the following data: The output message queue of the account (cf. 2.4.17 ) The collection of (hashes of) recently delivered messages (cf. 2.4.23 ) Not all of these are really required for every account; for example, smartcontract code is needed only for smart contracts, but not for \u201csimple\u201d accounts. Furthermore, while any account must have a non-zero balance in the principal currency (e.g., Grams for the masterchain and shardchains of the basic workchain), it may have balances of zero in other currencies. In order to avoid keeping unused data, a sum-product type (depending on the workchain) is defined (during the workchain\u2019s creation), which uses different tag bytes (e.g., TL constructors; cf. 2.2.5 ) to distinguish between different \u201cconstructors\u201d used. Ultimately, the account state is itself kept as a collection of cells of the TVM persistent storage. 2.4 Messages Between Shardchains An important component of the TON Blockchain is the messaging system between blockchains. These blockchains may be shardchains of the same workchain, or of different workchains. 2.4.1. Messages, accounts and transactions: a bird\u2019s eye view of the system. Messages are sent from one account to another. Each transaction consists of an account receiving one message, changing its state according to certain rules, and generating several (maybe one or zero) new messages to other accounts. Each message is generated and received (delivered) exactly once. This means that messages play a fundamental role in the system, comparable to that of accounts (smart contracts). From the perspective of the Infinite Sharding Paradigm (cf. 2.1.2 ), each account resides in its separate \u201caccount-chain\u201d, and the only way it can affect the state of some other account is by sending a message. 2.4.2. Accounts as processes or actors; Actor model. One might think about accounts (and smart contracts) as \u201cprocesses\u201d, or \u201cactors\u201d, that are able to process incoming messages, change their internal state and generate some outbound messages as a result. This is closely related to the so-called Actor model , used in languages such as Erlang (however, actors in Erlang are usually called \u201cprocesses\u201d). Since new actors (i.e., smart contracts) are also allowed to be created by existing actors as a result of processing an inbound message, the correspondence with the Actor model is essentially complete. 2.4.3. Message recipient. Any message has its recipient, characterized by the target workchain identifier w (assumed by default to be the same as that of the originating shardchain), and the recipient account account_id . The exact format (i.e., number of bits) of account_id depends on w ; however, the shard is always determined by its first (most significant) 64 bits. 2.4.4. Message sender. In most cases, a message has a sender , characterized again by a ( w' , account_id' ) pair. If present, it is located after the message recipient and message value. Sometimes, the sender is unimportant or it is somebody outside the blockchain (i.e., not a smart contract), in which case this field is absent. Notice that the Actor model does not require the messages to have an implicit sender. Instead, messages may contain a reference to the Actor to which an answer to the request should be sent; usually it coincides with the sender. However, it is useful to have an explicit unforgeable sender field in a message in a cryptocurrency (Byzantine) environment. 2.4.5. Message value. Another important characteristic of a message is its attached value, in one or several cryptocurrencies supported both by the source and by the target workchain. The value of the message is indicated at its very beginning immediately after the message recipient; it is essentially a list of ( currency_id, value ) pairs. Notice that \u201csimple\u201d value transfers between \u201csimple\u201d accounts are just empty (no-op) messages with some value attached to them. On the other hand, a slightly more complicated message body might contain a simple text or binary comment (e.g., about the purpose of the payment). 2.4.6. External messages, or \u201cmessages from nowhere\u201d. Some messages arrive into the system \u201cfrom nowhere\u201d\u2014that is, they are not generated by an account (smart contract or not) residing in the blockchain. The most typical example arises when a user wants to transfer some funds from an account controlled by her to some other account. In this case, the user sends a \u201cmessage from nowhere\u201d to her own account, requesting it to generate a message to the receiving account, carrying the specified value. If this message is correctly signed, her account receives it and generates the required outbound messages. In fact, one might consider a \u201csimple\u201d account as a special case of a smart contract with predefined code. This smart contract receives only one type of message. Such an inbound message must contain a list of outbound messages to be generated as a result of delivering (processing) the inbound message, along with a signature. The smart contract checks the signature, and, if it is correct, generates the required messages. Of course, there is a difference between \u201cmessages from nowhere\u201d and normal messages, because the \u201cmessages from nowhere\u201d cannot bear value, so they cannot pay for their \u201cgas\u201d (i.e., their processing) themselves. Instead, they are tentatively executed with a small gas limit before even being suggested for inclusion in a new shardchain block; if the execution fails (the signature is incorrect), the \u201cmessage from nowhere\u201d is deemed incorrect and is discarded. If the execution does not fail within the small gas limit, the message may be included in a new shardchain block and processed completely, with the payment for the gas (processing capacity) consumed exacted from the receiver\u2019s account. \u201cMessages from nowhere\u201d can also define some transaction fee which is deducted from the receiver\u2019s account on top of the gas payment for redistribution to the validators. In this sense, \u201cmessages from nowhere\u201d or \u201cexternal messages\u201d take the role of transaction candidates used in other blockchain systems (e.g., Bitcoin and Ethereum). 2.4.7. Log messages, or \u201cmessages to nowhere\u201d. Similarly, sometimes a special message can be generated and routed to a specific shardchain not to be delivered to its recipient, but to be logged in order to be easily observable by anybody receiving updates about the shard in question. These logged messages may be output in a user\u2019s console, or trigger an execution of some script on an off-chain server. In this sense, they represent the external \u201coutput\u201d of the \u201cblockchain supercomputer\u201d, just as the \u201cmessages from nowhere\u201d represent the external \u201cinput\u201d of the \u201cblockchain supercomputer\u201d. 2.4.8. Interaction with off-chain services and external blockchains. These external input and output messages can be used for interacting with off-chain services and other (external) blockchains, such as Bitcoin or Ethereum. One might create tokens or cryptocurrencies inside the TON Blockchain pegged to Bitcoins, Ethers or any ERC-20 tokens defined in the Ethereum blockchain, and use \u201cmessages from nowhere\u201d and \u201cmessages to nowhere\u201d, generated and processed by scripts residing on some third-party off-chain servers, to implement the necessary interaction between the TON Blockchain and these external blockchains. 2.4.9 Message body The message body is simply a sequence of bytes, the meaning of which is determined only by the receiving workchain and/or smart contract. For blockchains using TON VM, this could be the serialization of any TVM cell, generated automatically via the Send() operation. Such a serialization is obtained simply by recursively replacing all references in a TON VM cell with the cells referred to. Ultimately, a string of raw bytes appears, which is usually prepended by a 4-byte \u201cmessage type\u201d or \u201cmessage constructor\u201d, used to select the correct method of the receiving smart contract. Another option would be to use TL-serialized objects (cf. 2.2.5 ) as message bodies. This might be especially useful for communication between different workchains, one or both of which are not necessarily using the TON VM. Sometimes a message needs to carry information about the gas limit, the gas price, transaction fees and similar values that depend on the receiving workchain and are relevant only for the receiving workchain, but not necessarily for the originating workchain. Such parameters are included in or before the message body, sometimes (depending on the workchain) with special 4- byte prefixes indicating their presence (which can be defined by a TL-scheme; cf. 2.2.5 ). 2.4.10. Gas limit and other workchain/VM-specific parameters. Sometimes a message needs to carry information about the gas limit, the gas price, transaction fees and similar values that depend on the receiving workchain and are relevant only for the receiving workchain, but not necessarily for the originating workchain. Such parameters are included in or before the message body, sometimes (depending on the workchain) with special 4- byte prefixes indicating their presence (which can be defined by a TL-scheme; cf. 2.2.5 ). 2.4.11. Creating messages: smart contracts and transactions. There are two sources of new messages. Most messages are created during smartcontract execution (via the Send() operation in TON VM), when some smart contract is invoked to process an incoming message. Alternatively, messages may come from the outside as \u201cexternal messages\u201d or \u201cmessages from nowhere\u201d (cf. 2.4.6 ).* *The above needs to be literally true only for the basic workchain and its shardchains; other workchains may provide other ways of creating messages. 2.4.12. Delivering messages. When a message reaches the shardchain containing its destination account,* it is \u201cdelivered\u201d to its destination account. What happens next depends on the workchain; from an outside perspective, it is important that such a message can never be forwarded further from this shardchain. For shardchains of the basic workchain, delivery consists in adding the message value (minus any gas payments) to the balance of the receiving account, and possibly in invoking a message-dependent method of the receiving smart contract afterwards, if the receiving account is a smart contract. In fact, a smart contract has only one entry point for processing all incoming messages, and it must distinguish between different types of messages by looking at their first few bytes (e.g., the first four bytes containing a TL constructor; cf. 2.2.5 ). *As a degenerate case, this shardchain may coincide with the originating shardchain\u2014 for example, if we are working inside a workchain which has not yet been split. 2.4.13. Delivery of a message is a transaction. Because the delivery of a message changes the state of an account or smart contract, it is a special transaction in the receiving shardchain, and is explicitly registered as such. Essentially, all TON Blockchain transactions consist in the delivery of one inbound message to its receiving account (smart contract), neglecting some minor technical details. 2.4.14. Messages between instances of the same smart contract. Recall that a smart contract may be local (i.e., residing in one shardchain as any ordinary account does) or global (i.e., having instances in all shards, or at least in all shards up to some known depth d; cf. 2.3.18 ). Instances of a global smart contract may exchange special messages to transfer information and value between each other if required. In this case, the (unforgeable) sender account_id becomes important (cf. 2.4.4 ). 2.4.15. Messages to any instance of a smart contract; wildcard addresses. Sometimes a message (e.g., a client request) needs be delivered to any instance of a global smart contract, usually the closest one (if there is one residing in the same shardchain as the sender, it is the obvious candidate). One way of doing this is by using a \u201cwildcard recipient address\u201d, with the first d bits of the destination account_id allowed to take arbitrary values. In practice, one will usually set these d bits to the same values as in the sender\u2019s account_id . 2.4.16. Input queue is absent. All messages received by a blockchain (usually a shardchain; sometimes the masterchain)\u2014or, essentially, by an \u201caccount-chain\u201d residing inside some shardchain\u2014are immediately delivered (i.e., processed by the receiving account). Therefore, there is no \u201cinput queue\u201d as such. Instead, if not all messages destined for a specific shardchain can be processed because of limitations on the total size of blocks and gas usage, some messages are simply left to accumulate in the output queues of the originating shardchains. 2.4.17. Output queues. From the perspective of the Infinite Sharding Paradigm (cf. 2.1.2 ), each account-chain (i.e., each account) has its own output queue, consisting of all messages it has generated, but not yet delivered to their recipients. Of course, account-chains have only a virtual existence; they are grouped into shardchains, and a shardchain has an output \u201cqueue\u201d, consisting of the union of the output queues of all accounts belonging to the shardchain. This shardchain output \u201cqueue\u201d imposes only partial order on its member messages. Namely, a message generated in a preceding block must be delivered before any message generated in a subsequent block, and any messages generated by the same account and having the same destination must be delivered in the order of their generation. 2.4.18. Reliable and fast inter-chain messaging. It is of paramount importance for a scalable multi-blockchain project such as TON to be able to forward and deliver messages between different shardchains (cf. 2.1.3 ), even if there are millions of them in the system. The messages should be delivered reliably (i.e., messages should not be lost or delivered more than once) and quickly. The TON Blockchain achieves this goal by using a combination of two \u201cmessage routing\u201d mechanisms. 2.4.19. Hypercube routing: \u201cslow path\u201d for messages with assured delivery. The TON Blockchain uses \u201chypercube routing\u201d as a slow, but safe and reliable way of delivering messages from one shardchain to another, using several intermediate shardchains for transit if necessary. Otherwise, the validators of any given shardchain would need to keep track of the state of (the output queues of) all other shardchains, which would require prohibitive amounts of computing power and network bandwidth as the total quantity of shardchains grows, thus limiting the scalability of the system. Therefore, it is not possible to deliver messages directly from any shard to every other. Instead, each shard is \u201cconnected\u201d only to shards differing in exactly one hexadecimal digit of their (w, s) shard identifiers (cf. 2.1.8 ). In this way, all shardchains constitute a \u201chypercube\u201d graph, and messages travel along the edges of this hypercube. If a message is sent to a shard different from the current one, one of the hexadecimal digits (chosen deterministically) of the current shard identifier is replaced by the corresponding digit of the target shard, and the resulting identifier is used as the proximate target to forward the message to.* *This is not necessarily the final version of the algorithm used to compute the next hop for hypercube routing. In particular, hexadecimal digits may be replaced by r-bit groups, with r a configurable parameter, not necessarily equal to four. The main advantage of hypercube routing is that the block validity conditions imply that validators creating blocks of a shardchain must collect and process messages from the output queues of \u201cneighboring\u201d shardchains, on pain of losing their stakes. In this way, any message can be expected to reach its final destination sooner or later; a message cannot be lost in transit or delivered twice. Notice that hypercube routing introduces some additional delays and expenses, because of the necessity to forward messages through several intermediate shardchains. However, the number of these intermediate shardchains grows very slowly, as the logarithm log N (more precisely, dlog 16 Ne \u2212 1) of the total number of shardchains N. For example, if N \u2248 250, there will be at most one intermediate hop; and for N \u2248 4000 shardchains, at most two. With four intermediate hops, we can support up to one million shardchains. We think this is a very small price to pay for the essentially unlimited scalability of the system. In fact, it is not necessary to pay even this price: 2.4.20. Instant Hypercube Routing: \u201cfast path\u201d for messages. A novel feature of the TON Blockchain is that it introduces a \u201cfast path\u201d for forwarding messages from one shardchain to any other, allowing in most cases to bypass the \u201cslow\u201d hypercube routing of 2.4.19 altogether and deliver the message into the very next block of the final destination shardchain. The idea is as follows. During the \u201cslow\u201d hypercube routing, the message travels (in the network) along the edges of the hypercube, but it is delayed (for approximately five seconds) at each intermediate vertex to be committed into the corresponding shardchain before continuing its voyage. To avoid unnecessary delays, one might instead relay the message along with a suitable Merkle proof along the edges of the hypercube, without waiting to commit it into the intermediate shardchains. In fact, the network message should be forwarded from the validators of the \u201ctask group\u201d (cf. 2.6.8 ) of the original shard to the designated block producer (cf. 2.6.9 ) of the \u201ctask group\u201d of the destination shard; this might be done directly without going along the edges of the hypercube. When this message with the Merkle proof reaches the validators (more precisely, the collators; cf. 2.6.5 ) of the destination shardchain, they can commit it into a new block immediately, without waiting for the message to complete its travel along the \u201cslow path\u201d. Then a confirmation of delivery along with a suitable Merkle proof is sent back along the hypercube edges, and it may be used to stop the travel of the message along the \u201cslow path\u201d, by committing a special transaction. Note that this \u201cinstant delivery\u201d mechanism does not replace the \u201cslow\u201d but failproof mechanism described in 2.4.19 . The \u201cslow path\u201d is still needed because the validators cannot be punished for losing or simply deciding not to commit the \u201cfast path\u201d messages into new blocks of their blockchains.* Therefore, both message forwarding methods are run in parallel, and the \u201cslow\u201d mechanism is aborted only if a proof of success of the \u201cfast\u201d mechanism is committed into an intermediate shardchain.** *However, the validators have some incentive to do so as soon as possible, because they will be able to collect all forwarding fees associated with the message that have not yet been consumed along the slow path. **In fact, one might temporarily or permanently disable the \u201cinstant delivery\u201d mechanism altogether, and the system would continue working, albeit more slowly 2.4.21. Collecting input messages from output queues of neighboring shardchains. When a new block for a shardchain is proposed, some of the output messages of the neighboring (in the sense of the routing hypercube of 2.4.19 ) shardchains are included in the new block as \u201cinput\u201d messages and immediately delivered (i.e., processed). There are certain rules as to the order in which these neighbors\u2019 output messages must be processed. Essentially, an \u201colder\u201d message (coming from a shardchain block referring to an older masterchain block) must be delivered before any \u201cnewer\u201d message; and for messages coming from the same neighboring shardchain, the partial order of the output queue described in 2.4.17 must be observed. 2.4.22. Deleting messages from output queues. Once an output queue message is observed as having been delivered by a neighboring shardchain, it is explicitly deleted from the output queue by a special transaction. 2.4.23. Preventing double delivery of messages. To prevent double delivery of messages taken from the output queues of the neighboring shardchains, each shardchain (more precisely, each account-chain inside it) keeps the collection of recently delivered messages (or just their hashes) as part of its state. When a delivered message is observed to be deleted from the output queue by its originating neighboring shardchain (cf. 2.4.22 ), it is deleted from the collection of recently delivered messages as well. 2.4.24. Forwarding messages intended for other shardchains. Hypercube routing (cf. 2.4.19 ) means that sometimes outbound messages are delivered not to the shardchain containing the intended recipient, but to a neighboring shardchain lying on the hypercube path to the destination. In this case, \u201cdelivery\u201d consists in moving the inbound message to the outbound queue. This is reflected explicitly in the block as a special forwarding transaction, containing the message itself. Essentially, this looks as if the message had been received by somebody inside the shardchain, and one identical message had been generated as result. 2.4.25. Payment for forwarding and keeping a message. The forwarding transaction actually spends some gas (depending on the size of the message being forwarded), so a gas payment is deducted from the value of the message being forwarded on behalf of the validators of this shardchain. This forwarding payment is normally considerably smaller than the gas payment exacted when the message is finally delivered to its recipient, even if the message has been forwarded several times because of hypercube routing. Furthermore, as long as a message is kept in the output queue of some shardchain, it is part of the shardchain\u2019s global state, so a payment for keeping global data for a long time may be also collected by special transactions. 2.4.26. Messages to and from the masterchain. Messages can be sent directly from any shardchain to the masterchain, and vice versa. However, gas prices for sending messages to and for processing messages in the masterchain are quite high, so this ability will be used only when truly necessary\u2014 for example, by the validators to deposit their stakes. In some cases, a minimal deposit (attached value) for messages sent to the masterchain may be defined, which is returned only if the message is deemed \u201cvalid\u201d by the receiving party. Messages cannot be automatically routed through the masterchain. A message with workchain_id =/= \u22121 (\u22121 being the special workchain_id indicating the masterchain) cannot be delivered to the masterchain. In principle, one can create a message-forwarding smart contract inside the masterchain, but the price of using it would be prohibitive. 2.4.27. Messages between accounts in the same shardchain. In some cases, a message is generated by an account belonging to some shardchain, destined to another account in the same shardchain. For example, this happens in a new workchain which has not yet split into several shardchains because the load is manageable. Such messages might be accumulated in the output queue of the shardchain and then processed as incoming messages in subsequent blocks (any shard is considered a neighbor of itself for this purpose). However, in most cases it is possible to deliver these messages within the originating block itself. In order to achieve this, a partial order is imposed on all transactions included in a shardchain block, and the transactions (each consisting in the delivery of a message to some account) are processed respecting this partial order. In particular, a transaction is allowed to process some output message of a preceding transaction with respect to this partial order. In this case, the message body is not copied twice. Instead, the originating and the processing transactions refer to a shared copy of the message. 2.5 Global Shardchain State. \u201cBag of Cells\u201d Philosophy. Now we are ready to describe the global state of a TON blockchain, or at least of a shardchain of the basic workchain. We start with a \u201chigh-level\u201d or \u201clogical\u201d description, which consists in saying that the global state is a value of algebraic type ShardchainState . 2.5.1. Shardchain state as a collection of account-chain states. According to the Infinite Sharding Paradigm (cf. 2.1.2), any shardchain is just a (temporary) collection of virtual \u201caccount-chains\u201d, containing exactly one account each. This means that, essentially, the global shardchain state must be a hashmap \u200b ShardchainState := (Account 99K AccountState) (23) where all account_id appearing as indices of this hashmap must begin with prefix s, if we are discussing the state of shard (w, s) (cf. 2.1.8 ). In practice, we might want to split AccountState into several parts (e.g., keep the account output message queue separate to simplify its examination by the neighboring shardchains), and have several hashmaps (Account -- AccountStatePart i ) inside the ShardchainState . We might also add a small number of \u201cglobal\u201d or \u201cintegral\u201d parameters to the ShardchainState, (e.g., the total balance of all accounts belonging to this shard, or the total number of messages in all output queues). However, (23) is a good first approximation of what the shardchain global state looks like, at least from a \u201clogical\u201d (\u201chigh-level\u201d) perspective. The formal description of algebraic types AccountState and ShardchainState can be done with the aid of a TL-scheme (cf. 2.2.5 ), to be provided elsewhere. 2.5.2. Splitting and merging shardchain states. Notice that the Infinite Sharding Paradigm description of the shardchain state (23) shows how this state should be processed when shards are split or merged. In fact, these state transformations turn out to be very simple operations with hashmaps. 2.5.3. Account-chain state. The (virtual) account-chain state is just the state of one account, described by type AccountState. Usually it has all or some of the fields listed in 2.3.20 , depending on the specific constructor used. 2.5.4. Global workchain state. Similarly to (23), we may define the global workchain state by the same formula, but with account_id \u2019s allowed to take any values, not just those belonging to one shard. Remarks similar to those made in 2.5.1 apply in this case as well: we might want to split this hashmap into several hashmaps, and we might want to add some \u201cintegral\u201d parameters such as the total balance. Essentially, the global workchain state must be given by the same type ShardchainState as the shardchain state, because it is the shardchain state we would obtain if all existing shardchains of this workchain suddenly merged into one. 2.5.5. Low-level perspective: \u201cbag of cells\u201d. There is a \u201clow-level\u201d description of the account-chain or shardchain state as well, complementary to the \u201chigh-level\u201d description given above. This description is quite important, because it turns out to be pretty universal, providing a common basis for representing, storing, serializing and transferring by network almost all data used by the TON Blockchain (blocks, shardchain states, smart-contract storage, Merkle proofs, etc.). At the same time, such a universal \u201clow-level\u201d description, once understood and implemented, allows us to concentrate our attention on the \u201chigh-level\u201d considerations only. Recall that the TVM represents values of arbitrary algebraic types (including, for instance, ShardchainState of (23)) by means of a tree of TVM cells, or cells for short (cf. 2.3.14 and 2.2.5 ). Any such cell consists of two descriptor bytes , defining certain flags and values 0 \u2264 b \u2264 128, the quantity of raw bytes, and 0 \u2264 c \u2264 4, the quantity of references to other cells. Then b raw bytes and c cell references follow.* The exact format of cell references depends on the implementation and on whether the cell is located in RAM, on disk, in a network packet, in a block, and so on. A useful abstract model consists in imagining that all cells are kept in content-addressable memory, with the address of a cell equal to its (sha256) hash. Recall that the (Merkle) hash of a cell is computed exactly by replacing the references to its child cells by their (recursively computed) hashes and hashing the resulting byte string. In this way, if we use cell hashes to reference cells (e.g., inside descriptions of other cells), the system simplifies somewhat, and the hash of a cell starts to coincide with the hash of the byte string representing it. Now we see that any object representable by TVM, the global shardchain state included , can be represented as a \u201cbag of cells\u201d \u2014i.e., a collection of cells along with a \u201croot\u201d reference to one of them (e.g., by hash). Notice that duplicate cells are removed from this description (the \u201cbag of cells\u201d is a set of cells, not a multiset of cells), so the abstract tree representation might actually become a directed acyclic graph (dag) representation. One might even keep this state on disk in a B- or B+ -tree, containing all cells in question (maybe with some additional data, such as subtree height or reference counter), indexed by cell hash. However, a naive implementation of this idea would result in the state of one smart contract being scattered among distant parts of the disk file, something we would rather avoid.** Now we are going to explain in some detail how almost all objects used by the TON Blockchain can be represented as \u201cbags of cells\u201d, thus demonstrating the universality of this approach. *One can show that, if Merkle proofs for all data stored in a tree of cells are needed equally often, one should use cells with b+ch \u2248 2(h+r) to minimize average Merkle proof size, where h = 32 is the hash size in bytes, and r \u2248 4 is the \u201cbyte size\u201d of a cell reference. In other words, a cell should contain either two references and a few raw bytes, or one reference and about 36 raw bytes, or no references at all with 72 raw bytes. **A better implementation would be to keep the state of the smart contract as a serialized string, if it is small, or in a separate B-tree, if it is large; then the top-level structure representing the state of a blockchain would be a B-tree, whose leaves are allowed to contain references to other B-trees. 2.5.6. Shardchain block as a \u201cbag of cells\u201d. A shardchain block itself can be also described by an algebraic type, and stored as a \u201cbag of cells\u201d. Then a naive binary representation of the block may be obtained simply by concatenating the byte strings representing each of the cells in the \u201cbag of cells\u201d, in arbitrary order. This representation might be improved and optimized, for instance, by providing a list of offsets of all cells at the beginning of the block, and replacing hash references to other cells with 32-bit indices in this list whenever possible. However, one should imagine that a block is essentially a \u201cbag of cells\u201d, and all other technical details are just minor optimization and implementation issues. 2.5.7. Update to an object as a \u201cbag of cells\u201d. Imagine that we have an old version of some object represented as a \u201cbag of cells\u201d, and that we want to represent a new version of the same object, supposedly not too different from the previous one. One might simply represent the new state as another \u201cbag of cells\u201d with its own root, a nd remove from it all cells occurring in the old version . The remaining \u201cbag of cells\u201d is essentially an update to the object. Everybody who has the old version of this object and the update can compute the new version, simply by uniting the two bags of cells, and removing the old root (decreasing its reference counter and de-allocating the cell if the reference counter becomes zero). 2.5.8. Updates to the state of an account. In particular, updates to the state of an account, or to the global state of a shardchain, or to any hashmap can be represented using the idea described in 2.5.7 . This means that when we receive a new shardchain block (which is a \u201cbag of cells\u201d), we interpret this \u201cbag of cells\u201d not just by itself, but by uniting it first with the \u201cbag of cells\u201d representing the previous state of the shardchain. In this sense each block may \u201ccontain\u201d the whole state of the blockchain. 2.5.9. Updates to a block. Recall that a block itself is a \u201cbag of cells\u201d, so, if it becomes necessary to edit a block, one can similarly define a \u201cblock update\u201d as a \u201cbag of cells\u201d, interpreted in the presence of the \u201cbag of cells\u201d which is the previous version of this block. This is roughly the idea behind the \u201cvertical blocks\u201d discussed in 2.1.17 . 2.5.10. Merkle proof as a \u201cbag of cells\u201d. Notice that a (generalized) Merkle proof\u2014for example, one asserting that x[i] = y starting from a known value of Hash(x) = h (cf. 2.3.10 and 2.3.15)\u2014may also be represented as a \u201cbag of cells\u201d. Namely, one simply needs to provide a subset of cells corresponding to a path from the root of x : Hashmap(n, X) to its desired leaf with index i : 2^n and value y : X. References to children of these cells not lying on this path will be left \u201cunresolved\u201d in this proof, represented by cell hashes. One can also provide a simultaneous Merkle proof of, say, *x[i] = y* and *x[i'] = y'* , by including in the \u201cbag of cells\u201d the cells lying on the union of the two paths from the root of x to leaves corresponding to indices i and i' . 2.5.11. Merkle proofs as query responses from full nodes. In essence, a full node with a complete copy of a shardchain (or account-chain) state can provide a Merkle proof when requested by a light node (e.g., a network node running a light version of the TON Blockchain client), enabling the receiver to perform some simple queries without external help, using only the cells provided in this Merkle proof. The light node can send its queries in a serialized format to the full node, and receive the correct answers with Merkle proofs\u2014or just the Merkle proofs, because the requester should be able to compute the answers using only the cells included in the Merkle proof. This Merkle proof would consist simply of a \u201cbag of cells\u201d, containing only those cells belonging to the shardchain\u2019s state that have been accessed by the full node while executing the light node\u2019s query. This approach can be used in particular for executing \u201cget queries\u201d of smart contracts (cf. 4.3.12 ). 2.5.12. Augmented update, or state update with Merkle proof of validity. Recall (cf. 2.5.7 ) that we can describe the changes in an object state from an old value x : X to a new value x' : X by means of an \u201cupdate\u201d, which is simply a \u201cbag of cells\u201d, containing those cells that lie in the subtree representing new value x', but not in the subtree representing old value x, because the receiver is assumed to have a copy of the old value x and all its cells. However, if the receiver does not have a full copy of x , but knows only its (Merkle) hash h = Hash(x) , it will not be able to check the validity of the update (i.e., that all \u201cdangling\u201d cell references in the update do refer to cells present in the tree of x). One would like to have \u201cverifiable\u201d updates, augmented by Merkle proofs of existence of all referred cells in the old state. Then anybody knowing only h = Hash(x) would be able to check the validity of the update and compute the new h'= Hash(x') by itself. Because our Merkle proofs are \u201cbags of cells\u201d themselves (cf. 2.5.10 ), one can construct such an augmented update as a \u201cbag of cells\u201d, containing the old root of x, some of its descendants along with paths from the root of x to them, and the new root of x' and all its descendants that are not part of x. 2.5.13. Account state updates in a shardchain block. In particular, account state updates in a shardchain block should be augmented as discussed in 2.5.12 . Otherwise, somebody might commit a block containing an invalid state update, referring to a cell absent in the old state; proving the invalidity of such a block would be problematic (how is the challenger to prove that a cell is not part of the previous state?). Now, if all state updates included in a block are augmented, their validity is easily checked, and their invalidity is also easily shown as a violation of the recursive defining property of (generalized) Merkle hashes. 2.5.14. \u201cEverything is a bag of cells\u201d philosophy. Previous considerations show that everything we need to store or transfer, either in the TON Blockchain or in the network, is representable as a \u201cbag of cells\u201d. This is an important part of the TON Blockchain design philosophy. Once the \u201cbag of cells\u201d approach is explained and some \u201clow-level\u201d serializations of \u201cbags of cells\u201d are defined, one can simply define everything (block format, shardchain and account state, etc.) on the high level of abstract (dependent) algebraic data types. The unifying effect of the \u201ceverything is a bag of cells\u201d philosophy considerably simplifies the implementation of seemingly unrelated services; cf. 5.1.9 for an example involving payment channels. 2.5.15. Block \u201cheaders\u201d for TON blockchains. Usually, a block in a blockchain begins with a small header, containing the hash of the previous block, its creation time, the Merkle hash of the tree of all transactions contained in the block, and so on. Then the block hash is defined to be the hash of this small block header. Because the block header ultimately depends on all data included in the block, one cannot alter the block without changing its hash. In the \u201cbag of cells\u201d approach used by the blocks of TON blockchains, there is no designated block header. Instead, the block hash is defined as the (Merkle) hash of the root cell of the block. Therefore, the top (root) cell of the block might be considered a small \u201cheader\u201d of this block. However, the root cell might not contain all the data usually expected from such a header. Essentially, one wants the header to contain some of the fields defined in the Block datatype. Normally, these fields will be contained in several cells, including the root. These are the cells that together constitute a \u201cMerkle proof\u201d for the values of the fields in question. One might insist that a block contain these \u201cheader cells\u201d in the very beginning, before any other cells. Then one would need to download only the first several bytes of a block serialization in order to obtain all of the \u201cheader cells\u201d, and to learn all of the expected fields. 2.6 Creating and Validating New Blocks The TON Blockchain ultimately consists of shardchain and masterchain blocks. These blocks must be created, validated and propagated through the network to all parties concerned, in order for the system to function smoothly and correctly. 2.6.1. Validators. New blocks are created and validated by special designated nodes, called validators . Essentially, any node wishing to become a validator may become one, provided it can deposit a sufficiently large stake (in TON coins, i.e., Grams; cf. Appendix A ) into the masterchain. Validators obtain some \u201crewards\u201d for good work, namely, the transaction, storage and gas fees from all transactions (messages) committed into newly generated blocks, and some newly minted coins, reflecting the \u201cgratitude\u201d of the whole community to the validators for keeping the TON Blockchain working. This income is distributed among all participating validators proportionally to their stakes. However, being a validator is a high responsibility. If a validator signs an invalid block, it can be punished by losing part or all of its stake, and by being temporarily or permanently excluded from the set of validators. If a validator does not participate in creating a block, it does not receive its share of the reward associated with that block. If a validator abstains from creating new blocks for a long time, it may lose part of its stake and be suspended or permanently excluded from the set of validators. All this means that the validator does not get its money \u201cfor nothing\u201d. Indeed, it must keep track of the states of all or some shardchains (each validator is responsible for validating and creating new blocks in a certain subset of shardchains), perform all computations requested by smart contracts in these shardchains, receive updates about other shardchains and so on. This activity requires considerable disk space, computing power and network bandwidth. 2.6.2. Validators instead of miners. Recall that the TON Blockchain uses the Proof-of-Stake approach, instead of the Proof-of-Work approach adopted by Bitcoin, the current version of Ethereum, and most other cryptocurrencies. This means that one cannot \u201cmine\u201d a new block by presenting some proof-ofwork (computing a lot of otherwise useless hashes) and obtain some new coins as a result. Instead, one must become a validator and spend one\u2019s computing resources to store and process TON Blockchain requests and data. In short, one must be a validator to mine new coins. In this respect, validators are the new miners. However, there are some other ways to earn coins apart from being a validator. 2.6.3. Nominators and \u201cmining pools\u201d. To become a validator, one would normally need to buy and install several high-performance servers and acquire a good Internet connection for them. This is not so expensive as the ASIC equipment currently required to mine Bitcoins. However, one definitely cannot mine new TON coins on a home computer, let alone a smartphone. In the Bitcoin, Ethereum and other Proof-of-Work cryptocurrency mining communities there is a notion of mining pools, where a lot of nodes, having insufficient computing power to mine new blocks by themselves, combine their efforts and share the reward afterwards. A corresponding notion in the Proof-of-Stake world is that of a nominator. Essentially, this is a node lending its money to help a validator increase its stake; the validator then distributes the corresponding share of its reward (or some previously agreed fraction of it\u2014say, 50%) to the nominator. In this way, a nominator can also take part in the \u201cmining\u201d and obtain some reward proportional to the amount of money it is willing to deposit for this purpose. It receives only a fraction of the corresponding share of the validator\u2019s reward, because it provides only the \u201ccapital\u201d, but does not need to buy computing power, storage and network bandwidth. However, if the validator loses its stake because of invalid behavior, the nominator loses its share of the stake as well. In this sense the nominator shares the risk. It must choose its nominated validator wisely, otherwise it can lose money. In this sense, nominators make a weighted decision and \u201cvote\u201d for certain validators with their funds. On the other hand, this nominating or lending system enables one to become a validator without investing a large amount of money into Grams (TON coins) first. In other words, it prevents those keeping large amounts of Grams from monopolizing the supply of validators. 2.6.4. Fishermen: obtaining money by pointing out others\u2019 mistakes. Another way to obtain some rewards without being a validator is by becoming a fisherman. Essentially, any node can become a fisherman by making a small deposit in the masterchain. Then it can use special masterchain transactions to publish (Merkle) invalidity proofs of some (usually shardchain) blocks previously signed and published by validators. If other validators agree with this invalidity proof, the offending validators are punished (by losing part of their stake), and the fisherman obtains some reward (a fraction of coins confiscated from the offending validators). Afterwards, the invalid (shardchain) block must be corrected as outlined in 2.1.17 . Correcting invalid masterchain blocks may involve creating \u201cvertical\u201d blocks on top of previously committed masterchain blocks (cf. 2.1.17 ); there is no need to create a fork of the masterchain. Normally, a fisherman would need to become a full node for at least some shardchains, and spend some computing resources by running the code of at least some smart contracts. While a fisherman does not need to have as much computing power as a validator, we think that a natural candidate to become a fisherman is a would-be validator that is ready to process new blocks, but has not yet been elected as a validator (e.g., because of a failure to deposit a sufficiently large stake). 2.6.5. Collators: obtaining money by suggesting new blocks to validators. Yet another way to obtain some rewards without being a validator is by becoming a collator . This is a node that prepares and suggests to a validator new shardchain block candidates, complemented (collated) with data taken from the state of this shardchain and from other (usually neighboring) shardchains, along with suitable Merkle proofs. (This is necessary, for example, when some messages need to be forwarded from neighboring shardchains.) Then a validator can easily check the proposed block candidate for validity, without having to download the complete state of this or other shardchains. Because a validator needs to submit new (collated) block candidates to obtain some (\u201cmining\u201d) rewards, it makes sense to pay some part of the reward to a collator willing to provide suitable block candidates. In this way, a validator may free itself from the necessity of watching the state of the neighboring shardchains, by outsourcing it to a collator. However, we expect that during the system\u2019s initial deployment phase there will be no separate designated collators, because all validators will be able to act as collators for themselves. 2.6.6. Collators or validators: obtaining money for including user transactions. Users can open micropayment channels to some collators or validators and pay small amounts of coins in exchange for the inclusion of their transactions in the shardchain 2.6.7. Global validator set election. The \u201cglobal\u201d set of validators is elected once each month (actually, every 2^19 masterchain blocks). This set is determined and universally known one month in advance. In order to become a validator, a node must transfer some TON coins (Grams) into the masterchain, and then send them to a special smart contract as its suggested stake s. Another parameter, sent along with the stake, is l \u2265 1 , the maximum validating load this node is willing to accept relative to the minimal possible. There is also a global upper bound (another configurable parameter) L on l, equal to, say, 10. Then the global set of validators is elected by this smart contract, simply by selecting up to T candidates with maximal suggested stakes and publishing their identities. Originally, the total number of validators is T = 100; we expect it to grow to 1000 as the load increases. It is a configurable parameter (cf. 2.1.21 ). The actual stake of each validator is computed as follows: If the top T proposed stakes are s1 \u2265 s2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 sT , the actual stake of i-th validator is set to s ' i := min(si , li \u00b7 sT ) . In this way, s'i /s'T \u2264 li , so the i-th validator does not obtain more than li \u2264 L times the load of the weakest validator (because the load is ultimately proportional to the stake). Then elected validators may withdraw the unused part of their stake, si\u2212s'i. Unsuccessful validator candidates may withdraw all of their proposed stake. Each validator publishes its public signing key, not necessarily equal to the public key of the account the stake came from.* \\The stakes of the validators are frozen until the end of the period for which they have been elected, and one month more, in case new disputes arise (i.e., an invalid block signed by one of these validators is found). After that, the stake is returned, along with the validator\u2019s share of coins minted and fees from transactions processed during this time. *It makes sense to generate and use a new key pair for every validator election. 2.6.8. Election of validator \u201ctask groups\u201d. The whole global set of validators (where each validator is considered present with multiplicity equal to its stake\u2014otherwise a validator might be tempted to assume several identities and split its stake among them) is used only to validate new masterchain blocks. The shardchain blocks are validated only by specially selected subsets of validators, taken from the global set of validators chosen as described in 2.6.7 . These validator \u201csubsets\u201d or \u201ctask groups\u201d, defined for every shard, are rotated each hour (actually, every 2^10 masterchain blocks), and they are known one hour in advance, so that every validator knows which shards it will need to validate, and can prepare for that (e.g., by downloading missing shardchain data). The algorithm used to select validator task groups for each shard (w, s) is deterministic pseudorandom. It uses pseudorandom numbers embedded by validators into each masterchain block (generated by a consensus using threshold signatures) to create a random seed, and then computes for example Hash(code(w). code(s).validator_id.rand_seed) for each validator. Then validators are sorted by the value of this hash, and the first several are selected, so as to have at least 20/T of the total validator stakes and consist of at least 5 validators. This selection could be done by a special smart contract. In that case, the selection algorithm would easily be upgradable without hard forks by the voting mechanism mentioned in 2.1.21 . All other \u201cconstants\u201d mentioned so far (such as 2^19 , 2^10 , T, 20, and 5) are also configurable parameters. 2.6.9. Rotating priority order on each task group. There is a certain \u201cpriority\u201d order imposed on the members of a shard task group, depending on the hash of the previous masterchain block and (shardchain) block sequence number. This order is determined by generating and sorting some hashes as described above. When a new shardchain block needs to be generated, the shard task group validator selected to create this block is normally the first one with respect to this rotating \u201cpriority\u201d order. If it fails to create the block, the second or third validator may do it. Essentially, all of them may suggest their block candidates, but the candidate suggested by the validator having the highest priority should win as the result of Byzantine Fault Tolerant (BFT) consensus protocol. 2.6.10. Propagation of shardchain block candidates. Because shardchain task group membership is known one hour in advance, their members can use that time to build a dedicated \u201cshard validators multicast overlay network\u201d, using the general mechanisms of the TON Network (cf. 3.3 ). When a new shardchain block needs to be generated\u2014normally one or two seconds after the most recent masterchain block has been propagated\u2014everybody knows who has the highest priority to generate the next block (cf. 2.6.9 ). This validator will create a new collated block candidate, either by itself or with the aid of a collator (cf. 2.6.5 ). The validator must check (validate) this block candidate (especially if it has been prepared by some collator) and sign it with its (validator) private key. Then the block candidate is propagated to the remainder of the task group using the prearranged multicast overlay network (the task group creates its own private overlay network as explained in 3.3 , and then uses a version of the streaming multicast protocol described in 3.3.15 to propagate block candidates). A truly BFT way of doing this would be to use a Byzantine multicast protocol, such as the one used in Honey Badger BFT [ 11 ]: encode the block candidate by an (N, 2N/3)-erasure code, send 1/N of the resulting data directly to each member of the group, and expect them to multicast directly their part of the data to all other members of the group. However, a faster and more straightforward way of doing this (cf. also 3.3.15 ) is to split the block candidate into a sequence of signed one-kilobyte blocks (\u201cchunks\u201d), augment their sequence by a Reed\u2013Solomon or a fountain code (such as the RaptorQ code [ 9 ] [ 14 ]), and start transmitting chunks to the neighbors in the \u201cmulticast mesh\u201d (i.e., the overlay network), expecting them to propagate these chunks further. Once a validator obtains enough chunks to reconstruct the block candidate from them, it signs a confirmation receipt and propagates it through its neighbors to the whole of the group. Then its neighbors stop sending new chunks to it, but may continue to send the (original) signatures of these chunks, believing that this node can generate the subsequent chunks by applying the Reed\u2013Solomon or fountain code by itself (having all data necessary), combine them with signatures, and propagate to its neighbors that are not yet ready. If the \u201cmulticast mesh\u201d (overlay network) remains connected after removing all \u201cbad\u201d nodes (recall that up to one-third of nodes are allowed to be bad in a Byzantine way, i.e., behave in arbitrary malicious fashion), this algorithm will propagate the block candidate as quickly as possible. Not only the designated high-priority block creator may multicast its block candidate to the whole of the group. The second and third validator by priority may start multicasting their block candidates, either immediately or after failing to receive a block candidate from the top priority validator. However, normally only the block candidate with maximal priority will be signed by all (actually, by at least two-thirds of the task group) validators and committed as a new shardchain block. 2.6.12. Election of the next block candidate. Once a block candidate collects at least two-thirds (by stake) of the validity signatures of validators in the task group, it is eligible to be committed as the next shardchain block. A BFT protocol is run to achieve consensus on the block candidate chosen (there may be more than one proposed), with all \u201cgood\u201d validators preferring the block candidate with the highest priority for this round. As a result of running this protocol, the block is augmented by signatures of at least two-thirds of the validators (by stake). These signatures testify not only to the validity of the block in question, but also to its being elected by the BFT protocol. After that, the block (without collated data) is combined with these signatures, serialized in a deterministic way, and propagated through the network to all parties concerned. 2.6.15. Generation of new masterchain blocks. After all (or almost all) new shardchain blocks have been generated, a new masterchain block may be generated. The procedure is essentially the same as for shardchain blocks (cf. 2.6.12 ), with the difference that all validators (or at least two-thirds of them) must participate in this process. Because the headers and signatures of new shardchain blocks are propagated to all validators, hashes of the newest blocks in each shardchain can and must be included in the new masterchain block. Once these hashes are committed into the masterchain block, outside observers and other shardchains may consider the new shardchain blocks committed and immutable (cf. 2.1.13 ). 2.7 Splitting and Merging Shardchains 2.7.6. Determining the necessity of split operations. The split operation for a shardchain is triggered by certain formal conditions (e.g., if for 64 consecutive blocks the shardchain blocks are at least 90% full). These conditions are monitored by the shardchain task group. If they are met, first a \u201csplit preparation\u201d flag is included in the header of a new shardchain block (and propagated to the masterchain block referring to this shardchain block). Then, several blocks afterwards, the \u201csplit commit\u201d flag is included in the header of the shardchain block (and propagated to the next masterchain block). 2.7.8. Determining the necessity of merge operations. The necessity of shard merge operations is also detected by certain formal conditions (e.g., if for 64 consecutive blocks the sum of the sizes of the two blocks of sibling shardchains does not exceed 60% of maximal block size). These formal conditions should also take into account the total gas spent by these blocks and compare it to the current block gas limit, otherwise the blocks may happen to be small because there are some computation-intensive transactions that prevent the inclusion of more transactions. These conditions are monitored by validator task groups of both sibling shards (w, s.0) and (w, s.1). Notice that siblings are necessarily neighbors with respect to hypercube routing (cf. 2.4.19 ), so validators from the task group of any shard will be monitoring the sibling shard to some extent anyways. When these conditions are met, either one of the validator subgroups can suggest to the other that they merge by sending a special message. Then they combine into a provisional \u201cmerged task group\u201d, with combined membership, capable of running BFT consensus algorithms and of propagating block updates and block candidates if necessary. If they reach consensus on the necessity and readiness of merging, \u201cmerge prepare\u201d flags are committed into the headers of some blocks of each shardchain, along with the signatures of at least two-thirds of the validators of the sibling\u2019s task group (and are propagated to the next masterchain blocks, so that everybody can get ready for the imminent reconfiguration). However, they continue to create separate shardchain blocks for some predefined number of blocks. 2.8 Classification of Blockchain Projects 2.8.4. Variants of Proof-of-Stake. DPOS vs. BFT. While Proof-of-Work algorithms are very similar to each other and differ mostly in the hash functions that must be computed for mining new blocks, there are more possibilities for Proof-of-Stake algorithms. They merit a sub-classification of their own. Essentially, one must answer the following questions about a Proof-ofStake algorithm: Who can produce (\u201cmine\u201d) a new block\u2014any full node, or only a member of a (relatively) small subset of validators? (Most PoS systems require new blocks to be generated and signed by one of several designated validators.) Do validators guarantee the validity of the blocks by their signatures, or are all full nodes expected to validate all blocks by themselves? (Scalable PoS systems must rely on validator signatures instead of requiring all nodes to validate all blocks of all blockchains.) Is there a designated producer for the next blockchain block, known in advance, such that nobody else can produce that block instead? Is a newly-created block originally signed by only one validator (its producer), or must it collect a majority of validator signatures from the very beginning? While there seem to be 2^4 possible classes of PoS algorithms depending on the answers to these questions, the distinction in practice boils down to two major approaches to PoS. In fact, most modern PoS algorithms, designed to be used in scalable multi-chain systems, answer the first two questions in the same fashion: only validators can produce new blocks, and they guarantee block validity without requiring all full nodes to check the validity of all blocks by themselves. As to the two last questions, their answers turn out to be highly correlated, leaving essentially only two basic options: Delegated Proof-of-Stake (DPOS): There is a universally known designated producer for every block; no one else can produce that block; the new block is originally signed only by its producing validator. Byzantine Fault Tolerant (BFT) PoS algorithms: There is a known subset of validators, any of which can suggest a new block; the choice of the actual next block among several suggested candidates, which must be validated and signed by a majority of validators before being released to the other nodes, is achieved by a version of Byzantine Fault Tolerant consensus protocol. 2.8.5. Comparison of DPOS and BFT PoS. The BFT approach has the advantage that a newly-produced block has from the very beginning the signatures of a majority of validators testifying to its validity. Another advantage is that, if a majority of validators executes the BFT consensus protocol correctly, no forks can appear at all. On the other hand, BFT algorithms tend to be quite convoluted and require more time for the subset of validators to reach consensus. Therefore, blocks cannot be generated too often. This is why we expect the TON Blockchain (which is a BFT project from the perspective of this classification) to produce a block only once every five seconds. In practice, this interval might be decreased to 2\u20133 seconds (though we do not promise this), but not further, if validators are spread across the globe. The DPOS algorithm has the advantage of being quite simple and straightforward. It can generate new blocks quite often\u2014say, once every two seconds, or maybe even once every second,* because of its reliance on designated block producers known in advance. However, DPOS requires all nodes\u2014or at least all validators\u2014to validate all blocks received, because a validator producing and signing a new block confirms not only the relative validity of this block, but also the validity of the previous block it refers to, and all the blocks further back in the chain (maybe up to the beginning of the period of responsibility of the current subset of validators). There is a predetermined order on the current subset of validators, so that for each block there is a designated producer (i.e., validator expected to generate that block); these designated producers are rotated in a round-robin fashion. In this way, a block is at first signed only by its producing validator; then, when the next block is mined, and its producer chooses to refer to this block and not to one of its predecessors (otherwise its block would lie in a shorter chain, which might lose the \u201clongest fork\u201d competition in the future), the signature of the next block is essentially an additional signature on the previous block as well. In this way, a new block gradually collects the signatures of more validators\u2014say, twenty signatures in the time needed to generate the next twenty blocks. A full node will either need to wait for these twenty signatures, or validate the block by itself, starting from a sufficiently confirmed block (say, twenty blocks back), which might be not so easy. The obvious disadvantage of the DPOS algorithm is that a new block (and transactions committed into it) achieves the same level of trust (\u201crecursive reliability\u201d as discussed in 2.6.28) only after twenty more blocks are mined, compared to the BFT algorithms, which deliver this level of trust (say, twenty signatures) immediately. Another disadvantage is that DPOS uses the \u201clongest fork wins\u201d approach for switching to other forks; this makes forks quite probable if at least some producers fail to produce subsequent blocks after the one we are interested in (or we fail to observe these blocks because of a network partition or a sophisticated attack). We believe that the BFT approach, while more sophisticated to implement and requiring longer time intervals between blocks than DPOS, is better adapted to \u201ctightly-coupled\u201d (cf. 2.8.14) multichain systems, because other blockchains can start acting almost immediately after seeing a committed transaction (e.g., generating a message intended for them) in a new block, without waiting for twenty confirmations of validity (i.e., the next twenty blocks), or waiting for the next six blocks to be sure that no forks appear and verifying the new block by themselves (verifying blocks of other blockchains may become prohibitive in a scalable multi-chain system). Thus they can achieve scalability while preserving high reliability and availability (cf. 2.8.12 ). On the other hand, DPOS might be a good choice for a \u201cloosely-coupled\u201d multi-chain system, where fast interaction between blockchains is not required \u2013 e.g., if each blockchain (\u201cworkchain\u201d) represents a separate distributed exchange, and inter-blockchain interaction is limited to rare transfers of tokens from one workchain into another (or, rather, trading one altcoin residing in one workchain for another at a rate approaching 1 : 1). This is what is actually done in the BitShares project, which uses DPOS quite successfully. To summarize, while DPOS can generate new blocks and include transactions into them faster (with smaller intervals between blocks), these transactions reach the level of trust required to use them in other blockchains and off-chain applications as \u201ccommitted\u201d and \u201cimmutable\u201d much more slowly than in the BFT systems\u2014say, in thirty seconds** instead of five. Faster transaction inclusion does not mean faster transaction commitment. This could become a huge problem if fast inter-blockchain interaction is required. In that case, one must abandon DPOS and opt for BFT PoS instead. *Some people even claim DPOS block generation times of half a second, which does not seem realistic if validators are scattered across several continents. **For instance, EOS, one of the best DPOS projects proposed up to this date, promises a 45-second confirmation and inter-blockchain interaction delay (cf. [ 5 ], \u201cTransaction Confirmation\u201d and \u201cLatency of Interchain Communication\u201d sections). 2.8.8. Blockchain types: homogeneous and heterogeneous systems. In a multi-chain system, all blockchains may be essentially of the same type and have the same rules (i.e., use the same format of transactions, the same virtual machine for executing smart-contract code, share the same cryptocurrency, and so on), and this similarity is explicitly exploited, but with different data in each blockchain. In this case, we say that the system is homogeneous . Otherwise, different blockchains (which will usually be called workchains inthis case) can have different \u201crules\u201d. Then we say that the system is heterogeneous . 2.8.10. Heterogeneous systems with several workchains having the same rules, or confederations . In some cases, several blockchains (workchains) with the same rules can be present in a heterogeneous system, but the interaction between them is the same as between blockchains with different rules (i.e., their similarity is not exploited explicitly). Even if they appear to use \u201cthe same\u201d cryptocurrency, they in fact use different \u201caltcoins\u201d (independent incarnations of the cryptocurrency). Sometimes one can even have certain mechanisms to convert these altcoins at a rate near to 1 : 1. However, this does not make the system homogeneous in our view; it remains heterogeneous. We say that such a heterogeneous collection of workchains with the same rules is a confederation . While making a heterogeneous system that allows one to create several workchains with the same rules (i.e., a confederation) may seem a cheap way of building a scalable system, this approach has a lot of drawbacks, too. Essentially, if someone hosts a large project in many workchains with the same rules, she does not obtain a large project, but rather a lot of small instances of this project. This is like having a chat application (or a game) that allows having at most 50 members in any chat (or game) room, but \u201cscales\u201d by creating new rooms to accommodate more users when necessary. As a result, a lot of users can participate in the chats or in the game, but can we say that such a system is truly scalable? 2.8.12. Sharding support. Some blockchain projects (or systems) have native support for sharding, meaning that several (necessarily homogeneous; cf. 2.8.8 ) blockchains are thought of as shards of a single (from a high-level perspective) virtual blockchain. For example, one can create 256 shard blockchains (\u201cshardchains\u201d) with the same rules, and keep the state of an account in exactly one shard selected depending on the first byte of its account_id. Sharding is a natural approach to scaling blockchain systems, because, if it is properly implemented, users and smart contracts in the system need not be aware of the existence of sharding at all. In fact, one often wants to add sharding to an existing single-chain project (such as Ethereum) when the load becomes too high. An alternative approach to scaling would be to use a \u201cconfederation\u201d of heterogeneous workchains as described in 2.8.10 , allowing each user to keep her account in one or several workchains of her choice, and transfer funds from her account in one workchain to another workchain when necessary, essentially performing a 1 : 1 altcoin exchange operation. The drawbacks of this approach have already been discussed in 2.8.10 . However, sharding is not so easy to implement in a fast and reliable fashion, because it implies a lot of messages between different shardchains. For example, if accounts are evenly distributed between N shards, and the only transactions are simple fund transfers from one account to another, then only a small fraction (1/N) of all transactions will be performed within a single blockchain; almost all (1 \u2212 1/N) transactions will involve two blockchains, requiring inter-blockchain communication. If we want these transactions to be fast, we need a fast system for transferring messages between shardchains. In other words, the blockchain project needs to be \u201ctightly-coupled\u201d in the sense described in 2.8.14 . 2.8.13. Dynamic and static sharding. Sharding might be dynamic (if additional shards are automatically created when necessary) or static (when there is a predefined number of shards, which is changeable only through a hard fork at best). Most sharding proposals are static; the TON Blockchain uses dynamic sharding (cf. 2.7 ). 2.8.14. Interaction between blockchains: loosely-coupled and tightly-coupled systems. Multi-blockchain projects can be classified according to the supported level of interaction between the constituent blockchains. The least level of support is the absence of any interaction between different blockchains whatsoever. We do not consider this case here, because we would rather say that these blockchains are not parts of one blockchain system, but just separate instances of the same blockchain protocol. The next level of support is the absence of any specific support for messaging between blockchains, making interaction possible in principle, but awkward. We call such systems \u201cloosely-coupled\u201d; in them one must send messages and transfer value between blockchains as if they had been blockchains belonging to completely separate blockchain projects (e.g., Bitcoin and Ethereum; imagine two parties want to exchange some Bitcoins, kept in the Bitcoin blockchain, into Ethers, kept in the Ethereum blockchain). In other words, one must include the outbound message (or its generating transaction) in a block of the source blockchain. Then she (or some other party) must wait for enough confirmations (e.g., a given number of subsequent blocks) to consider the originating transaction to be \u201ccommitted\u201d and \u201cimmutable\u201d, so as to be able to perform external actions based on its existence. Only then may a transaction relaying the message into the target blockchain (perhaps along with a reference and a Merkle proof of existence for the originating transaction) be committed. If one does not wait long enough before transferring the message, or if a fork happens anyway for some other reason, the joined state of the two blockchains turns out to be inconsistent: a message is delivered into the second blockchain that has never been generated in (the ultimately chosen fork of) the first blockchain. Sometimes partial support for messaging is added, by standardizing the format of messages and the location of input and output message queues in the blocks of all workchains (this is especially useful in heterogeneous systems). While this facilitates messaging to a certain extent, it is conceptually not too different from the previous case, so such systems are still \u201cloosely-coupled\u201d. By contrast, \u201ctightly-coupled\u201d systems include special mechanisms to provide fast messaging between all blockchains. The desired behavior is to be able to deliver a message into another workchain immediately after it has been generated in a block of the originating blockchain. On the other hand, \u201ctightly-coupled\u201d systems are also expected to maintain overall consistency in the case of forks. While these two requirements appear to be contradictory at first glance, we believe that the mechanisms used by the TON Blockchain (the inclusion of shardchain block hashes into masterchain blocks; the use of \u201cvertical\u201d blockchains for fixing invalid blocks, cf. 2.1.17 ; hypercube routing, cf. 2.4.19 ; Instant Hypercube Routing, cf. 2.4.20 ) enable it to be a \u201ctightly-coupled\u201d system, perhaps the only one so far. Of course, building a \u201cloosely-coupled\u201d system is much simpler; however, fast and efficient sharding (cf. 2.8.12 ) requires the system to be \u201ctightlycoupled\u201d. 2.8.16. Complications of changing the \u201cgenome\u201d of a blockchain project. The above classification defines the \u201cgenome\u201d of a blockchain project. This genome is quite \u201crigid\u201d: it is almost impossible to change it once the project is deployed and is used by a lot of people. One would need a series of hard forks (which would require the approval of the majority of the community), and even then the changes would need to be very conservative in order to preserve backward compatibility (e.g., changing the semantics of the virtual machine might break existing smart contracts). An alternative would be to create new \u201csidechains\u201d with their different rules, and bind them somehow to the blockchain (or the blockchains) of the original project. One might use the blockchain of the existing single-blockchain project as an external masterchain for an essentially new and separate project. Our conclusion is that the genome of a project is very hard to change once it has been deployed. Even starting with PoW and planning to replace it with PoS in the future is quite complicated. Adding shards to a project originally designed without support for them seems almost impossible. In fact, adding support for smart contracts into a project (namely, Bitcoin) originally designed without support for such features has been deemed impossible (or at least undesirable by the majority of the Bitcoin community) and eventually led to the creation of a new blockchain project, Ethereum. *For example, the Plasma project plans to use the Ethereum blockchain as its (external) masterchain; it does not interact much with Ethereum otherwise, and it could have been suggested and implemented by a team unrelated to the Ethereum project. **As of 2017, Ethereum is still struggling to transition from PoW to a combined PoW+PoS system; we hope it will become a truly PoS system someday. ***There are sharding proposals for Ethereum dating back to 2015; it is unclear how they might be implemented and deployed without disrupting Ethereum or creating an essentially independent parallel project. 2.9 Comparsion with other blockchain projects 2.9.7. EOS [5]; https://eos.io. EOS (2018 or later) is a proposed heterogeneous multi-blockchain DPoS system with smart contract support and with some minimal support for messaging (still loosely-coupled in the sense described in 2.8.14). It is an attempt by the same team that has previously successfully created the BitShares and SteemIt projects, demonstrating the strong points of the DPoS consensus algorithm. Scalability will be achieved by creating specialized workchains for projects that need it (e.g., a distributed exchange might use a workchain supporting a special set of optimized transactions, similarly to what BitShares did) and by creating multiple workchains with the same rules (confederations in the sense described in 2.8.10). The drawbacks and limitations of this approach to scalability have been discussed in loc. cit. Cf. also 2.8.5, 2.8.12, and 2.8.14 for a more detailed discussion of DPoS, sharding, interaction between workchains and their implications for the scalability of a blockchain system. At the same time, even if one will not be able to \u201ccreate a Facebook inside a blockchain\u201d (cf. 2.9.13), EOS or otherwise, we think that EOS might become a convenient platform for some highly-specialized weakly interacting distributed applications, similar to BitShares (decentralized exchange) and SteemIt (decentralized blog platform). 2.9.8. PolkaDot [17]; https://polkadot.io/. PolkaDot (2019 or later) is one of the best thought-out and most detailed proposed multichain Proofof-Stake projects; its development is led by one of the Ethereum co-founders. This project is one of the closest projects to the TON Blockchain on our map. (In fact, we are indebted for our terminology for \u201cfishermen\u201d and \u201cnominators\u201d to the PolkaDot project.) PolkaDot is a heterogeneous loosely-coupled multichain Proof-of-Stake project, with Byzantine Fault Tolerant (BFT) consensus for generation of new blocks and a masterchain (which might be external\u2014e.g., the Ethereum blockchain). It also uses hypercube routing, somewhat like (the slow version of) TON\u2019s as described in 2.4.19 . Its unique feature is its ability to create not only public, but also private blockchains. These private blockchains would also be able to interact with other public blockchains, PolkaDot or otherwise. As such, PolkaDot might become a platform for large-scale private blockchains, which might be used, for example, by bank consortiums to quickly transfer funds to each other, or for any other uses a large corporation might have for private blockchain technology. However, PolkaDot has no sharding support and is not tightly-coupled. This somewhat hampers its scalability, which is similar to that of EOS. (Perhaps a bit better, because PolkaDot uses BFT PoS instead of DPoS.) 2.9.13. Is it possible to \u201cupload Facebook into a blockchain\u201d? Sometimes people claim that it will be possible to implement a social network on the scale of Facebook as a distributed application residing in a blockchain. Usually a favorite blockchain project is cited as a possible \u201chost\u201d for such an application. We cannot say that this is a technical impossibility. Of course, one needs a tightly-coupled blockchain project with true sharding (i.e., TON) in order for such a large application not to work too slowly (e.g., deliver messages and updates from users residing in one shardchain to their friends residing in another shardchain with reasonable delays). However, we think that this is not needed and will never be done, because the price would be prohibitive. Let us consider \u201cuploading Facebook into a blockchain\u201d as a thought experiment; any other project of similar scale might serve as an example as well. Once Facebook is uploaded into a blockchain, all operations currently done by Facebook\u2019s servers will be serialized as transactions in certain blockchains (e.g., TON\u2019s shardchains), and will be performed by all validators of these blockchains. Each operation will have to be performed, say, at least twenty times, if we expect every block to collect at least twenty validator signatures (immediately or eventually, as in DPOS systems). Similarly, all data kept by Facebook\u2019s servers on their disks will be kept on the disks of all validators for the corresponding shardchain (i.e., in at least twenty copies). Because the validators are essentially the same servers (or perhaps clusters of servers, but this does not affect the validity of this argument) as those currently used by Facebook, we see that the total hardware expenses associated with running Facebook in a blockchain are at least twenty times higher than if it were implemented in the conventional way. In fact, the expenses would be much higher still, because the blockchain\u2019s virtual machine is slower than the \u201cbare CPU\u201d running optimized compiled code, and its storage is not optimized for Facebook-specific problems. One might partially mitigate this problem by crafting a specific workchain with some special transactions adapted for Facebook; this is the approach of BitShares and EOS to achieving high performance, available in the TON Blockchain as well. However, the general blockchain design would still impose some additional restrictions by itself, such as the necessity to register all operations as transactions in a block, to organize these transactions in a Merkle tree, to compute and check their Merkle hashes, to propagate this block further, and so on. Therefore, a conservative estimate is that one would need 100 times more servers of the same performance as those used by Facebook now in order to validate a blockchain project hosting a social network of that scale. Somebody will have to pay for these servers, either the company owning the distributed application (imagine seeing 700 ads on each Facebook page instead of 7) or its users. Either way, this does not seem economically viable. We believe that it is not true that everything should be uploaded into the blockchain. For example, it is not necessary to keep user photographs in the blockchain; registering the hashes of these photographs in the blockchain and keeping the photographs in a distributed off-chain storage (such as FileCoin or TON Storage) would be a better idea. This is the reason why TON is not just a blockchain project, but a collection of several components (TON P2P Network, TON Storage, TON Services) centered around the TON Blockchain as outlined in Chapters 1 and 4 . \\3. TON Networking Under construction. First we add chapters we have to refer to from our product docs. Any blockchain project requires not only a specification of block format and blockchain validation rules, but also a network protocol used to propagate new blocks, send and collect transaction candidates and so on. In other words, a specialized peer-to-peer network must be set up by every blockchain project. This network must be peer-to-peer, because blockchain projects are normally expected to be decentralized, so one cannot rely on a centralized group of servers and use conventional client-server architecture, as, for instance, classical online banking applications do. Even light clients (e.g., light cryptocurrency wallet smartphone applications), which must connect to full nodes in a client-server\u2013like fashion, are actually free to connect to another full node if their previous peer goes down, provided the protocol used to connect to full nodes is standardized enough. While the networking demands of single-blockchain projects, such as Bitcoin or Ethereum, can be met quite easily (one essentially needs to construct a \u201crandom\u201d peer-to-peer overlay network, and propagate all new blocks and transaction candidates by a gossip protocol), multi-blockchain projects, such as the TON Blockchain, are much more demanding (e.g., one must be able to subscribe to updates of only some shardchains, not necessarily all of them). Therefore, the networking part of the TON Blockchain and the TON Project as a whole merits at least a brief discussion. On the other hand, once the more sophisticated network protocols needed to support the TON Blockchain are in place, it turns out that they can easily be used for purposes not necessarily related to the immediate demands of the TON Blockchain, thus providing more possibilities and flexibility for creating new services in the TON ecosystem. TON Networking 3.1 Abstract Datagram Network Layer The cornerstone in building the TON networking protocols is the (TON) Abstract (Datagram) Network Layer. It enables all nodes to assume certain \u201cnetwork identities\u201d, represented by 256-bit \u201cabstract network addresses\u201d, and communicate (send datagrams to each other, as a first step) using only these 256-bit network addresses to identify the sender and the receiver. In particular, one does not need to worry about IPv4 or IPv6 addresses, UDP port numbers, and the like; they are hidden by the Abstract Network Layer. 3.1.1. Abstract network addresses. An abstract network address, or an abstract address, or just address for short, is a 256-bit integer, essentially equal to a 256-bit ECC public key. This public key can be generated arbitrarily, thus creating as many different network identities as the node likes. However, one must know the corresponding private key in order to receive (and decrypt) messages intended for such an address. In fact, the address is not the public key itself; instead, it is a 256-bit hash (Hash = sha256) of a serialized TL-object (cf. 2.2.5 ) that can describe several types of public keys and addresses depending on its constructor (first four bytes). In the simplest case, this serialized TL-object consists just of a 4-byte magic number and a 256-bit elliptic curve cryptography (ECC) public key; in this case, the address will equal the hash of this 36-byte structure. One might use, however, 2048-bit RSA keys, or any other scheme of publickey cryptography instead. When a node learns another node\u2019s abstract address, it must also receive its \u201cpreimage\u201d (i.e., the serialized TL-object, the hash of which equals that abstract address) or else it will not be able to encrypt and send datagrams to that address. 3.1.2. Lower-level networks. UDP implementation. From the perspective of almost all TON Networking components, the only thing that exists is a network (the Abstract Datagram Networking Layer) able to (unreliably) send datagrams from one abstract address to another. In principle, the Abstract Datagram Networking Layer (ADNL) can be implemented over different existing network technologies. However, we are going to implement it over UDP in IPv4/IPv6 networks (such as the Internet or intranets), with an optional TCP fallback if UDP is not available. 3.1.3. Simplest case of ADNL over UDP. The simplest case of sending a datagram from a sender\u2019s abstract address to any other abstract address (with known preimage) can be implemented as follows. Suppose that the sender somehow knows the IP-address and the UDP port of the receiver who owns the destination abstract address, and that both the receiver and the sender use abstract addresses derived from 256-bit ECC public keys. In this case, the sender simply augments the datagram to be sent by its ECC signature (done with its private key) and its source address (or the preimage of the source address, if the receiver is not known to know that preimage yet). The result is encrypted with the recipient\u2019s public key, embedded into a UDP datagram and sent to the known IP and port of the recipient. Because the first 256 bits of the UDP datagram contain the recipient\u2019s abstract address, the recipient can identify which private key should be used to decrypt the remainder of the datagram. Only after that is the sender\u2019s identity revealed. 3.1.4. Less secure way, with the sender\u2019s address in plaintext. Sometimes a less secure scheme is sufficient, when the recipient\u2019s and the sender\u2019s addresses are kept in plaintext in the UDP datagram; the sender\u2019s private key and the recipient\u2019s public key are combined together using ECDH (Elliptic Curve Diffie\u2013Hellman) to generate a 256-bit shared secret, which is used afterwards, along with a random 256-bit nonce also included in the unencrypted part, to derive AES keys used for encryption. The integrity may be provided, for instance, by concatenating the hash of the original plaintext data to the plaintext before encryption. This approach has the advantage that, if more than one datagram is expected to be exchanged between the two addresses, the shared secret can be computed only once and then cached; then slower elliptic curve operations will no longer be required for encrypting or decrypting the next datagrams. 3.1.5. Channels and channel identifiers. In the simplest case, the first 256 bits of a UDP datagram carrying an embedded TON ADNL datagram will be equal to the recipient\u2019s address. However, in general they constitute a channel identifier. There are different types of channels. Some of them are point-to-point; they are created by two parties who wish to exchange a lot of data in the future and generate a shared secret by exchanging several packets encrypted as described in 3.1.3 or 3.1.4 , by running classical or elliptic curve Diffie\u2013Hellman (if extra security is required), or simply by one party generating a random shared secret and sending it to the other party. After that, a channel identifier is derived from the shared secret combined with some additional data (such as the sender\u2019s and recipient\u2019s addresses), for instance by hashing, and that identifier is used as the first 256 bits of UDP datagrams carrying data encrypted with the aid of that shared secret. 3.1.6. Channel as a tunnel identifier. In general, a \u201cchannel\u201d, or \u201cchannel identifier\u201d simply selects a way of processing an inbound UDP datagram, known to the receiver. If the channel is the receiver\u2019s abstract address, the processing is done as outlined in 3.1.3 or 3.1.4 ; if the channel is an estabished point-to-point channel discussed in 3.1.5 , the processing consists in decrypting the datagram with the aid of the shared secret as explained in loc. cit., and so on. In particular, a channel identifier can actually select a \u201ctunnel\u201d, when the immediate recipient simply forwards the received message to somebody else\u2014the actual recipient or another proxy. Some encryption or decryption steps (reminiscent of \u201conion routing\u201d [ 6 ] or even \u201cgarlic routing\u201d *) might be done along the way, and another channel identifier might be used for reencrypted forwarded packets (for example, a peer-to-peer channel could be employed to forward the packet to the next recipient on the path). In this way, some support for \u201ctunneling\u201d and \u201cproxying\u201d\u2014somewhat similar to that provided by the TOR or I2P projects\u2014can be added on the level of the TON Abstract Datagram Network Layer, without affecting the functionality of all higher-level TON network protocols, which would be agnostic of such an addition. This opportunity is exploited by the TON Proxy service (cf. 4.1.11 ). * https://geti2p.net/en/docs/how/garlic-routing 3.1.7. Zero channel and the bootstrap problem. Normally, a TON ADNL node will have some \u201cneighbor table\u201d, containing information about other known nodes, such as their abstract addresses and their preimages (i.e., public keys) and their IP addresses and UDP ports. Then it will gradually extend this table by using information learned from these known nodes as answers to special queries, and sometimes prune obsolete records. However, when a TON ADNL node just starts up, it may happen that it does not know any other node, and can learn only the IP address and UDP port of a node, but not its abstract address. This happens, for example, if a light client is not able to access any of the previously cached nodes and any nodes hardcoded into the software, and must ask the user to enter an IP address or a DNS domain of a node, to be resolved through DNS. In this case, the node will send packets to a special \u201czero channel\u201d of the node in question. This does not require knowledge of the recipient\u2019s public key (but the message should still contain the sender\u2019s identity and signature), so the message is transferred without encryption. It should be normally used only to obtain an identity (maybe a one-time identity created especially for this purpose) of the receiver, and then to start communicating in a safer way. Once at least one node is known, it is easy to populate the \u201cneighbor table\u201d and \u201crouting table\u201d by more entries, learning them from answers to special queries sent to the already known nodes. Not all nodes are required to process datagrams sent to the zero channel, but those used to bootstrap light clients should support this feature. 3.1.8. TCP-like stream protocol over ADNL. The ADNL, being an unreliable (small-size) datagram protocol based on 256-bit abstract addresses, can be used as a base for more sophisticated network protocols. One can build, for example, a TCP-like stream protocol, using ADNL as an abstract replacement for IP. However, most components of the TON Project do not need such a stream protocol. 3.1.9. RLDP, or Reliable Large Datagram Protocol over ADNL. A reliable arbitrary-size datagram protocol built upon the ADNL, called RLDP, is used instead of a TCP-like protocol. This reliable datagram protocol can be employed, for instance, to send RPC queries to remote hosts and receive answers from them (cf. 4.1.5 ). 3.2 TON DHT: Kademlia-like Distributed Hash Table The TON Distributed Hash Table (DHT) plays a crucial role in the networking part of the TON Project, being used to locate other nodes in the network. For example, a client wanting to commit a transaction into a shardchain might want to find a validator or a collator of that shardchain, or at least some node that might relay the client\u2019s transaction to a collator. This can be done by looking up a special key in the TON DHT. Another important application of the TON DHT is that it can be used to quickly populate a new node\u2019s neighbor table (cf. 3.1.7 ), simply by looking up a random key, or the new node\u2019s address. If a node uses proxying and tunneling for its inbound datagrams, it publishes the tunnel identifier and its entry point (e.g., IP address and UDP port) in the TON DHT; then all nodes wishing to send datagrams to that node will obtain this contact information from the DHT first. The TON DHT is a member of the family of Kademlia-like distributed hash tables [ 10 ]. 3.2.10. Distributed \u201ctorrent trackers\u201d and \u201cnetwork interest groups\u201d in TON DHT. Yet another interesting case is when the value contains a list of nodes\u2014perhaps with their IP addresses and ports, or just with their abstract addresses\u2014and the \u201cupdate rule\u201d consists in including the requester in this list, provided she can confirm her identity. This mechanism might be used to create a distributed \u201ctorrent tracker\u201d, where all nodes interested in a certain \u201ctorrent\u201d (i.e., a certain file) can find other nodes that are interested in the same torrent, or already have a copy. TON Storage (cf. 4.1.8 ) uses this technology to find the nodes that have a copy of a required file (e.g., a snapshot of the state of a shardchain, or an old block). However, its more important use is to create \u201coverlay multicast subnetworks\u201d and \u201cnetwork interest groups\u201d (cf. 3.3 ). The idea is that only some nodes are interested in the updates of a specific shardchain. If the number of shardchains becomes very large, finding even one node interested in the same shard may become complicated. This \u201cdistributed torrent tracker\u201d provides a convenient way to find some of these nodes. Another option would be to request them from a validator, but this would not be a scalable approach, and validators might choose not to respond to such queries coming from arbitrary unknown nodes. 3.2.12. Locating services. Some services, located in the TON Network and available through the (higher-level protocols built upon the) TON ADNL described in 3.1 , may want to publish their abstract addresses somewhere, so that their clients would know where to find them. However, publishing the service\u2019s abstract address in the TON Blockchain may not be the best approach, because the abstract address might need to be changed quite often, and because it could make sense to provide several addresses, for reliability or load balancing purposes. An alternative is to publish a public key into the TON Blockchain, and use a special DHT key indicating that public key as its \u201cowner\u201d in the TL description string (cf. 2.2.5 ) to publish an up-to-date list of the service\u2019s abstract addresses. This is one of the approaches exploited by TON Services. 3.2.14. Locating abstract addresses. Notice that the TON DHT, while being implemented over TON ADNL, is itself used by the TON ADNL for several purposes. The most important of them is to locate a node or its contact data starting from its 256-bit abstract address. This is necessary because the TON ADNL should be able to send datagrams to arbitrary 256-bit abstract addresses, even if no additional information is provided. To this end, the 256-bit abstract address is simply looked up as a key in the DHT. Either a node with this address (i.e., using this address as a public semi-persistent DHT address) is found, in which case its IP address and port can be learned; or, an input tunnel description may be retrieved as the value of the key in question, signed by the correct private key, in which case this tunnel description would be used to send ADNL datagrams to the intended recipient. Notice that in order to make an abstract address \u201cpublic\u201d (reachable from any nodes in the network), its owner must either use it as a semi-permanent DHT address, or publish (in the DHT key equal to the abstract address under consideration) an input tunnel description with another of its public abstract addresses (e.g., the semi-permanent address) as the tunnel\u2019s entry point. Another option would be to simply publish its IP address and UDP port. 3.3 Overlay Networks and Multicasting Messages In a multi-blockchain system like the TON Blockchain, even full nodes would normally be interested in obtaining updates (i.e., new blocks) only about some shardchains. To this end, a special overlay (sub)network must be built inside the TON Network, on top of the ADNL protocol discussed in 3.1 , one for each shardchain. Therefore, the need to build arbitrary overlay subnetworks, open to any nodes willing to participate, arises. Special gossip protocols, built upon ADNL, will be run in these overlay networks. In particular, these gossip protocols may be used to propagate (broadcast) arbitrary data inside such a subnetwork. 3.3.10. TON overlay networks are optimized for lower latency. TON overlay networks optimize the \u201crandom\u201d network graph generated by the previous method as follows. Every node tries to retain at least three neighbors with the minimal round-trip time, changing this list of \u201cfast neighbors\u201d very rarely. At the same time, it also has at least three other \u201cslow neighbors\u201d that are chosen completely randomly, so that the overlay network graph would always contain a random subgraph. This is required to maintain connectivity and prevent splitting of the overlay network into several unconnected regional subnetworks. At least three \u201cintermediate neighbors\u201d, which have intermediate round-trip times, bounded by a certain constant (actually, a function of the round-trip times of the fast and the slow neighbors), are also chosen and retained. In this way, the graph of an overlay network still maintains enough randomness to be connected, but is optimized for lower latency and higher throughput. 3.3.15. Streaming broadcast protocol. Finally, there is a streaming broadcast protocol for TON overlay networks, used, for example, to propagate block candidates among validators of some shardchain (\u201cshardchain task group\u201d), who, of course, create a private overlay network for that purpose. The same protocol can be used to propagate new shardchain blocks to all full nodes for that shardchain. This protocol has already been outlined in 2.6.10 : the new (large) broadcast message is split into, say, N one-kilobyte chunks; the sequence of these chunks is augmented to M \u2265 N chunks by means of an erasure code such as the Reed\u2013Solomon or a fountain code (e.g., the RaptorQ code [ 9 ] [ 14 ]), and these M chunks are streamed to all neighbors in ascending chunk number order. The participating nodes collect these chunks until they can recover the original large message (one would have to successfully receive at least N of the chunks for this), and then instruct their neighbors to stop sending new chunks of the stream, because now these nodes can generate the subsequent chunks on their own, having a copy of the original message. Such nodes continue to generate the subsequent chunks of the stream and send them to their neighbors, unless the neighbors in turn indicate that this is no longer necessary. In this way, a node does not need to download a large message in its entirety before propagating it further. This minimizes broadcast latency, especially when combined with the optimizations described in 3.3.10 . \\4. TON Services and Applications Under construction. First we add chapters we have to refer to from our product docs. e. TON Services and Applications We have discussed the TON Blockchain and TON Networking technologies at some length. Now we explain some ways in which they can be combined to create a wide range of services and applications, and discuss some of the services that will be provided by the TON Project itself, either from the very beginning or at a later time. 4.1 TON Service Implementation Strategies We start with a discussion of how different blockchain and network-related applications and services may be implemented inside the TON ecosystem. First of all, a simple classification is in order: 4.1.1. Applications and services. We will use the words \u201capplication\u201d and \u201cservice\u201d interchangeably. However, there is a subtle and somewhat vague distinction: an application usually provides some services directly to human users, while a service is usually exploited by other applications and services. For example, TON Storage is a service, because it is designed to keep files on behalf of other applications and services, even though a human user might use it directly as well. A hypothetical \u201cFacebook in a blockchain\u201d (cf. 2.9.13 ) or Telegram messenger, if made available through the TON Network (i.e., implemented as a \u201cton-service\u201d; cf. 4.1.6 ), would rather be an application, even though some \u201cbots\u201d might access it automatically without human intervention. 4.1.2. Location of the application: on-chain, off-chain or mixed. A service or an application designed for the TON ecosystem needs to keep its data and process that data somewhere. This leads to the following classification of applications (and services): On-chain applications (cf. 4.1.4 ): All data and processing are in the TON Blockchain. Off-chain applications (cf. 4.1.5 ): All data and processing are outside the TON Blockchain, on servers available through the TON Network. Mixed applications (cf. 4.1.7 ): Some, but not all, data and processing are in the TON Blockchain; the rest are on off-chain servers available through the TON Network. 4.1.3. Centralization: centralized and decentralized, or distributed, applications. Another classification criterion is whether the application (or service) relies on a centralized server cluster, or is really \u201cdistributed\u201d (cf. 4.1.9 ). All on-chain applications are automatically decentralized and distributed. Off-chain and mixed applications may exhibit different degrees of centralization. Now let us consider the above possibilities in more detail. 4.1.4. Pure \u201con-chain\u201d applications: distributed applications, or \u201cdapps\u201d, residing in the blockchain. One of the possible approaches, mentioned in 4.1.2 , is to deploy a \u201cdistributed application\u201d (commonly abbreviated as \u201cdapp\u201d) completely in the TON Blockchain, as one smart contract or a collection of smart contracts. All data will be kept as part of the permanent state of these smart contracts, and all interaction with the project will be done by means of (TON Blockchain) messages sent to or received from these smart contracts. We have already discussed in 2.9.13 that this approach has its drawbacks and limitations. It has its advantages, too: such a distributed application needs no servers to run on or to store its data (it runs \u201cin the blockchain\u201d\u2014 i.e., on the validators\u2019 hardware), and enjoys the blockchain\u2019s extremely high (Byzantine) reliability and accessibility. The developer of such a distributed application does not need to buy or rent any hardware; all she needs to do is develop some software (i.e., the code for the smart contracts). After that, she will effectively rent the computing power from the validators, and will pay for it in Grams, either herself or by putting this burden on the shoulders of her users. 4.1.5. Pure network services: \u201cton-sites\u201d and \u201cton-services\u201d. Another extreme option is to deploy the service on some servers and make it available to the users through the ADNL protocol described in 3.1 , and maybe some higher level protocol such as the RLDP discussed in 3.1.9 , which can be used to send RPC queries to the service in any custom format and obtain answers to these queries. In this way, the service will be totally off-chain, and will reside in the TON Network, almost without using the TON Blockchain. The TON Blockchain might be used only to locate the abstract address or addresses of the service, as outlined in 3.2.12 , perhaps with the aid of a service such as the TON DNS (cf. 4.3.1 ) to facilitate translation of domainlike human-readable strings into abstract addresses. To the extent the ADNL network (i.e., the TON Network) is similar to the Invisible Internet Project (I 2P), such (almost) purely network services are analogous to the so-called \u201ceep-services\u201d (i.e., services that have an I 2Paddress as their entry point, and are available to clients through the I 2P network). We will say that such purely network services residing in the TON Network are \u201cton-services\u201d. An \u201ceep-service\u201d may implement HTTP as its client-server protocol; in the TON Network context, a \u201cton-service\u201d might simply use RLDP (cf. 3.1.9 ) datagrams to transfer HTTP queries and responses to them. If it uses the TON DNS to allow its abstract address to be looked up by a human-readable domain name, the analogy to a web site becomes almost perfect. One might even write a specialized browser, or a special proxy (\u201cton-proxy\u201d) that is run locally on a user\u2019s machine, accepts arbitrary HTTP queries from an ordinary web browser the user employs (once the local IP address and the TCP port of the proxy are entered into the browser\u2019s configuration), and forwards these queries through the TON Network to the abstract address of the service. Then the user would have a browsing experience similar to that of the World Wide Web (WWW). In the I 2P ecosystem, such \u201ceep-services\u201d are called \u201ceep-sites\u201d. One can easily create \u201cton-sites\u201d in the TON ecosystem as well. This is facilitated somewhat by the existence of services such as the TON DNS, which exploit the TON Blockchain and the TON DHT to translate (TON) domain names into abstract addresses. 4.1.6. Telegram Messenger as a ton-service; MTProto over RLDP. We would like to mention in passing that the MTProto protocol, used by Telegram Messenger * for client-server interaction, can be easily embedded into the RLDP protocol discussed in 3.1.9 , thus effectively transforming Telegram into a ton-service. Because the TON Proxy technology can be switched on transparently for the end user of a ton-site or a ton-service, being implemented on a lower level than the RLDP and ADNL protocols (cf. 3.1.6 ), this would make Telegram effectively unblockable. Of course, other messaging and social networking services might benefit from this technology as well. * https://core.telegram.org/mtproto ** https://telegram.org/ 4.1.7. Mixed services: partly off-chain, partly on-chain. Some services might use a mixed approach: do most of the processing off-chain, but also have some on-chain part (for example, to register their obligations towards their users, and vice versa). In this way, part of the state would still be kept in the TON Blockchain (i.e., an immutable public ledger), and any misbehavior of the service or of its users could be punished by smart contracts. 4.1.8. Example: keeping files off-chain; TON Storage. An example of such a service is given by TON Storage. In its simplest form, it allows users to store files off-chain, by keeping on-chain only a hash of the file to be stored, and possibly a smart contract where some other parties agree to keep the file in question for a given period of time for a pre-negotiated fee. In fact, the file may be subdivided into chunks of some small size (e.g., 1 kilobyte), augmented by an erasure code such as a Reed\u2013Solomon or a fountain code, a Merkle tree hash may be constructed for the augmented sequence of chunks, and this Merkle tree hash might be published in the smart contract instead of or along with the usual hash of the file. This is somewhat reminiscent of the way files are stored in a torrent. An even simpler form of storing files is completely off-chain: one might essentially create a \u201ctorrent\u201d for a new file, and use TON DHT as a \u201cdistributed torrent tracker\u201d for this torrent (cf. 3.2.10 ). This might actually work pretty well for popular files. However, one does not get any availability guarantees. For example, a hypothetical \u201cblockchain Facebook\u201d (cf. 2.9.13 ), which would opt to keep the profile photographs of its users completely off-chain in such \u201ctorrents\u201d, might risk losing photographs of ordinary (not especially popular) users, or at least risk being unable to present these photographs for prolonged periods. The TON Storage technology, which is mostly off-chain, but uses an on-chain smart contract to enforce availability of the stored files, might be a better match for this task. 4.1.9. Decentralized mixed services, or \u201cfog services\u201d. So far, we have discussed centralized mixed services and applications. While their on-chain component is processed in a decentralized and distributed fashion, being located in the blockchain, their off-chain component relies on some servers controlled by the service provider in the usual centralized fashion. Instead of using some dedicated servers, computing power might be rented from a cloud computing service offered by one of the large companies. However, this would not lead to decentralization of the off-chain component of the service. A decentralized approach to implementing the off-chain component of a service consists in creating a market, where anybody possessing the required hardware and willing to rent their computing power or disk space would offer their services to those needing them. For example, there might exist a registry (which might also be called a \u201cmarket\u201d or an \u201cexchange\u201d) where all nodes interested in keeping files of other users publish their contact information, along with their available storage capacity, availability policy, and prices. Those needing these services might look them up there, and, if the other party agrees, create smart contracts in the blockchain and upload files for off-chain storage. In this way a service like TON Storage becomes truly decentralized, because it does not need to rely on any centralized cluster of servers for storing files. 4.1.10. Example: \u201cfog computing\u201d platforms as decentralized mixed services. Another example of such a decentralized mixed application arises when one wants to perform some specific computations (e.g., 3D rendering or training neural networks), often requiring specific and expensive hardware. Then those having such equipment might offer their services through a similar \u201cexchange\u201d, and those needing such services would rent them, with the obligations of the sides registered by means of smart contracts. This is similar to what \u201cfog computing\u201d platforms, such as Golem ( https://golem.network/) or SONM ( https://sonm.io/), promise to deliver. 4.1.11. Example: TON Proxy is a fog service. TON Proxy provides yet another example of a fog service, where nodes wishing to offer their services (with or without compensation) as tunnels for ADNL network traffic might register, and those needing them might choose one of these nodes depending on the price, latency and bandwidth offered. Afterwards, one might use payment channels provided by TON Payments for processing micropayments for the services of those proxies, with payments collected, for instance, for every 128 KiB transferred. 4.1.12. Example: TON Payments is a fog service. The TON Payments platform (cf. 5 ) is also an example of such a decentralized mixed application 4.3 Accessing TON Services We have discussed in 4.1 the different approaches one might employ for creating new services and applications residing in the TON ecosystem. Now we discuss how these services might be accessed, and some of the \u201chelper services\u201d that will be provided by TON, including TON DNS and TON Storage. 4.3.1. TON DNS: a mostly on-chain hierarchical domain name service. The TON DNS is a predefined service, which uses a collection of smart contracts to keep a map from human-readable domain names to (256-bit) addresses of ADNL network nodes and TON Blockchain accounts and smart contracts. While anybody might in principle implement such a service using the TON Blockchain, it is useful to have such a predefined service with a wellknown interface, to be used by default whenever an application or a service wants to translate human-readable identifiers into addresses. 4.3.6. Retrieving data from a DNS smart contract. In principle, any full node for the masterchain or shardchain containing a DNS smart contract might be able to look up any subdomain in the database of that smart contract, if the structure and the location of the hashmap inside the persistent storage of the smart contract are known. However, this approach would work only for certain DNS smart contracts. It would fail miserably if a non-standard DNS smart contract were used. Instead, an approach based on general smart contract interfaces and get methods (cf. 4.3.11 ) is used. Any DNS smart contract must define a \u201cget method\u201d with a \u201cknown signature\u201d, which is invoked to look up a key. Since this approach makes sense for other smart contracts as well, especially those providing on-chain and mixed services, we explain it in some detail in 4.3.11 . 4.3.11. \u201cGet methods\u201d of smart contracts. A better way would be to define some get methods in the smart contract, that is, some types of inbound messages that do not affect the state of the smart contract when delivered, but generate one or more output messages containing the \u201cresult\u201d of the get method. In this way, one can obtain data from a smart contract, knowing only that it implements a get method with a known signature (i.e., a known format of the inbound message to be sent and outbound messages to be received as a result). This way is much more elegant and in line with object oriented programming (OOP). However, it has an obvious defect so far: one must actually commit a transaction into the blockchain (sending the get message to the smart contract), wait until it is committed and processed by the validators, extract the answer from a new block, and pay for gas (i.e., for executing the get method on the validators\u2019 hardware). This is a waste of resources: get methods do not change the state of the smart contract anyways, so they need not be executed in the blockchain. 4.3.12. Tentative execution of get methods of smart contracts. We have already remarked (cf. 2.4.6 ) that any full node can tentatively execute any method of any smart contract (i.e., deliver any message to a smart contract), starting from a given state of the smart contract, without actually committing the corresponding transaction. The full node can simply load the code of the smart contract under consideration into the TON VM, initialize its persistent storage from the global state of the shardchain (known to all full nodes of the shardchain), and execute the smart-contract code with the inbound message as its input parameter. The output messages created will yield the result of this computation. In this way, any full node can evaluate arbitrary get methods of arbitrary smart contracts, provided their signature (i.e., the format of inbound and outbound messages) is known. The node may keep track of the cells of the shardchain state accessed during this evaluation, and create a Merkle proof of the validity of the computation performed, for the benefit of a light node that might have asked the full node to do so (cf. 2.5.11 ). 4.3.14. Public interfaces of a smart contract. Notice that a formalized smart-contract interface, either in form of a TL-scheme (represented as a TL source file; cf. 2.2.5 ) or in serialized form,* can be published\u2014for example, in a special field in the smart-contract account description, stored in the blockchain, or separately, if this interface will be referred to many times. In the latter case a hash of the supported public interface may be incorporated into the smart-contract description instead of the interface description itself. An example of such a public interface is that of a DNS smart contract, which is supposed to implement at least one standard get method for looking up subdomains (cf. 4.3.6 ). A standard method for registering new subdomains can be also included in the standard public interface of DNS smart contracts. *TL-schemes can be TL-serialized themselves; cf. https://core.telegram.org/mtproto/TL-tl 4.3.17. Locating user interfaces via TON DNS. The TON DNS record containing an abstract address of a ton-service or a smart-contract account identifier might also contain an optional field describing the public (user) interface of that entity, or several supported interfaces. Then the client application (be it a wallet, a ton-browser or a ton-proxy) will be able to download the interface and interact with the entity in question (be it a smart contract or a ton-service) in a uniform way. 4.3.19. A light wallet and TON entity explorer can be built into Telegram Messenger clients. An interesting opportunity arises at this point. A light wallet and TON entity explorer, implementing the above functionality, can be embedded into the Telegram Messenger smartphone client application, thus bringing the technology to more than 200 million people. Users would be able to send hyperlinks to TON entities and resources by including TON URIs (cf. 4.3.22 ) in messages; such hyperlinks, if selected, will be opened internally by the Telegram client application of the receiving party, and interaction with the chosen entity will begin. 4.3.22. Hyperlink URLs may specify some parameters. The hyperlink URLs may contain not only a (TON) DNS domain or an abstract address of the service in question, but also the name of the method to be invoked and some or all of its parameters. A possible URI scheme for this might look as follows: \u200b ton:// domain / method ? field1 = value 1 field2 =. . . When the user selects such a link in a ton-browser, either the action is performed immediately (especially if it is a get method of a smart contract,invoked anonymously), or a partially filled form is displayed, to be explicitly confirmed and submitted by the user (this may be required for payment forms). 4.3.23. POST actions. A ton-site may embed into the HTML pages it returns some usual-looking POST forms, with POST actions referring either to ton-sites, ton-services or smart contracts by means of suitable (TON) URLs. In that case, once the user fills and submits that custom form, the corresponding action is taken, either immediately or after an explicit confirmation. 4.3.24. TON WWW. All of the above will lead to the creation of a whole web of cross-referencing entities, residing in the TON Network, which would be accessible to the end user through a ton-browser, providing the user with a WWW-like browsing experience. For end users, this will finally make blockchain applications fundamentally similar to the web sites they are already accustomed to. 4.3.25. Advantages of TON WWW. This \u201cTON WWW\u201d of on-chain and off-chain services has some advantages over its conventional counterpart. For example, payments are inherently integrated in the system. User identity can be always presented to the services (by means of automatically generated signatures on the transactions and RPC requests generated), or hidden at will. Services would not need to check and re-check user credentials; these credentials can be published in the blockchain once and for all. User network anonymity can be easily preserved by means of TON Proxy, and all services will be effectively unblockable. Micropayments are also possible and easy, because ton-browsers can be integrated with the TON Payments system. ON Payments Under construction. First we add chapters we have to refer to from our product docs. The last component of the TON Project we will briefly discuss in this text is TON Payments, the platform for (micro)payment channels and \u201clightning network\u201d value transfers. It would enable \u201cinstant\u201d payments, without the need to commit all transactions into the blockchain, pay the associated transaction fees (e.g., for the gas consumed), and wait five seconds until the block containing the transactions in question is confirmed. The overall overhead of such instant payments is so small that one can use them for micropayments. For example, a TON file-storing service might charge the user for every 128 KiB of downloaded data, or a paid TON Proxy might require some tiny micropayment for every 128 KiB of traffic relayed. While TON Payments is likely to be released later than the core components of the TON Project, some considerations need to be made at the very beginning. For example, the TON Virtual Machine (TON VM; cf. 2.1.20 ), used to execute the code of TON Blockchain smart contracts, must support some special operations with Merkle proofs. If such support is not present in the original design, adding it at a later stage might become problematic (cf. 2.8.16 ). We will see, however, that the TON VM comes with natural support for \u201csmart\u201d payment channels (cf. 5.1.9) out of the box. TON Payments 5.1 Payment Channels We start with a discussion of point-to-point payment channels, and how they can be implemented in the TON Blockchain. 5.1.1. The idea of a payment channel. Suppose two parties, A and B, know that they will need to make a lot of payments to each other in the future. Instead of committing each payment as a transaction in the blockchain, they create a shared \u201cmoney pool\u201d (or perhaps a small private bank with exactly two accounts), and contribute some funds to it: A contributes a coins, and B contributes b coins. This is achieved by creating a special smart contract in the blockchain, and sending the money to it. Before creating the \u201cmoney pool\u201d, the two sides agree to a certain protocol. They will keep track of the state of the pool\u2014that is, of their balances in the shared pool. Originally, the state is (a, b), meaning that a coins actually belong to A, and b coins belong to B. Then, if A wants to pay d coins to B, they can simply agree that the new state is (a', b' ) = (a \u2212 d, b + d). Afterwards, if, say, B wants to pay d 0 coins to A, the state will become (a '', b'') = (a' + d' , b' \u2212 d' ), and so on. All this updating of balances inside the pool is done completely off-chain. When the two parties decide to withdraw their due funds from the pool, they do so according to the final state of the pool. This is achieved by sending a special message to the smart contract, containing the agreed-upon final state (a \u2217 , b\u2217 ) along with the signatures of both A and B. Then the smart contract sends a \u2217 coins to A, b \u2217 coins to B and self-destructs. This smart contract, along with the network protocol used by A and B to update the state of the pool, is a simple payment channel between A and B. According to the classification described in 4.1.2 , it is a mixed service: part of its state resides in the blockchain (the smart contract), but most of its state updates are performed off-chain (by the network protocol). If everything goes well, the two parties will be able to perform as many payments to each other as they want (with the only restriction being that the \u201ccapacity\u201d of the channel is not overrun\u2014i.e., their balances in the payment channel both remain non-negative), committing only two transactions into the blockchain: one to open (create) the payment channel (smart contract), and another to close (destroy) it. 5.1.8. Challenges for the sophisticated payment channel smart contracts. Notice that, while the final state of a sophisticated payment channel is still small, and the \u201cclean\u201d finalization is simple (if the two sides have agreed on their amounts due, and both have signed their agreement, nothing else remains to be done), the unilateral finalization method and the method for punishing fraudulent behavior need to be more complex. Indeed, they must be able to accept Merkle proofs of misbehavior, and to check whether the more sophisticated transactions of the payment channel blockchain have been processed correctly. In other words, the payment channel smart contract must be able to work with Merkle proofs, to check their \u201chash validity\u201d, and must contain an implementation of ev_trans and ev_block functions (cf. 2.2.6) for the payment channel (virtual) blockchain. 5.1.9. TON VM support for \u201csmart\u201d payment channels. The TON VM, used to run the code of TON Blockchain smart contracts, is up to the challenge of executing the smart contracts required for \u201csmart\u201d, or sophisticated, payment channels (cf. 5.1.8 ). At this point the \u201ceverything is a bag of cells\u201d paradigm (cf. 2.5.14) becomes extremely convenient. Since all blocks (including the blocks of the ephemeral payment channel blockchain) are represented as bags of cells (and described by some algebraic data types), and the same holds for messages and Merkle proofs as well, a Merkle proof can easily be embedded into aninbound message sent to the payment channel smart contract. The \u201chash condition\u201d of the Merkle proof will be checked automatically, and when the smart contract accesses the \u201cMerkle proof\u201d presented, it will work with it as if it were a value of the corresponding algebraic data type\u2014albeit incomplete, with some subtrees of the tree replaced by special nodes containing the Merkle hash of the omitted subtree. Then the smart contract will work with that value, which might represent, for instance, a block of the payment channel (virtual) blockchain along with its state, and will evaluate the ev_block function (cf. 2.2.6 ) of that blockchain on this block and the previous state. Then either the computation finishes, and the final state can be compared with that asserted in the block, or an \u201cabsent node\u201d exception is thrown while attempting to access an absent subtree, indicating that the Merkle proof is invalid. In this way, the implementation of the verification code for smart payment channel blockchains turns out to be quite straightforward using TON Blockchain smart contracts. One might say that the TON Virtual Machine comes with built-in support for checking the validity of other simple blockchains . The only limiting factor is the size of the Merkle proof to be incorporated into the inbound message to the smart contract (i.e., into the transaction). Appendix References [1] K. Birman, Reliable Distributed Systems: Technologies, Web Services and Applications, Springer, 2005. [2] V. Buterin, Ethereum: A next-generation smart contract and decentralized application platform, https://github.com/ethereum/wiki/ wiki/White-Paper, 2013. [3] M. Ben-Or, B. Kelmer, T. Rabin, Asynchronous secure computations with optimal resilience, in Proceedings of the thirteenth annual ACM symposium on Principles of distributed computing, p. 183\u2013192. ACM, 1994. [4] M. Castro, B. Liskov, et al., Practical byzantine fault tolerance, Proceedings of the Third Symposium on Operating Systems Design and Implementation (1999), p. 173\u2013186, available at http://pmg.csail.mit. edu/papers/osdi99.pdf. [5] EOS.IO, EOS.IO technical white paper, https://github.com/EOSIO/ Documentation/blob/master/TechnicalWhitePaper.md, 2017. [6] D. Goldschlag, M. Reed, P. Syverson, Onion Routing for Anonymous and Private Internet Connections, Communications of the ACM, 42, num. 2 (1999), http://www.onion-router.net/Publications/ CACM-1999.pdf. [7] L. Lamport, R. Shostak, M. Pease, The byzantine generals problem, ACM Transactions on Programming Languages and Systems, 4/3 (1982), p. 382\u2013401. [8] S. Larimer, The history of BitShares, https://docs.bitshares.org/ bitshares/history.html, 2013. [9] M. Luby, A. Shokrollahi, et al., RaptorQ forward error correction scheme for object delivery, IETF RFC 6330, https://tools.ietf.org/ html/rfc6330, 2011. [10] P. Maymounkov, D. Mazi\u00e8res, Kademlia: A peer-to-peer information system based on the XOR metric, in IPTPS \u201901 revised papers from the First International Workshop on Peer-to-Peer Systems, p. 53\u201365, available at http://pdos.csail.mit.edu/~petar/papers/ maymounkov-kademlia-lncs.pdf, 2002. [11] A. Miller, Yu Xia, et al., The honey badger of BFT protocols, Cryptology e-print archive 2016/99, https://eprint.iacr.org/2016/ 199.pdf, 2016. [12] S. Nakamoto, Bitcoin: A peer-to-peer electronic cash system, https: //bitcoin.org/bitcoin.pdf, 2008. [13] S. Peyton Jones, Implementing lazy functional languages on stock hardware: the Spineless Tagless G-machine, Journal of Functional Programming 2 (2), p. 127\u2013202, 1992. [14] A. Shokrollahi, M. Luby, Raptor Codes, IEEE Transactions on Information Theory 6, no. 3\u20134 (2006), p. 212\u2013322. [15] M. van Steen, A. Tanenbaum, Distributed Systems, 3rd ed., 2017. [16] The Univalent Foundations Program, Homotopy Type Theory: Univalent Foundations of Mathematics, Institute for Advanced Study, 2013, available at https://homotopytypetheory.org/book. [17] G. Wood, PolkaDot: vision for a heterogeneous multi-chain framework, draft 1, https://github.com/w3f/polkadot-white-paper/raw/ master/PolkaDotPaper.pdf, 2016.","title":"TON Whitepaper"},{"location":"TON Blockchain/TON Whitepaper/#ton-whitepaper","text":"","title":"TON Whitepaper"},{"location":"TON Blockchain/TON Whitepaper/#a-brief-description-of-ton-components","text":"The Telegram Open Network (TON) is a combination of the following components: A flexible multi-blockchain platform (TON Blockchain; cf. Chapter 2 ), capable of processing millions of transactions per second, with Turingcomplete smart contracts, upgradable formal blockchain specifications, multi-cryptocurrency value transfer, support for micropayment channels and off-chain payment networks. TON Blockchain presents some new and unique features, such as the \u201cself-healing\u201d vertical blockchain mechanism (cf. 2.1.17 ) and Instant Hypercube Routing (cf. 2.4.20 ), which enable it to be fast, reliable, scalable and self-consistent at the same time. A peer-to-peer network (TON P2P Network, or just TON Network; cf. Chapter 3 ), used for accessing the TON Blockchain, sending transaction candidates, and receiving updates about only those parts of the blockchain a client is interested in (e.g., those related to the client\u2019s accounts and smart contracts), but also able to support arbitrary distributed services, blockchain-related or not. A distributed file storage technology (TON Storage; cf. 4.1.8 ), accessible through TON Network, used by the TON Blockchain to store archive copies of blocks and status data (snapshots), but also available for storing arbitrary files for users or other services running on the platform, with torrent-like access technology. A network proxy/anonymizer layer (TON Proxy; cf. 4.1.11 and 3.1.6 ), similar to the I 2P (Invisible Internet Project), used to hide the identity and IP addresses of TON Network nodes if necessary (e.g., nodes committing transactions from accounts with large amounts of cryptocurrency, or high-stake blockchain validator nodes who wish to hide their exact IP address and geographical location as a measure against DDoS attacks). A Kademlia-like distributed hash table (TON DHT; cf. 3.2 ), used as a \u201ctorrent tracker\u201d for TON Storage (cf. 3.2.10 ), as an \u201cinput tunnel locator\u201d for TON Proxy (cf. 3.2.14 ), and as a service locator for TON Services (cf. 3.2.12 ). A platform for arbitrary services (TON Services; cf. Chapter 4 ), residing in and available through TON Network and TON Proxy, with formalized interfaces (cf. 4.3.14 ) enabling browser-like or smartphone application interaction. These formal interfaces and persistent service entry points can be published in the TON Blockchain (cf. 4.3.17 ); actual nodes providing service at any given moment can be looked up through the TON DHT starting from information published in the TON Blockchain (cf. 3.2.12 ). Services may create smart contracts in the TON Blockchain to offer some guarantees to their clients (cf. 4.1.7 ). TON DNS (cf. 4.3.1 ), a service for assigning human-readable names to accounts, smart contracts, services and network nodes. TON Payments (cf. Chapter 5 ), a platform for micropayments, micropayment channels and a micropayment channel network. It can be used for fast off-chain value transfers, and for paying for services powered by TON Services. TON will allow easy integration with third-party messaging and social networking applications, thus making blockchain technologies and distributed services finally available and accessible to ordinary users (cf. 4.3.24 ), rather than just to a handful of early cryptocurrency adopters. We will provide an example of such an integration in another of our projects, the Telegram Messenger (cf. 4.3.19 ). While the TON Blockchain is the core of the TON project, and the other components might be considered as playing a supportive role for the blockchain, they turn out to have useful and interesting functionality by themselves. Combined, they allow the platform to host more versatile applications than it would be possible by just using the TON Blockchain (cf. 2.9.13 and 4.1 ).","title":"A Brief Description of TON Components"},{"location":"TON Blockchain/TON Whitepaper/#introduction","text":"The aim of this text is to provide a first description of the Telegram Open Network (TON) and related blockchain, peer-to-peer, distributed storage and service hosting technologies. To reduce the size of this document to reasonable proportions, we focus mainly on the unique and defining features of the TON platform that are important for it to achieve its stated goals. The Telegram Open Network (TON) is a fast, secure and scalable blockchain and network project, capable of handling millions of transactions per second if necessary, and both user-friendly and service provider-friendly. We aim for it to be able to host all reasonable applications currently proposed and conceived. One might think about TON as a huge distributed supercomputer, or rather a huge \u201csuperserver\u201d, intended to host and provide a variety of services. This text is not intended to be the ultimate reference with respect to all implementation details. Some particulars are likely to change during the development and testing phases.","title":"Introduction"},{"location":"TON Blockchain/TON Whitepaper/#ton-blockchain","text":"","title":"TON Blockchain"},{"location":"TON Blockchain/TON Whitepaper/#21-ton-blockchain-as-a-collection-of-2-blockchains","text":"The TON Blockchain is actually a collection of blockchains (even a collection of blockchains of blockchains, or 2-blockchains\u2014this point will be clarified later in 2.1.17 ), because no single blockchain project is capable of achieving our goal of processing millions of transactions per second, as opposed to the now-standard dozens of transactions per second.","title":"2.1 TON Blockchain as a Collection of 2-Blockchains"},{"location":"TON Blockchain/TON Whitepaper/#211-list-of-blockchain-types","text":"The blockchains in this collection are: The unique master blockchain, or masterchain for short, containing general information about the protocol and the current values of its parameters, the set of validators and their stakes, the set of currently active workchains and their \u201cshards\u201d, and, most importantly, the set of hashes of the most recent blocks of all workchains and shardchains. Several (up to 2^32) working blockchains, or workchains for short, which are actually the \u201cworkhorses\u201d, containing the value-transfer and smartcontract transactions. Different workchains may have different \u201crules\u201d, meaning different formats of account addresses, different formats of transactions, different virtual machines (VMs) for smart contracts, different basic cryptocurrencies and so on. However, they all must satisfy certain basic interoperability criteria to make interaction between different workchains possible and relatively simple. In this respect, the TON Blockchain is heterogeneous (cf. 2.8.8 ), similarly to the EOS (cf. 2.9.7 ) and PolkaDot (cf. 2.9.8 ) projects. Each workchain is in turn subdivided into up to 2^60 shard blockchains, or shardchains for short, having the same rules and block format as the workchain itself, but responsible only for a subset of accounts, depending on several first (most significant) bits of the account address. In other words, a form of sharding is built into the system (cf. 2.8.12 ). Because all these shardchains share a common block format and rules, the TON Blockchain is homogeneous in this respect (cf. 2.8.8 ), similarly to what has been discussed in one of Ethereum scaling proposals.* * https://github.com/ethereum/wiki/wiki/Sharding-FAQ Each block in a shardchain (and in the masterchain) is actually not just a block, but a small blockchain. Normally, this \u201cblock blockchain\u201d or \u201cvertical blockchain\u201d consists of exactly one block, and then we might think this is just the corresponding block of the shardchain (also called \u201chorizontal blockchain\u201d in this situation). However, if it becomes necessary to fix incorrect shardchain blocks, a new block is committed into the \u201cvertical blockchain\u201d, containing either the replacement for the invalid \u201chorizontal blockchain\u201d block, or a \u201cblock difference\u201d, containing only a description of those parts of the previous version of this block that need to be changed. This is a TON-specific mechanism to replace detected invalid blocks without making a true fork of all shardchains involved; it will be explained in more detail in 2.1.17 . For now, we just remark that each shardchain (and the masterchain) is not a conventional blockchain, but a blockchain of blockchains, or 2D-blockchain, or just a 2-blockchain.","title":"2.1.1. List of blockchain types."},{"location":"TON Blockchain/TON Whitepaper/#212-infinite-sharding-paradigm","text":"Almost all blockchain sharding proposals are \u201ctop-down\u201d: one first imagines a single blockchain, and then discusses how to split it into several interacting shardchains to improve performance and achieve scalability. The TON approach to sharding is \u201cbottom-up\u201d, explained as follows. Imagine that sharding has been taken to its extreme, so that exactly one account or smart contract remains in each shardchain. Then we have a huge number of \u201caccount-chains\u201d, each describing the state and state transitions of only one account, and sending value-bearing messages to each other to transfer value and information. Of course, it is impractical to have hundreds of millions of blockchains, with updates (i.e., new blocks) usually appearing quite rarely in each of them. In order to implement them more efficiently, we group these \u201caccount-chains\u201d into \u201cshardchains\u201d, so that each block of the shardchain is essentially a collection of blocks of account-chains that have been assigned to this shard. Thus the \u201caccount-chains\u201d have only a purely virtual or logical existence inside the \u201cshardchains\u201d. We call this perspective the Infinite Sharding Paradigm . It explains many of the design decisions for the TON Blockchain.","title":"2.1.2. Infinite Sharding Paradigm."},{"location":"TON Blockchain/TON Whitepaper/#213-messages-instant-hypercube-routing","text":"The Infinite Sharding Paradigm instructs us to regard each account (or smart contract) as if it were in its own shardchain by itself. Then the only way one account might affect the state of another is by sending a message to it (this is a special instance of the so-called Actor model, with accounts as Actors; cf. 2.4.2 ). Therefore, a system of messages between accounts (and shardchains, because the source and destination accounts are, generally speaking, located in different shardchains) is of paramount importance to a scalable system such as the TON Blockchain. In fact, a novel feature of the TON Blockchain, called Instant Hypercube Routing (cf. 2.4.20 ), enables it to deliver and process a message created in a block of one shardchain into the very next block of the destination shardchain, regardless of the total number of shardchains in the system.","title":"2.1.3. Messages. Instant Hypercube Routing."},{"location":"TON Blockchain/TON Whitepaper/#214-quantity-of-masterchains-workchains-and-shardchains","text":"A TON Blockchain contains exactly one masterchain. However, the system can potentially accommodate up to 2^32 workchains, each subdivided into up to 2^60 shardchains.","title":"2.1.4. Quantity of masterchains, workchains and shardchains."},{"location":"TON Blockchain/TON Whitepaper/#215-workchains-can-be-virtual-blockchains-not-true-blockchains","text":"Because a workchain is usually subdivided into shardchains, the existence of the workchain is \u201cvirtual\u201d, meaning that it is not a true blockchain in the sense of the general definition provided in 2.2.1 below, but just a collection of shardchains. When only one shardchain corresponds to a workchain, this unique shardchain may be identified with the workchain, which in this case becomes a \u201ctrue\u201d blockchain, at least for some time, thus gaining a superficial similarity to customary single-blockchain design. However, the Infinite Sharding Paradigm (cf. 2.1.2 ) tells us that this similarity is indeed superficial: it is just a coincidence that the potentially huge number of \u201caccountchains\u201d can temporarily be grouped into one blockchain.","title":"2.1.5. Workchains can be virtual blockchains, not true blockchains."},{"location":"TON Blockchain/TON Whitepaper/#216-identification-of-workchains","text":"Each workchain is identified by its number or workchain identifier (workchain_id : uint32) , which is simply an unsigned 32-bit integer. Workchains are created by special transactions in the masterchain, defining the (previously unused) workchain identifier and the formal description of the workchain, sufficient at least for the interaction of this workchain with other workchains and for superficial verification of this workchain\u2019s blocks.","title":"2.1.6. Identification of workchains."},{"location":"TON Blockchain/TON Whitepaper/#217-creation-and-activation-of-new-workchains","text":"The creation of a new workchain may be initiated by essentially any member of the community, ready to pay the (high) masterchain transaction fees required to publish the formal specification of a new workchain. However, in order for the new workchain to become active, a two-thirds consensus of validators is required, because they will need to upgrade their software to process blocks of the new workchain, and signal their readiness to work with the new workchain by special masterchain transactions. The party interested in the activation of the new workchain might provide some incentive for the validators to support the new workchain by means of some rewards distributed by a smart contract.","title":"2.1.7. Creation and activation of new workchains."},{"location":"TON Blockchain/TON Whitepaper/#218-identification-of-shardchains","text":"Each shardchain is identified by a couple (w, s) = (workchain_id,shard_prefix) , where workchain_id : uint32 identifies the corresponding workchain, and shard_prefix : 2^0...60 is a bit string of length at most 60, defining the subset of accounts for which this shardchain is responsible. Namely, all accounts with account_id starting with shard_prefix (i.e., having shard_prefix as most significant bits) will be assigned to this shardchain.","title":"2.1.8. Identification of shardchains."},{"location":"TON Blockchain/TON Whitepaper/#219-identification-of-account-chains","text":"Recall that account-chains have only a virtual existence (cf. 2.1.2 ). However, they have a natural identifier\u2014 namely, (workchain_id, account_id)\u2014because any account-chain contains information about the state and updates of exactly one account (either a simple account or smart contract\u2014the distinction is unimportant here).","title":"2.1.9. Identification of account-chains."},{"location":"TON Blockchain/TON Whitepaper/#2110-dynamic-splitting-and-merging-of-shardchains-cf-27","text":"A less sophisticated system might use static sharding\u2014for example, by using the top eight bits of the account_id to select one of 256 pre-defined shards. An important feature of the TON Blockchain is that it implements dynamic sharding, meaning that the number of shards is not fixed. Instead, shard (w, s) can be automatically subdivided into shards (w, s.0) and (w, s.1) if some formal conditions are met (essentially, if the transaction load on the original shard is high enough for a prolonged period of time). Conversely, if the load stays too low for some period of time, the shards (w, s.0) and (w, s.1) can be automatically merged back into shard (w, s). Initially, only one shard (w, \u2205) is created for workchain *w* . Later, it is subdivided into more shards, if and when this becomes necessary (cf. 2.7.6 and 2.7.8 ).","title":"2.1.10. Dynamic splitting and merging of shardchains; cf. 2.7."},{"location":"TON Blockchain/TON Whitepaper/#2111-basic-workchain-or-workchain-zero","text":"While up to 2^32 workchains can be defined with their specific rules and transactions, we initially define only one, with workchain_id = 0 . This workchain, called Workchain Zero or the basic workchain, is the one used to work with TON smart contracts and transfer TON coins, also known as Grams (cf. Appendix A ). Most applications are likely to require only Workchain Zero. Shardchains of the basic workchain will be called basic shardchains.","title":"2.1.11. Basic workchain or Workchain Zero."},{"location":"TON Blockchain/TON Whitepaper/#2112-block-generation-intervals","text":"We expect a new block to be generated in each shardchain and the masterchain approximately once every five seconds. This will lead to reasonably small transaction confirmation times. New blocks of all shardchains are generated approximately simultaneously; a new block of the masterchain is generated approximately one second later, because it must contain the hashes of the latest blocks of all shardchains.","title":"2.1.12. Block generation intervals."},{"location":"TON Blockchain/TON Whitepaper/#2113-using-the-masterchain-to-make-workchains-and-shardchains-tightly-coupled","text":"Once the hash of a block of a shardchain is incorporated into a block of the masterchain, that shardchain block and all its ancestors are considered \u201ccanonical\u201d, meaning that they can be referenced from the subsequent blocks of all shardchains as something fixed and immutable. In fact, each new shardchain block contains a hash of the most recent masterchain block, and all shardchain blocks referenced from that masterchain block are considered immutable by the new block. Essentially, this means that a transaction or a message committed in a shardchain block may be safely used in the very next blocks of the other shardchains, without needing to wait for, say, twenty confirmations (i.e., twenty blocks generated after the original block in the same blockchain) before forwarding a message or taking other actions based on a previous transaction, as is common in most proposed \u201cloosely-coupled\u201d systems (cf. 2.8.14 ), such as EOS. This ability to use transactions and messages in other shardchains a mere five seconds after being committed is one of the reasons we believe our \u201ctightly-coupled\u201d system, the first of its kind, will be able to deliver unprecedented performance (cf. 2.8.12 and 2.8.14 ).","title":"2.1.13. Using the masterchain to make workchains and shardchains tightly coupled."},{"location":"TON Blockchain/TON Whitepaper/#2114-masterchain-block-hash-as-a-global-state","text":"According to 2.1.13 , the hash of the last masterchain block completely determines the overall state of the system from the perspective of an external observer. One does not need to monitor the state of all shardchains separately.","title":"2.1.14. Masterchain block hash as a global state."},{"location":"TON Blockchain/TON Whitepaper/#2115-generation-of-new-blocks-by-validators-cf-26","text":"The TON Blockchain uses a Proof-of-Stake (PoS) approach for generating new blocks in the shardchains and the masterchain. This means that there is a set of, say, up to a few hundred validators\u2014special nodes that have deposited stakes (large amounts of TON coins) by a special masterchain transaction to be eligible for new block generation and validation. Then a smaller subset of validators is assigned to each shard (w, s) in a deterministic pseudorandom way, changing approximately every 1024 blocks. This subset of validators suggests and reaches consensus on what the next shardchain block would be, by collecting suitable proposed transactions from the clients into new valid block candidates. For each block, there is a pseudorandomly chosen order on the validators to determine whose block candidate has the highest priority to be committed at each turn. Validators and other nodes check the validity of the proposed block candidates; if a validator signs an invalid block candidate, it may be automatically punished by losing part or all of its stake, or by being suspended from the set of validators for some time. After that, the validators should reach consensus on the choice of the next block, essentially by an efficient variant of the BFT (Byzantine Fault Tolerant; cf. 2.8.4 ) consensus protocol, similar to PBFT [ 4 ] or Honey Badger BFT [ 11 ]. If consensus is reached, a new block is created, and validators divide between themselves the transaction fees for the transactions included, plus some newly-created (\u201cminted\u201d) coins. Each validator can be elected to participate in several validator subsets; in this case, it is expected to run all validation and consensus algorithms in parallel. After all new shardchain blocks are generated or a timeout is passed, a new masterchain block is generated, including the hashes of the latest blocks of all shardchains. This is done by BFT consensus of all validators.* More detail on the TON PoS approach and its economical model is provided in section 2.6 . *Actually, two-thirds by stake is enough to achieve consensus, but an effort is made to collect as many signatures as possible.","title":"2.1.15. Generation of new blocks by validators; cf. 2.6."},{"location":"TON Blockchain/TON Whitepaper/#2116-forks-of-the-masterchain","text":"A complication that arises from our tightly-coupled approach is that switching to a different fork in the masterchain will almost necessarily require switching to another fork in at least some of the shardchains. On the other hand, as long as there are no forks in the masterchain, no forks in the shardchain are even possible, because no blocks in the alternative forks of the shardchains can become \u201ccanonical\u201d by having their hashes incorporated into a masterchain block. The general rule is that if masterchain block B' is a predecessor of B, B' includes hash Hash(B' w,s) of (w, s)-shardchain block B' w,s, and B includes hash Hash(Bw,s), then B'w,s must be a predecessor of Bw,s; otherwise, the masterchain block B is invalid. We expect masterchain forks to be rare, next to non-existent, because in the BFT paradigm adopted by the TON Blockchain they can happen only in the case of incorrect behavior by a majority of validators (cf. 2.6.1 and 2.6.15 ), which would imply significant stake losses by the offenders. Therefore, no true forks in the shardchains should be expected. Instead, if an invalid shardchain block is detected, it will be corrected by means of the \u201cvertical blockchain\u201d mechanism of the 2-blockchain (cf. 2.1.17 ), which can achieve this goal without forking the \u201chorizontal blockchain\u201d (i.e., the shardchain). The same mechanism can be used to fix non-fatal mistakes in the masterchain blocks as well.","title":"2.1.16. Forks of the masterchain."},{"location":"TON Blockchain/TON Whitepaper/#2117-correcting-invalid-shardchain-blocks","text":"Normally, only valid shardchain blocks will be committed, because validators assigned to the shardchain must reach a two-thirds Byzantine consensus before a new block can be committed. However, the system must allow for detection of previously committed invalid blocks and their correction. Of course, once an invalid shardchain block is found\u2014either by a validator (not necessarily assigned to this shardchain) or by a \u201cfisherman\u201d (any node of the system that made a certain deposit to be able to raise questions about block validity; cf. 2.6.4 )\u2014the invalidity claim and its proof are committed into the masterchain, and the validators that have signed the invalid block are punished by losing part of their stake and/or being temporarily suspended from the set of validators (the latter measure is important for the case of an attacker stealing the private signing keys of an otherwise benign validator). However, this is not sufficient, because the overall state of the system (TON Blockchain) turns out to be invalid because of the invalid shardchain block previously committed. This invalid block must be replaced by a newer valid version. Most systems would achieve this by \u201crolling back\u201d to the last block before the invalid one in this shardchain and the last blocks unaffected by messages propagated from the invalid block in each of the other shardchains, and creating a new fork from these blocks. This approach has the disadvantage that a large number of otherwise correct and committed transactions are suddenly rolled back, and it is unclear whether they will be included later at all. The TON Blockchain solves this problem by making each \u201cblock\u201d of each shardchain and of the masterchain (\u201chorizontal blockchains\u201d) a small blockchain (\u201cvertical blockchain\u201d) by itself, containing different versions of this \u201cblock\u201d, or their \u201cdifferences\u201d. Normally, the vertical blockchain consists of exactly one block, and the shardchain looks like a classical blockchain. However, once the invalidity of a block is confirmed and committed into a masterchain block, the \u201cvertical blockchain\u201d of the invalid block is allowed to grow by a new block in the vertical direction, replacing or editing the invalid block. The new block is generated by the current validator subset for the shardchain in question. The rules for a new \u201cvertical\u201d block to be valid are quite strict. In particular, if a virtual \u201caccount-chain block\u201d (cf. 2.1.2 ) contained in the invalid block is valid by itself, it must be left unchanged by the new vertical block. Once a new \u201cvertical\u201d block is committed on top of the invalid block, its hash is published in a new masterchain block (or rather in a new \u201cvertical\u201d block, lying above the original masterchain block where the hash of the invalid shardchain block was originally published), and the changes are propagated further to any shardchain blocks referring to the previous version of this block (e.g., those having received messages from the incorrect block). This is fixed by committing new \u201cvertical\u201d blocks in vertical blockchains for all blocks previously referring to the \u201cincorrect\u201d block; new vertical blocks will refer to the most recent (corrected) versions instead. Again, strict rules forbid changing account-chains that are not really affected (i.e., that receive the same messages as in the previous version). In this way, fixing an incorrect block generates \u201cripples\u201d that are ultimately propagated towards the most recent blocks of all affected shardchains; these changes are reflected in new \u201cvertical\u201d masterchain blocks as well. Once the \u201chistory rewriting\u201d ripples reach the most recent blocks, the new shardchain blocks are generated in one version only, being successors of the newest block versions only. This means that they will contain references to the correct (most recent) vertical blocks from the very beginning. The masterchain state implicitly defines a map transforming the hash of the first block of each \u201cvertical\u201d blockchain into the hash of its latest version. This enables a client to identify and locate any vertical blockchain by the hash of its very first (and usually the only) block.","title":"2.1.17. Correcting invalid shardchain blocks."},{"location":"TON Blockchain/TON Whitepaper/#2118-ton-coins-and-multi-currency-workchains","text":"The TON Blockchain supports up to 2^32 different \u201ccryptocurrencies\u201d, \u201ccoins\u201d, or \u201ctokens\u201d, distinguished by a 32-bit currency_id . New cryptocurrencies can be added by special transactions in the masterchain. Each workchain has a basic cryptocurrency, and can have several additional cryptocurrencies. There is one special cryptocurrency with currency_id = 0 , namely, the TON coin, also known as the Gram (cf. Appendix A). It is the basic cryptocurrency of Workchain Zero. It is also used for transaction fees and validator stakes. In principle, other workchains may collect transaction fees in other tokens. In this case, some smart contract for automated conversion of these transaction fees into Grams should be provided.","title":"2.1.18. TON coins and multi-currency workchains."},{"location":"TON Blockchain/TON Whitepaper/#2119-messaging-and-value-transfer","text":"Shardchains belonging to the same or different workchains may send messages to each other. While the exact form of the messages allowed depends on the receiving workchain and receiving account (smart contract), there are some common fields making inter-workchain messaging possible. In particular, each message may have some value attached, in the form of a certain amount of Grams (TON coins) and/or other registered cryptocurrencies, provided they are declared as acceptable cryptocurrencies by the receiving workchain. The simplest form of such messaging is a value transfer from one (usually not a smart-contract) account to another.","title":"2.1.19. Messaging and value transfer."},{"location":"TON Blockchain/TON Whitepaper/#2120-ton-virtual-machine","text":"The TON Virtual Machine, also abbreviated as TON VM or TVM , is the virtual machine used to execute smart-contract code in the masterchain and in the basic workchain. Other workchains may use other virtual machines alongside or instead of the TVM. Here we list some of its features. They are discussed further in 2.3.12 , 2.3.14 and elsewhere. TVM represents all data as a collection of (TVM) cells (cf. 2.3.14 ). Each cell contains up to 128 data bytes and up to 4 references to other cells. As a consequence of the \u201ceverything is a bag of cells\u201d philosophy (cf. 2.5.14 ), this enables TVM to work with all data related to the TON Blockchain, including blocks and blockchain global state if necessary. TVM can work with values of arbitrary algebraic data types (cf. 2.3.12 ), represented as trees or directed acyclic graphs of TVM cells. However, it is agnostic towards the existence of algebraic data types; it just works with cells. TVM has built-in support for hashmaps (cf. 2.3.7 ). TVM is a stack machine. Its stack keeps either 64-bit integers or cell references. 64-bit, 128-bit and 256-bit arithmetic is supported. All n-bit arithmetic operations come in three flavors: for unsigned integers, for signed integers and for integers modulo 2^n (no automatic overflow checks in the latter case). TVM has unsigned and signed integer conversion from n-bit to m-bit, for all 0 \u2264 m, n \u2264 256, with overflow checks. All arithmetic operations perform overflow checks by default, greatly simplifying the development of smart contracts. TVM has \u201cmultiply-then-shift\u201d and \u201cshift-then-divide\u201d arithmetic operations with intermediate values computed in a larger integer type; this simplifies implementing fixed-point arithmetic. TVM offers support for bit strings and byte strings. Support for 256-bit Elliptic Curve Cryptography (ECC) for some predefined curves, including Curve25519, is present. Support for Weil pairings on some elliptic curves, useful for fast implementation of zk-SNARKs, is also present. Support for popular hash functions, including sha256, is present. TVM can work with Merkle proofs (cf. 5.1.9 ). TVM offers support for \u201clarge\u201d or \u201cglobal\u201d smart contracts. Such smart contracts must be aware of sharding (cf. 2.3.18 and 2.3.16 ). Usual (local) smart contracts can be sharding-agnostic. TVM supports closures. A \u201cspineless tagless G-machine\u201d [ 13 ] can be easily implemented inside TVM. Several high-level languages can be designed for TVM, in addition to the \u201cTVM assembly\u201d. All these languages will have static types and will support algebraic data types. We envision the following possibilities: A Java-like imperative language, with each smart contract resembling a separate class. A lazy functional language (think of Haskell). An eager functional language (think of ML).","title":"2.1.20. TON Virtual Machine."},{"location":"TON Blockchain/TON Whitepaper/#2121-configurable-parameters","text":"An important feature of the TON Blockchain is that many of its parameters are configurable. This means that they are part of the masterchain state, and can be changed by certain special proposal/vote/result transactions in the masterchain, without any need for hard forks. Changing such parameters will require collecting two-thirds of validator votes and more than half of the votes of all other participants who would care to take part in the voting process in favor of the proposal.","title":"2.1.21. Configurable parameters."},{"location":"TON Blockchain/TON Whitepaper/#22-generalities-on-blockchains","text":"","title":"2.2 Generalities on Blockchains"},{"location":"TON Blockchain/TON Whitepaper/#221-general-blockchain-definition","text":"In general, any (true) blockchain is a sequence of blocks , each block B containing a reference blk-prev(B) to the previous block (usually by including the hash of the previous block into the header of the current block), and a list of transactions. Each transaction describes some transformation of the global blockchain state ; the transactions listed in a block are applied sequentially to compute the new state starting from the old state, which is the resulting state after the evaluation of the previous block.","title":"2.2.1. General blockchain definition."},{"location":"TON Blockchain/TON Whitepaper/#222-relevance-for-the-ton-blockchain","text":"Recall that the TON Blockchain is not a true blockchain, but a collection of 2-blockchains (i.e., of blockchains of blockchains; cf. 2.1.1 ), so the above is not directly applicable to it. However, we start with these generalities on true blockchains to use them as building blocks for our more sophisticated constructions.","title":"2.2.2. Relevance for the TON Blockchain."},{"location":"TON Blockchain/TON Whitepaper/#223-blockchain-instance-and-blockchain-type","text":"One often uses the word blockchain to denote both a general blockchain type and its specific blockchain instances, defined as sequences of blocks satisfying certain conditions. For example, 2.2.1 refers to blockchain instances. In this way, a blockchain type is usually a \u201csubtype\u201d of the type Block\u2217 of lists (i.e., finite sequences) of blocks, consisting of those sequences of blocks that satisfy certain compatibility and validity conditions: \u200b Blockchain \u2282 Block* (1) A better way to define Blockchain would be to say that Blockchain is a dependent couple type , consisting of couples (B, v), with first component B : Block\u2217 being of type Block\u2217 (i.e., a list of blocks), and the second component v : isValidBc(B) being a proof or a witness of the validity of B. In this way, \u200b Blockchain \u2261 \u03a3*(B:Block\u2217 )* isValidBc(B) (2) We use here the notation for dependent sums of types borrowed from [ 16 ].","title":"2.2.3. Blockchain instance and blockchain type."},{"location":"TON Blockchain/TON Whitepaper/#224-dependent-type-theory-coq-and-tl","text":"Note that we are using (Martin-L\u00f6f) dependent type theory here, similar to that used in the Coq proof assistant. A simplified version of dependent type theory is also used in TL (Type Language) , * which will be used in the formal specification of the TON Blockchain to describe the serialization of all data structures and the layouts of blocks, transactions, and the like. In fact, dependent type theory gives a useful formalization of what a proof is, and such formal proofs (or their serializations) might become handy when one needs to provide proof of invalidity for some block, for example. * https://coq.inria.fr ** https://core.telegram.org/mtproto/TL","title":"2.2.4. Dependent type theory, Coq and TL."},{"location":"TON Blockchain/TON Whitepaper/#225-tl-or-the-type-language","text":"Since TL (Type Language) will be used in the formal specifications of TON blocks, transactions, and network datagrams, it warrants a brief discussion. TL is a language suitable for description of dependent algebraic types,which are allowed to have numeric (natural) and type parameters. Each type is described by means of several constructors. Each constructor has a (human-readable) identifier and a name, which is a bit string (32-bit integer by default). Apart from that, the definition of a constructor contains a list of fields along with their types. A collection of constructor and type definitions is called a TL-scheme. It is usually kept in one or several files with the suffix .tl. An important feature of TL-schemes is that they determine an unambiguous way of serializing and deserializing values (or objects) of algebraic types defined. Namely, when a value needs to be serialized into a stream of bytes, first the name of the constructor used for this value is serialized. Recursively computed serializations of each field follow. The description of a previous version of TL, suitable for serializing arbitrary objects into sequences of 32-bit integers, is available at https://core.telegram.org/mtproto/ TL. A new version of TL, called TL-B, is being developed for the purpose of describing the serialization of objects used by the TON Project. This new version can serialize objects into streams of bytes and even bits (not just 32-bit integers), and offers support for serialization into a tree of TVM cells (cf. 2.3.14 ). A description of TL-B will be a part of the formal specification of the TON Blockchain.","title":"2.2.5. TL, or the Type Language."},{"location":"TON Blockchain/TON Whitepaper/#226-blocks-and-transactions-as-state-transformation-operators","text":"Normally, any blockchain (type) Blockchain has an associated global state (type) State, and a transaction (type) Transaction. The semantics of a blockchain are to a large extent determined by the transaction application function: \u200b ev_trans0 : Transaction \u00d7 State \u2192 State^? (3) Here X^? denotes Maybe X, the result of applying the Maybe monad to type X. This is similar to our use of X^\u2217 for List X . Essentially, a value of type X^? is either a value of type X or a special value \u22a5 indicating the absence of an actual value (think about a null pointer). In our case, we use State^? instead of State as the result type because a transaction may be invalid if invoked from certain original states (think about attempting to withdraw from an account more money than it is actually there). We might prefer a curried version of ev_trans' : \u200b ev_trans : Transaction \u2192 State \u2192 State^? (4) Because a block is essentially a list of transactions, the block evaluation function \u200b ev_block : Block \u2192 State \u2192 State? (5) can be derived from ev_trans. It takes a block *B : Block* and the previous blockchain state *s : State* (which might include the hash of the previous block) and computes the next blockchain state s' = ev_block(B)(s) : State , which is either a true state or a special value \u22a5 indicating that the next state cannot be computed (i.e., that the block is invalid if evaluated from the starting state given\u2014for example, the block includes a transaction trying to debit an empty account.)","title":"2.2.6. Blocks and transactions as state transformation operators."},{"location":"TON Blockchain/TON Whitepaper/#227-block-sequence-numbers","text":"Each block B in the blockchain can be referred to by its sequence number blk-seqno(B) , starting from zero for the very first block, and incremented by one whenever passing to the next block. More formally, \u200b blk-seqno(B) = blk-seqno (blk-prev(B)) + 1 (6) Notice that the sequence number does not identify a block uniquely in the presence of forks.","title":"2.2.7. Block sequence numbers."},{"location":"TON Blockchain/TON Whitepaper/#228-block-hashes","text":"Another way of referring to a block B is by its hash *blk-hash(B)* , which is actually the hash of the header of block B (however, the header of the block usually contains hashes that depend on all content of block B ). Assuming that there are no collisions for the hash function used (or at least that they are very improbable), a block is uniquely identified by its hash.","title":"2.2.8. Block hashes."},{"location":"TON Blockchain/TON Whitepaper/#229-hash-assumption","text":"During formal analysis of blockchain algorithms, we assume that there are no collisions for the k-bit hash function Hash : Bytes* \u2192 2^k used: \u200b Hash(s) = Hash(s') \u21d2 s = s' for any s, s' \u2208 Bytes* (7) Here Bytes = {0 . . . 255} = 2 ^8 is the type of bytes, or the set of all byte values, and Bytes\u2217 is the type or set of arbitrary (finite) lists of bytes; while 2 = {0, 1} is the bit type, and 2^ k is the set (or actually the type) of all k-bit sequences (i.e., of k-bit numbers). Of course, (7) is impossible mathematically, because a map from an infinite set to a finite set cannot be injective. A more rigorous assumption would be \u200b \u2200s, s' : s =/= s' , P (Hash(s) = Hash(s')) = 2^\u2212k (8) However, this is not so convenient for the proofs. If (8) is used at most N times in a proof with 2 ^\u2212k*N \u2208 for some small \u2208 (say, \u2208 = 10^\u221218), we can reason as if (7) were true, provided we accept a failure probability \u2208 (i.e., the final conclusions will be true with probability at least 1 \u2212 \u2208). Final remark: in order to make the probability statement of (8) really rigorous, one must introduce a probability distribution on the set Bytes * of all byte sequences. A way of doing this is by assuming all byte sequences of the same length l equiprobable, and setting the probability of observing a sequence of length l equal to p^l \u2212 p^l+1 for some p \u2192 1\u2212. Then (8) should be understood as a limit of conditional probability P (Hash(s) = Hash(s')|s =/= s') when p tends to one from below.","title":"2.2.9. Hash assumption."},{"location":"TON Blockchain/TON Whitepaper/#2210-hash-used-for-the-ton-blockchain","text":"We are using the 256-bit sha256 hash for the TON Blockchain for the time being. If it turns out to be weaker than expected, it can be replaced by another hash function in the future. The choice of the hash function is a configurable parameter of the protocol, so it can be changed without hard forks as explained in 2.1.21","title":"2.2.10. Hash used for the TON Blockchain."},{"location":"TON Blockchain/TON Whitepaper/#23-blockchain-state-accounts-and-hashmaps","text":"We have noted above that any blockchain defines a certain global state, and each block and each transaction defines a transformation of this global state. Here we describe the global state used by TON blockchain","title":"2.3 Blockchain State, Accounts and Hashmaps"},{"location":"TON Blockchain/TON Whitepaper/#231-account-ids","text":"The basic account IDs used by TON blockchains\u2014 or at least by its masterchain and Workchain Zero\u2014are 256-bit integers, assumed to be public keys for 256-bit Elliptic Curve Cryptography (ECC) for a specific elliptic curve. In this way, \u200b account_id : Account = uint256 = 2^256 (9) Here Account is the account type, while account_id : Account is a specific variable of type Account . Other workchains can use other account ID formats, 256-bit or otherwise. For example, one can use Bitcoin-style account IDs, equal to sha256 of an ECC public key. However, the bit length l of an account ID must be fixed during the creation of the workchain (in the masterchain), and it must be at least 64, because the first 64 bits of account_id are used for sharding and message routing.","title":"2.3.1. Account IDs."},{"location":"TON Blockchain/TON Whitepaper/#232-main-component-hashmaps","text":"The principal component of the TON blockchain state is a hashmap. In some cases we consider (partially defined) \u201cmaps\u201d h : 2 ^n -- 2 ^m. More generally, we might be interested in hashmaps h : 2 ^n -- X for a composite type X. However, the source (or index) type is almost always 2 ^n . Sometimes, we have a \u201cdefault value\u201d empty : X, and the hashmap h : 2^n \u2192 X is \u201cinitialized\u201d by its \u201cdefault value\u201d i \u2192 empty.","title":"2.3.2. Main component: Hashmaps."},{"location":"TON Blockchain/TON Whitepaper/#233-example-ton-account-balances","text":"An important example is given by TON account balances. It is a hashmap balance : \u200b Account \u2192 uint*128* (10) mapping Account = 2^256 into a Gram (TON coin) balance of type uint128 = 2^128. This hashmap has a default value of zero, meaning that initially (before the first block is processed) the balance of all accounts is zero.","title":"2.3.3. Example: TON account balances."},{"location":"TON Blockchain/TON Whitepaper/#234-example-smart-contract-persistent-storage","text":"Another example is given by smart-contract persistent storage, which can be (very approximately) represented as a hashmap storage : \u200b 2^256 -- 2^256 (11) This hashmap also has a default value of zero, meaning that uninitialized cells of persistent storage are assumed to be zero.","title":"2.3.4. Example: smart-contract persistent storage."},{"location":"TON Blockchain/TON Whitepaper/#235-example-persistent-storage-of-all-smart-contracts","text":"Because we have more than one smart contract, distinguished by account_id , each having its separate persistent storage, we must actually have a hashmap \u200b Storage : Account -- (2^256 -- 2^256) (12) mapping account_id of a smart contract into its persistent storage.","title":"2.3.5. Example: persistent storage of all smart contracts."},{"location":"TON Blockchain/TON Whitepaper/#236-hashmap-type","text":"The hashmap is not just an abstract (partially defined) function 2^n -- X; it has a specific representation. Therefore, we suppose that we have a special hashmap type \u200b *Hashmap(n, X) : Type* (13) corresponding to a data structure encoding a (partial) map 2^n-- X. We can also write \u200b Hashmap(n : nat)(X : Type) : Type (14) or \u200b Hashmap : nat \u2192 Type \u2192 Type (15) We can always transform h : Hashmap(n, X) into a map hget(h) : 2^n \u2192 X^? . Henceforth, we usually write h[i] instead of hget(h)(i): \u200b h[i] :\u2261 hget(h)(i) : X^? for any i : **2**^n , h : Hashmap(n, X) (16)","title":"2.3.6. Hashmap type."},{"location":"TON Blockchain/TON Whitepaper/#237-definition-of-hashmap-type-as-a-patricia-tree","text":"Logically, one might define Hashmap(n, X) as an (incomplete) binary tree of depth n with edge labels 0 and 1 and with values of type X in the leaves. Another way to describe the same structure would be as a (bitwise) trie for binary strings of length equal to n. In practice, we prefer to use a compact representation of this trie, by compressing each vertex having only one child with its parent. The resulting representation is known as a Patricia tree or a binary radix tree. Each intermediate vertex now has exactly two children, labeled by two non-empty binary strings, beginning with zero for the left child and with one for the right child. In other words, there are two types of (non-root) nodes in a Patricia tree: Leaf(x), containing value x of type X. Node(l, sl , r, sr), where l is the (reference to the) left child or subtree, sl is the bitstring labeling the edge connecting this vertex to its left child (always beginning with 0), r is the right subtree, and sr is the bitstring labeling the edge to the right child (always beginning with 1). A third type of node, to be used only once at the root of the Patricia tree, is also necessary: Root(n, s0, t), where n is the common length of index bitstrings of Hashmap(n, X), s0 is the common prefix of all index bitstrings, and t is a reference to a Leaf or a Node. If we want to allow the Patricia tree to be empty, a fourth type of (root) node would be used: EmptyRoot(n), where n is the common length of all index bitstrings. We define the height of a Patricia tree by height (Leaf(x))= 0 (17) HEIGHT Node(*l, sl , r, sr*)= height(*l*) + len(*sl*) = height(*r*) + len(*sr*) (18) HEIGHT Root(*n, s0, t*)= len(*s0*) + height(*t*) = *n* (19) The last two expressions in each of the last two formulas must be equal. We use Patricia trees of height n to represent values of type Hashmap(n, X) . If there are N leaves in the tree (i.e., our hashmap contains N values), then there are exactly N \u2212 1 intermediate vertices. Inserting a new value always involves splitting an existing edge by inserting a new vertex in the middle and adding a new leaf as the other child of this new vertex. Deleting a value from a hashmap does the opposite: a leaf and its parent are deleted, and the parent\u2019s parent and its other child become directly linked","title":"2.3.7. Definition of hashmap type as a Patricia tree."},{"location":"TON Blockchain/TON Whitepaper/#238-merkle-patricia-trees","text":"When working with blockchains, we want to be able to compare Patricia trees (i.e., hash maps) and their subtrees, by reducing them to a single hash value. The classical way of achieving this is given by the Merkle tree. Essentially, we want to describe a way of hashing objects h of type Hashmap(n, X) with the aid of a hash function Hash defined for binary strings, provided we know how to compute hashes Hash(x) of objects x : X (e.g., by applying the hash function Hash to a binary serialization of object x). One might define Hash(h) recursively as follows: Hash Leaf(x) := Hash(x) (20) Hash Node(*l, sl , r, sr*) := Hash Hash(*l*). Hash(*r*). code(*sl*). code(*sr*) (21) Hash Root(*n, s0, t*) := Hash code(*n*). code(*s0*). Hash(*t*) (22) Here s.t denotes the concatenation of (bit) strings s and t , and code( s ) is a prefix code for all bit strings s . For example, one might encode 0 by 10, 1 by 11, and the end of the string by 0.* We will see later (cf. 2.3.12 and 2.3.14 ) that this is a (slightly tweaked) version of recursively defined hashes for values of arbitrary (dependent) algebraic types. *One can show that this encoding is optimal for approximately half of all edge labels of a Patricia tree with random or consecutive indices. Remaining edge labels are likely to be long (i.e., almost 256 bits long). Therefore, a nearly optimal encoding for edge labels is to use the above code with prefix 0 for \u201cshort\u201d bit strings, and encode 1, then nine bits containing length l = |s| of bitstring s, and then the l bits of s for \u201clong\u201d bitstrings (with l \u2265 10).","title":"2.3.8. Merkle-Patricia trees."},{"location":"TON Blockchain/TON Whitepaper/#239-recomputing-merkle-tree-hashes","text":"This way of recursively defining Hash(h), called a Merkle tree hash, has the advantage that, if one explicitly stores Hash(h') along with each node h' (resulting in a structure called a Merkle tree , or, in our case, a Merkle\u2013Patricia tree ), one needs to recompute only at most n hashes when an element is added to, deleted from or changed in the hashmap. In this way, if one represents the global blockchain state by a suitable Merkle tree hash, it is easy to recompute this state hash after each transaction.","title":"2.3.9. Recomputing Merkle tree hashes."},{"location":"TON Blockchain/TON Whitepaper/#2310-merkle-proofs","text":"Under the assumption (7) of \u201cinjectivity\u201d of the chosen hash function Hash, one can construct a proof that, for a given value z of Hash(h), h : Hashmap(n, X), one has hget(h)(i) = x for some i : 2^n and x : X. Such a proof will consist of the path in the Merkle\u2013Patricia tree from the leaf corresponding to i to the root, augmented by the hashes of all siblings of all nodes occurring on this path. In this way, a light node knowing only the value of Hash(h) for some hashmap h (e.g., smart-contract persistent storage or global blockchain state) might request from a full node * not only the value x = h[i] = hget(h)(i), but such a value along with a Merkle proof starting from the already known value Hash(h). Then, under assumption (7), the light node can check for itself that x is indeed the correct value of h[i]. In some cases, the client may want to obtain the value y = Hash(x) = Hash(h[i]) instead\u2014for example, if x itself is very large (e.g., a hashmap itself). Then a Merkle proof for (i, y) can be provided instead. If x is a hashmap as well, then a second Merkle proof starting from y = Hash(x) may be obtained from a full node, to provide a value x[j] = h[i][j] or just its hash. *A light node is a node that does not keep track of the full state of a shardchain; instead, it keeps minimal information such as the hashes of the several most recent blocks, and relies on information obtained from full nodes when it becomes necessary to inspect some parts of the full state. **A full node is a node keeping track of the complete up-to-date state of the shardchain in question.","title":"2.3.10. Merkle proofs."},{"location":"TON Blockchain/TON Whitepaper/#2311-importance-of-merkle-proofs-for-a-multi-chain-system-such-as-ton","text":"Notice that a node normally cannot be a full node for all shardchains existing in the TON environment. It usually is a full node only for some shardchains\u2014for instance, those containing its own account, a smart contract it is interested in, or those that this node has been assigned to be a validator of. For other shardchains, it must be a light node\u2014otherwise the storage, computing and network bandwidth requirements would be prohibitive. This means that such a node cannot directly check assertions about the state of other shardchains; it must rely on Merkle proofs obtained from full nodes for those shardchains, which is as safe as checking by itself unless (7) fails (i.e., a hash collision is found).","title":"2.3.11. Importance of Merkle proofs for a multi-chain system such as TON."},{"location":"TON Blockchain/TON Whitepaper/#2312-peculiarities-of-ton-vm","text":"The TON VM or TVM (Telegram Virtual Machine), used to run smart contracts in the masterchain and Workchain Zero, is considerably different from customary designs inspired by the EVM (Ethereum Virtual Machine): it works not just with 256-bit integers, but actually with (almost) arbitrary \u201crecords\u201d, \u201cstructures\u201d, or \u201csum-product types\u201d, making it more suitable to execute code written in high-level (especially functional) languages. Essentially, TVM uses tagged data types, not unlike those used in implementations of Prolog or Erlang. One might imagine first that the state of a TVM smart contract is not just a hashmap 2 ^256 \u2192 2 ^256, or Hashmap(256, 2 ^256), but (as a first step) Hashmap(256, X), where X is a type with several constructors, enabling it to store, apart from 256-bit integers, other data structures, including other hashmaps Hashmap(256, X) in particular. This would mean that a cell of TVM (persistent or temporary) storage\u2014or a variable or an element of an array in a TVM smart-contract code\u2014may contain not only an integer, but a whole new hashmap. Of course, this would mean that a cell contains not just 256 bits, but also, say, an 8-bit tag, describing how these 256 bits should be interpreted. In fact, values do not need to be precisely 256-bit. The value format used by TVM consists of a sequence of raw bytes and references to other structures, mixed in arbitrary order, with some descriptor bytes inserted in suitable locations to be able to distinguish pointers from raw data (e.g., strings or integers); cf. 2.3.14 . This raw value format may be used to implement arbitrary sum-product algebraic types. In this case, the value would contain a raw byte first, describing the \u201cconstructor\u201d being used (from the perspective of a high-level language), and then other \u201cfields\u201d or \u201cconstructor arguments\u201d, consisting of raw bytes and references to other structures depending on the constructor chosen (cf. 2.2.5 ). However, TVM does not know anything about the correspondence between constructors and their arguments; the mixture of bytes and references is explicitly described by certain descriptor bytes.* The Merkle tree hashing is extended to arbitrary such structures: to compute the hash of such a structure, all references are recursively replaced by hashes of objects referred to, and then the hash of the resulting byte string (descriptor bytes included) is computed. In this way, the Merkle tree hashing for hashmaps, described in 2.3.8, is just a special case of hashing for arbitrary (dependent) algebraic data types, applied to type Hashmap(n, X) with two constructors.** *These two descriptor bytes, present in any TVM cell, describe only the total number of references and the total number of raw bytes; references are kept together either before or after all raw bytes. **Actually, Leaf and Node are constructors of an auxiliary type, HashmapAux(n, X). Type Hashmap(n, X) has constructors Root and EmptyRoot, with Root containing a value of type HashmapAux(n, X).","title":"2.3.12. Peculiarities of TON VM."},{"location":"TON Blockchain/TON Whitepaper/#2313-persistent-storage-of-ton-smart-contracts","text":"Persistent storage of a TON smart contract essentially consists of its \u201cglobal variables\u201d, preserved between calls to the smart contract. As such, it is just a \u201cproduct\u201d, \u201ctuple\u201d, or \u201crecord\u201d type, consisting of fields of the correct types, corresponding to one global variable each. If there are too many global variables, they cannot fit into one TON cell because of the global restriction on TON cell size. In such a case, they are split into several records and organized into a tree, essentially becoming a \u201cproduct of products\u201d or \u201cproduct of products of products\u201d type instead of just a product type.","title":"2.3.13. Persistent storage of TON smart contracts."},{"location":"TON Blockchain/TON Whitepaper/#2314-tvm-cells","text":"Ultimately, the TON VM keeps all data in a collection of (TVM) cells. Each cell contains two descriptor bytes first, indicating how many bytes of raw data are present in this cell (up to 128) and how many references to other cells are present (up to four). Then these raw data bytes and references follow. Each cell is referenced exactly once, so we might have included in each cell a reference to its \u201cparent\u201d (the only cell referencing this one). However, this reference need not be explicit. In this way, the persistent data storage cells of a TON smart contract are organized into a tree,* with a reference to the root of this tree kept in the smart-contract description. If necessary, a Merkle tree hash of this entire persistent storage is recursively computed, starting from the leaves and then simply replacing all references in a cell with the recursively computed hashes of the referenced cells, and subsequently computing the hash of the byte string thus obtained. *Logically; the \u201cbag of cells\u201d representation described in 2.5.5 identifies all duplicate cells, transforming this tree into a directed acyclic graph (dag) when serialized.","title":"2.3.14. TVM Cells."},{"location":"TON Blockchain/TON Whitepaper/#2315-generalized-merkle-proofs-for-values-of-arbitrary-algebraic-types","text":"Because the TON VM represents a value of arbitrary algebraic type by means of a tree consisting of (TVM) cells, and each cell has a well-defined (recursively computed) Merkle hash, depending in fact on the whole subtree rooted in this cell, we can provide \u201cgeneralized Merkle proofs\u201d for (parts of) values of arbitrary algebraic types, intended to prove that a certain subtree of a tree with a known Merkle hash takes a specific value or a value with a specific hash. This generalizes the approach of 2.3.10 , where only Merkle proofs for x[i] = y have been considered.","title":"2.3.15. Generalized Merkle proofs for values of arbitrary algebraic types."},{"location":"TON Blockchain/TON Whitepaper/#2316-support-for-sharding-in-ton-vm-data-structures","text":"We have just outlined how the TON VM, without being overly complicated, supports arbitrary (dependent) algebraic data types in high-level smart-contract languages. However, sharding of large (or global) smart contracts requires special support on the level of TON VM. To this end, a special version of the hashmap type has been added to the system, amounting to a \u201cmap\u201d Account 9 -- X. This \u201cmap\u201d might seem equivalent to Hashmap(m, X), where Account = 2^m. However, when a shard is split in two, or two shards are merged, such hashmaps are automatically split in two, or merged back, so as to keep only those keys that belong to the corresponding shard.","title":"2.3.16. Support for sharding in TON VM data structures."},{"location":"TON Blockchain/TON Whitepaper/#2317-payment-for-persistent-storage","text":"A noteworthy feature of the TON Blockchain is the payment exacted from smart contracts for storing their persistent data (i.e., for enlarging the total state of the blockchain). It works as follows: Each block declares two rates, nominated in the principal currency of the blockchain (usually the Gram): the price for keeping one cell in the persistent storage, and the price for keeping one raw byte in some cell of the persistent storage. Statistics on the total numbers of cells and bytes used by each account are stored as part of its state, so by multiplying these numbers by the two rates declared in the block header, we can compute the payment to be deducted from the account balance for keeping its data between the previous block and the current one. However, payment for persistent storage usage is not exacted for every account and smart contract in each block; instead, the sequence number of the block where this payment was last exacted is stored in the account data, and when any action is done with the account (e.g., a value transfer or a message is received and processed by a smart contract), the storage usage payment for all blocks since the previous such payment is deducted from the account balance before performing any further actions. If the account\u2019s balance would become negative after this, the account is destroyed. A workchain may declare some number of raw data bytes per account to be \u201cfree\u201d (i.e., not participating in the persistent storage payments) in order to make \u201csimple\u201d accounts, which keep only their balance in one or two cryptocurrencies, exempt from these constant payments. Notice that, if nobody sends any messages to an account, its persistent storage payments are not collected, and it can exist indefinitely. However, anybody can send, for instance, an empty message to destroy such an account. A small incentive, collected from part of the original balance of the account to be destroyed, can be given to the sender of such a message. We expect, however, that the validators would destroy such insolvent accounts for free, simply to decrease the global blockchain state size and to avoid keeping large amounts of data without compensation. Payments collected for keeping persistent data are distributed among the validators of the shardchain or the masterchain (proportionally to their stakes in the latter case).","title":"2.3.17. Payment for persistent storage."},{"location":"TON Blockchain/TON Whitepaper/#2318-local-and-global-smart-contracts-smart-contract-instances","text":"A smart contract normally resides just in one shard, selected according to the smart contract\u2019s account_id, similarly to an \u201cordinary\u201d account. This is usually sufficient for most applications. However, some \u201chigh-load\u201d smart contracts may want to have an \u201cinstance\u201d in each shardchain of some workchain. To achieve this, they must propagate their creating transaction into all shardchains, for instance, by committing this transaction into the \u201croot\u201d shardchain (w, \u2205) of the workchain w and paying a large commission. * This action effectively creates instances of the smart contract in each shard, with separate balances. Originally, the balance transferred in the creating transaction is distributed simply by giving the instance in shard (w, s) the 2^\u2212|s| part of the total balance. When a shard splits into two child shards, balances of all instances of global smart contracts are split in half; when two shards merge, balances are added together. In some cases, splitting/merging instances of global smart contracts may involve (delayed) execution of special methods of these smart contracts. By default, the balances are split and merged as described above, and some special \u201caccount-indexed\u201d hashmaps are also automatically split and merged (cf. 2.3.16). *A more expensive alternative is to publish such a \u201cglobal\u201d smart contract in the masterchain. **This is a sort of \u201cbroadcast\u201d feature for all shards, and as such, it must be quite expensive.","title":"2.3.18. Local and global smart contracts; smart-contract instances."},{"location":"TON Blockchain/TON Whitepaper/#2319-limiting-splitting-of-smart-contracts","text":"A global smart contract may limit its splitting depth d upon its creation, in order to make persistent storage expenses more predictable. This means that, if shardchain (w, s) with |s| \u2265 d splits in two, only one of two new shardchains inherits an instance of the smart contract. This shardchain is chosen deterministically: each global smart contract has some \u201caccount_id\u201d , which is essentially the hash of its creating transaction, and its instances have the same account_id with the first \u2264 d bits replaced by suitable values needed to fall into the correct shard. This account_id selects which shard will inherit the smart-contract instance after splitting.","title":"2.3.19. Limiting splitting of smart contracts."},{"location":"TON Blockchain/TON Whitepaper/#2320-accountsmart-contract-state","text":"We can summarize all of the above to conclude that an account or smart-contract state consists of the following: A balance in the principal currency of the blockchain A balance in other currencies of the blockchain Smart-contract code (or its hash) Smart-contract persistent data (or its Merkle hash) Statistics on the number of persistent storage cells and raw bytes used The last time (actually, the masterchain block number) when payment for smart-contract persistent storage was collected The public key needed to transfer currency and send messages from this account (optional; by default equal to account_id itself). In some cases, more sophisticated signature checking code may be located here, similar to what is done for Bitcoin transaction outputs; then the account_id will be equal to the hash of this code. We also need to keep somewhere, either in the account state or in some other account-indexed hashmap, the following data: The output message queue of the account (cf. 2.4.17 ) The collection of (hashes of) recently delivered messages (cf. 2.4.23 ) Not all of these are really required for every account; for example, smartcontract code is needed only for smart contracts, but not for \u201csimple\u201d accounts. Furthermore, while any account must have a non-zero balance in the principal currency (e.g., Grams for the masterchain and shardchains of the basic workchain), it may have balances of zero in other currencies. In order to avoid keeping unused data, a sum-product type (depending on the workchain) is defined (during the workchain\u2019s creation), which uses different tag bytes (e.g., TL constructors; cf. 2.2.5 ) to distinguish between different \u201cconstructors\u201d used. Ultimately, the account state is itself kept as a collection of cells of the TVM persistent storage.","title":"2.3.20. Account/Smart-contract state."},{"location":"TON Blockchain/TON Whitepaper/#24-messages-between-shardchains","text":"An important component of the TON Blockchain is the messaging system between blockchains. These blockchains may be shardchains of the same workchain, or of different workchains.","title":"2.4 Messages Between Shardchains"},{"location":"TON Blockchain/TON Whitepaper/#241-messages-accounts-and-transactions-a-birds-eye-view-of-the-system","text":"Messages are sent from one account to another. Each transaction consists of an account receiving one message, changing its state according to certain rules, and generating several (maybe one or zero) new messages to other accounts. Each message is generated and received (delivered) exactly once. This means that messages play a fundamental role in the system, comparable to that of accounts (smart contracts). From the perspective of the Infinite Sharding Paradigm (cf. 2.1.2 ), each account resides in its separate \u201caccount-chain\u201d, and the only way it can affect the state of some other account is by sending a message.","title":"2.4.1. Messages, accounts and transactions: a bird\u2019s eye view of the system."},{"location":"TON Blockchain/TON Whitepaper/#242-accounts-as-processes-or-actors-actor-model","text":"One might think about accounts (and smart contracts) as \u201cprocesses\u201d, or \u201cactors\u201d, that are able to process incoming messages, change their internal state and generate some outbound messages as a result. This is closely related to the so-called Actor model , used in languages such as Erlang (however, actors in Erlang are usually called \u201cprocesses\u201d). Since new actors (i.e., smart contracts) are also allowed to be created by existing actors as a result of processing an inbound message, the correspondence with the Actor model is essentially complete.","title":"2.4.2. Accounts as processes or actors; Actor model."},{"location":"TON Blockchain/TON Whitepaper/#243-message-recipient","text":"Any message has its recipient, characterized by the target workchain identifier w (assumed by default to be the same as that of the originating shardchain), and the recipient account account_id . The exact format (i.e., number of bits) of account_id depends on w ; however, the shard is always determined by its first (most significant) 64 bits.","title":"2.4.3. Message recipient."},{"location":"TON Blockchain/TON Whitepaper/#244-message-sender","text":"In most cases, a message has a sender , characterized again by a ( w' , account_id' ) pair. If present, it is located after the message recipient and message value. Sometimes, the sender is unimportant or it is somebody outside the blockchain (i.e., not a smart contract), in which case this field is absent. Notice that the Actor model does not require the messages to have an implicit sender. Instead, messages may contain a reference to the Actor to which an answer to the request should be sent; usually it coincides with the sender. However, it is useful to have an explicit unforgeable sender field in a message in a cryptocurrency (Byzantine) environment.","title":"2.4.4. Message sender."},{"location":"TON Blockchain/TON Whitepaper/#245-message-value","text":"Another important characteristic of a message is its attached value, in one or several cryptocurrencies supported both by the source and by the target workchain. The value of the message is indicated at its very beginning immediately after the message recipient; it is essentially a list of ( currency_id, value ) pairs. Notice that \u201csimple\u201d value transfers between \u201csimple\u201d accounts are just empty (no-op) messages with some value attached to them. On the other hand, a slightly more complicated message body might contain a simple text or binary comment (e.g., about the purpose of the payment).","title":"2.4.5. Message value."},{"location":"TON Blockchain/TON Whitepaper/#246-external-messages-or-messages-from-nowhere","text":"Some messages arrive into the system \u201cfrom nowhere\u201d\u2014that is, they are not generated by an account (smart contract or not) residing in the blockchain. The most typical example arises when a user wants to transfer some funds from an account controlled by her to some other account. In this case, the user sends a \u201cmessage from nowhere\u201d to her own account, requesting it to generate a message to the receiving account, carrying the specified value. If this message is correctly signed, her account receives it and generates the required outbound messages. In fact, one might consider a \u201csimple\u201d account as a special case of a smart contract with predefined code. This smart contract receives only one type of message. Such an inbound message must contain a list of outbound messages to be generated as a result of delivering (processing) the inbound message, along with a signature. The smart contract checks the signature, and, if it is correct, generates the required messages. Of course, there is a difference between \u201cmessages from nowhere\u201d and normal messages, because the \u201cmessages from nowhere\u201d cannot bear value, so they cannot pay for their \u201cgas\u201d (i.e., their processing) themselves. Instead, they are tentatively executed with a small gas limit before even being suggested for inclusion in a new shardchain block; if the execution fails (the signature is incorrect), the \u201cmessage from nowhere\u201d is deemed incorrect and is discarded. If the execution does not fail within the small gas limit, the message may be included in a new shardchain block and processed completely, with the payment for the gas (processing capacity) consumed exacted from the receiver\u2019s account. \u201cMessages from nowhere\u201d can also define some transaction fee which is deducted from the receiver\u2019s account on top of the gas payment for redistribution to the validators. In this sense, \u201cmessages from nowhere\u201d or \u201cexternal messages\u201d take the role of transaction candidates used in other blockchain systems (e.g., Bitcoin and Ethereum).","title":"2.4.6. External messages, or \u201cmessages from nowhere\u201d."},{"location":"TON Blockchain/TON Whitepaper/#247-log-messages-or-messages-to-nowhere","text":"Similarly, sometimes a special message can be generated and routed to a specific shardchain not to be delivered to its recipient, but to be logged in order to be easily observable by anybody receiving updates about the shard in question. These logged messages may be output in a user\u2019s console, or trigger an execution of some script on an off-chain server. In this sense, they represent the external \u201coutput\u201d of the \u201cblockchain supercomputer\u201d, just as the \u201cmessages from nowhere\u201d represent the external \u201cinput\u201d of the \u201cblockchain supercomputer\u201d.","title":"2.4.7. Log messages, or \u201cmessages to nowhere\u201d."},{"location":"TON Blockchain/TON Whitepaper/#248-interaction-with-off-chain-services-and-external-blockchains","text":"These external input and output messages can be used for interacting with off-chain services and other (external) blockchains, such as Bitcoin or Ethereum. One might create tokens or cryptocurrencies inside the TON Blockchain pegged to Bitcoins, Ethers or any ERC-20 tokens defined in the Ethereum blockchain, and use \u201cmessages from nowhere\u201d and \u201cmessages to nowhere\u201d, generated and processed by scripts residing on some third-party off-chain servers, to implement the necessary interaction between the TON Blockchain and these external blockchains.","title":"2.4.8. Interaction with off-chain services and external blockchains."},{"location":"TON Blockchain/TON Whitepaper/#249-message-body","text":"The message body is simply a sequence of bytes, the meaning of which is determined only by the receiving workchain and/or smart contract. For blockchains using TON VM, this could be the serialization of any TVM cell, generated automatically via the Send() operation. Such a serialization is obtained simply by recursively replacing all references in a TON VM cell with the cells referred to. Ultimately, a string of raw bytes appears, which is usually prepended by a 4-byte \u201cmessage type\u201d or \u201cmessage constructor\u201d, used to select the correct method of the receiving smart contract. Another option would be to use TL-serialized objects (cf. 2.2.5 ) as message bodies. This might be especially useful for communication between different workchains, one or both of which are not necessarily using the TON VM. Sometimes a message needs to carry information about the gas limit, the gas price, transaction fees and similar values that depend on the receiving workchain and are relevant only for the receiving workchain, but not necessarily for the originating workchain. Such parameters are included in or before the message body, sometimes (depending on the workchain) with special 4- byte prefixes indicating their presence (which can be defined by a TL-scheme; cf. 2.2.5 ).","title":"2.4.9 Message body"},{"location":"TON Blockchain/TON Whitepaper/#2410-gas-limit-and-other-workchainvm-specific-parameters","text":"Sometimes a message needs to carry information about the gas limit, the gas price, transaction fees and similar values that depend on the receiving workchain and are relevant only for the receiving workchain, but not necessarily for the originating workchain. Such parameters are included in or before the message body, sometimes (depending on the workchain) with special 4- byte prefixes indicating their presence (which can be defined by a TL-scheme; cf. 2.2.5 ).","title":"2.4.10. Gas limit and other workchain/VM-specific parameters."},{"location":"TON Blockchain/TON Whitepaper/#2411-creating-messages-smart-contracts-and-transactions","text":"There are two sources of new messages. Most messages are created during smartcontract execution (via the Send() operation in TON VM), when some smart contract is invoked to process an incoming message. Alternatively, messages may come from the outside as \u201cexternal messages\u201d or \u201cmessages from nowhere\u201d (cf. 2.4.6 ).* *The above needs to be literally true only for the basic workchain and its shardchains; other workchains may provide other ways of creating messages.","title":"2.4.11. Creating messages: smart contracts and transactions."},{"location":"TON Blockchain/TON Whitepaper/#2412-delivering-messages","text":"When a message reaches the shardchain containing its destination account,* it is \u201cdelivered\u201d to its destination account. What happens next depends on the workchain; from an outside perspective, it is important that such a message can never be forwarded further from this shardchain. For shardchains of the basic workchain, delivery consists in adding the message value (minus any gas payments) to the balance of the receiving account, and possibly in invoking a message-dependent method of the receiving smart contract afterwards, if the receiving account is a smart contract. In fact, a smart contract has only one entry point for processing all incoming messages, and it must distinguish between different types of messages by looking at their first few bytes (e.g., the first four bytes containing a TL constructor; cf. 2.2.5 ). *As a degenerate case, this shardchain may coincide with the originating shardchain\u2014 for example, if we are working inside a workchain which has not yet been split.","title":"2.4.12. Delivering messages."},{"location":"TON Blockchain/TON Whitepaper/#2413-delivery-of-a-message-is-a-transaction","text":"Because the delivery of a message changes the state of an account or smart contract, it is a special transaction in the receiving shardchain, and is explicitly registered as such. Essentially, all TON Blockchain transactions consist in the delivery of one inbound message to its receiving account (smart contract), neglecting some minor technical details.","title":"2.4.13. Delivery of a message is a transaction."},{"location":"TON Blockchain/TON Whitepaper/#2414-messages-between-instances-of-the-same-smart-contract","text":"Recall that a smart contract may be local (i.e., residing in one shardchain as any ordinary account does) or global (i.e., having instances in all shards, or at least in all shards up to some known depth d; cf. 2.3.18 ). Instances of a global smart contract may exchange special messages to transfer information and value between each other if required. In this case, the (unforgeable) sender account_id becomes important (cf. 2.4.4 ).","title":"2.4.14. Messages between instances of the same smart contract."},{"location":"TON Blockchain/TON Whitepaper/#2415-messages-to-any-instance-of-a-smart-contract-wildcard-addresses","text":"Sometimes a message (e.g., a client request) needs be delivered to any instance of a global smart contract, usually the closest one (if there is one residing in the same shardchain as the sender, it is the obvious candidate). One way of doing this is by using a \u201cwildcard recipient address\u201d, with the first d bits of the destination account_id allowed to take arbitrary values. In practice, one will usually set these d bits to the same values as in the sender\u2019s account_id .","title":"2.4.15. Messages to any instance of a smart contract; wildcard addresses."},{"location":"TON Blockchain/TON Whitepaper/#2416-input-queue-is-absent","text":"All messages received by a blockchain (usually a shardchain; sometimes the masterchain)\u2014or, essentially, by an \u201caccount-chain\u201d residing inside some shardchain\u2014are immediately delivered (i.e., processed by the receiving account). Therefore, there is no \u201cinput queue\u201d as such. Instead, if not all messages destined for a specific shardchain can be processed because of limitations on the total size of blocks and gas usage, some messages are simply left to accumulate in the output queues of the originating shardchains.","title":"2.4.16. Input queue is absent."},{"location":"TON Blockchain/TON Whitepaper/#2417-output-queues","text":"From the perspective of the Infinite Sharding Paradigm (cf. 2.1.2 ), each account-chain (i.e., each account) has its own output queue, consisting of all messages it has generated, but not yet delivered to their recipients. Of course, account-chains have only a virtual existence; they are grouped into shardchains, and a shardchain has an output \u201cqueue\u201d, consisting of the union of the output queues of all accounts belonging to the shardchain. This shardchain output \u201cqueue\u201d imposes only partial order on its member messages. Namely, a message generated in a preceding block must be delivered before any message generated in a subsequent block, and any messages generated by the same account and having the same destination must be delivered in the order of their generation.","title":"2.4.17. Output queues."},{"location":"TON Blockchain/TON Whitepaper/#2418-reliable-and-fast-inter-chain-messaging","text":"It is of paramount importance for a scalable multi-blockchain project such as TON to be able to forward and deliver messages between different shardchains (cf. 2.1.3 ), even if there are millions of them in the system. The messages should be delivered reliably (i.e., messages should not be lost or delivered more than once) and quickly. The TON Blockchain achieves this goal by using a combination of two \u201cmessage routing\u201d mechanisms.","title":"2.4.18. Reliable and fast inter-chain messaging."},{"location":"TON Blockchain/TON Whitepaper/#2419-hypercube-routing-slow-path-for-messages-with-assured-delivery","text":"The TON Blockchain uses \u201chypercube routing\u201d as a slow, but safe and reliable way of delivering messages from one shardchain to another, using several intermediate shardchains for transit if necessary. Otherwise, the validators of any given shardchain would need to keep track of the state of (the output queues of) all other shardchains, which would require prohibitive amounts of computing power and network bandwidth as the total quantity of shardchains grows, thus limiting the scalability of the system. Therefore, it is not possible to deliver messages directly from any shard to every other. Instead, each shard is \u201cconnected\u201d only to shards differing in exactly one hexadecimal digit of their (w, s) shard identifiers (cf. 2.1.8 ). In this way, all shardchains constitute a \u201chypercube\u201d graph, and messages travel along the edges of this hypercube. If a message is sent to a shard different from the current one, one of the hexadecimal digits (chosen deterministically) of the current shard identifier is replaced by the corresponding digit of the target shard, and the resulting identifier is used as the proximate target to forward the message to.* *This is not necessarily the final version of the algorithm used to compute the next hop for hypercube routing. In particular, hexadecimal digits may be replaced by r-bit groups, with r a configurable parameter, not necessarily equal to four. The main advantage of hypercube routing is that the block validity conditions imply that validators creating blocks of a shardchain must collect and process messages from the output queues of \u201cneighboring\u201d shardchains, on pain of losing their stakes. In this way, any message can be expected to reach its final destination sooner or later; a message cannot be lost in transit or delivered twice. Notice that hypercube routing introduces some additional delays and expenses, because of the necessity to forward messages through several intermediate shardchains. However, the number of these intermediate shardchains grows very slowly, as the logarithm log N (more precisely, dlog 16 Ne \u2212 1) of the total number of shardchains N. For example, if N \u2248 250, there will be at most one intermediate hop; and for N \u2248 4000 shardchains, at most two. With four intermediate hops, we can support up to one million shardchains. We think this is a very small price to pay for the essentially unlimited scalability of the system. In fact, it is not necessary to pay even this price:","title":"2.4.19. Hypercube routing: \u201cslow path\u201d for messages with assured delivery."},{"location":"TON Blockchain/TON Whitepaper/#2420-instant-hypercube-routing-fast-path-for-messages","text":"A novel feature of the TON Blockchain is that it introduces a \u201cfast path\u201d for forwarding messages from one shardchain to any other, allowing in most cases to bypass the \u201cslow\u201d hypercube routing of 2.4.19 altogether and deliver the message into the very next block of the final destination shardchain. The idea is as follows. During the \u201cslow\u201d hypercube routing, the message travels (in the network) along the edges of the hypercube, but it is delayed (for approximately five seconds) at each intermediate vertex to be committed into the corresponding shardchain before continuing its voyage. To avoid unnecessary delays, one might instead relay the message along with a suitable Merkle proof along the edges of the hypercube, without waiting to commit it into the intermediate shardchains. In fact, the network message should be forwarded from the validators of the \u201ctask group\u201d (cf. 2.6.8 ) of the original shard to the designated block producer (cf. 2.6.9 ) of the \u201ctask group\u201d of the destination shard; this might be done directly without going along the edges of the hypercube. When this message with the Merkle proof reaches the validators (more precisely, the collators; cf. 2.6.5 ) of the destination shardchain, they can commit it into a new block immediately, without waiting for the message to complete its travel along the \u201cslow path\u201d. Then a confirmation of delivery along with a suitable Merkle proof is sent back along the hypercube edges, and it may be used to stop the travel of the message along the \u201cslow path\u201d, by committing a special transaction. Note that this \u201cinstant delivery\u201d mechanism does not replace the \u201cslow\u201d but failproof mechanism described in 2.4.19 . The \u201cslow path\u201d is still needed because the validators cannot be punished for losing or simply deciding not to commit the \u201cfast path\u201d messages into new blocks of their blockchains.* Therefore, both message forwarding methods are run in parallel, and the \u201cslow\u201d mechanism is aborted only if a proof of success of the \u201cfast\u201d mechanism is committed into an intermediate shardchain.** *However, the validators have some incentive to do so as soon as possible, because they will be able to collect all forwarding fees associated with the message that have not yet been consumed along the slow path. **In fact, one might temporarily or permanently disable the \u201cinstant delivery\u201d mechanism altogether, and the system would continue working, albeit more slowly","title":"2.4.20. Instant Hypercube Routing: \u201cfast path\u201d for messages."},{"location":"TON Blockchain/TON Whitepaper/#2421-collecting-input-messages-from-output-queues-of-neighboring-shardchains","text":"When a new block for a shardchain is proposed, some of the output messages of the neighboring (in the sense of the routing hypercube of 2.4.19 ) shardchains are included in the new block as \u201cinput\u201d messages and immediately delivered (i.e., processed). There are certain rules as to the order in which these neighbors\u2019 output messages must be processed. Essentially, an \u201colder\u201d message (coming from a shardchain block referring to an older masterchain block) must be delivered before any \u201cnewer\u201d message; and for messages coming from the same neighboring shardchain, the partial order of the output queue described in 2.4.17 must be observed.","title":"2.4.21. Collecting input messages from output queues of neighboring shardchains."},{"location":"TON Blockchain/TON Whitepaper/#2422-deleting-messages-from-output-queues","text":"Once an output queue message is observed as having been delivered by a neighboring shardchain, it is explicitly deleted from the output queue by a special transaction.","title":"2.4.22. Deleting messages from output queues."},{"location":"TON Blockchain/TON Whitepaper/#2423-preventing-double-delivery-of-messages","text":"To prevent double delivery of messages taken from the output queues of the neighboring shardchains, each shardchain (more precisely, each account-chain inside it) keeps the collection of recently delivered messages (or just their hashes) as part of its state. When a delivered message is observed to be deleted from the output queue by its originating neighboring shardchain (cf. 2.4.22 ), it is deleted from the collection of recently delivered messages as well.","title":"2.4.23. Preventing double delivery of messages."},{"location":"TON Blockchain/TON Whitepaper/#2424-forwarding-messages-intended-for-other-shardchains","text":"Hypercube routing (cf. 2.4.19 ) means that sometimes outbound messages are delivered not to the shardchain containing the intended recipient, but to a neighboring shardchain lying on the hypercube path to the destination. In this case, \u201cdelivery\u201d consists in moving the inbound message to the outbound queue. This is reflected explicitly in the block as a special forwarding transaction, containing the message itself. Essentially, this looks as if the message had been received by somebody inside the shardchain, and one identical message had been generated as result.","title":"2.4.24. Forwarding messages intended for other shardchains."},{"location":"TON Blockchain/TON Whitepaper/#2425-payment-for-forwarding-and-keeping-a-message","text":"The forwarding transaction actually spends some gas (depending on the size of the message being forwarded), so a gas payment is deducted from the value of the message being forwarded on behalf of the validators of this shardchain. This forwarding payment is normally considerably smaller than the gas payment exacted when the message is finally delivered to its recipient, even if the message has been forwarded several times because of hypercube routing. Furthermore, as long as a message is kept in the output queue of some shardchain, it is part of the shardchain\u2019s global state, so a payment for keeping global data for a long time may be also collected by special transactions.","title":"2.4.25. Payment for forwarding and keeping a message."},{"location":"TON Blockchain/TON Whitepaper/#2426-messages-to-and-from-the-masterchain","text":"Messages can be sent directly from any shardchain to the masterchain, and vice versa. However, gas prices for sending messages to and for processing messages in the masterchain are quite high, so this ability will be used only when truly necessary\u2014 for example, by the validators to deposit their stakes. In some cases, a minimal deposit (attached value) for messages sent to the masterchain may be defined, which is returned only if the message is deemed \u201cvalid\u201d by the receiving party. Messages cannot be automatically routed through the masterchain. A message with workchain_id =/= \u22121 (\u22121 being the special workchain_id indicating the masterchain) cannot be delivered to the masterchain. In principle, one can create a message-forwarding smart contract inside the masterchain, but the price of using it would be prohibitive.","title":"2.4.26. Messages to and from the masterchain."},{"location":"TON Blockchain/TON Whitepaper/#2427-messages-between-accounts-in-the-same-shardchain","text":"In some cases, a message is generated by an account belonging to some shardchain, destined to another account in the same shardchain. For example, this happens in a new workchain which has not yet split into several shardchains because the load is manageable. Such messages might be accumulated in the output queue of the shardchain and then processed as incoming messages in subsequent blocks (any shard is considered a neighbor of itself for this purpose). However, in most cases it is possible to deliver these messages within the originating block itself. In order to achieve this, a partial order is imposed on all transactions included in a shardchain block, and the transactions (each consisting in the delivery of a message to some account) are processed respecting this partial order. In particular, a transaction is allowed to process some output message of a preceding transaction with respect to this partial order. In this case, the message body is not copied twice. Instead, the originating and the processing transactions refer to a shared copy of the message.","title":"2.4.27. Messages between accounts in the same shardchain."},{"location":"TON Blockchain/TON Whitepaper/#25-global-shardchain-state-bag-of-cells-philosophy","text":"Now we are ready to describe the global state of a TON blockchain, or at least of a shardchain of the basic workchain. We start with a \u201chigh-level\u201d or \u201clogical\u201d description, which consists in saying that the global state is a value of algebraic type ShardchainState .","title":"2.5 Global Shardchain State. \u201cBag of Cells\u201d Philosophy."},{"location":"TON Blockchain/TON Whitepaper/#251-shardchain-state-as-a-collection-of-account-chain-states","text":"According to the Infinite Sharding Paradigm (cf. 2.1.2), any shardchain is just a (temporary) collection of virtual \u201caccount-chains\u201d, containing exactly one account each. This means that, essentially, the global shardchain state must be a hashmap \u200b ShardchainState := (Account 99K AccountState) (23) where all account_id appearing as indices of this hashmap must begin with prefix s, if we are discussing the state of shard (w, s) (cf. 2.1.8 ). In practice, we might want to split AccountState into several parts (e.g., keep the account output message queue separate to simplify its examination by the neighboring shardchains), and have several hashmaps (Account -- AccountStatePart i ) inside the ShardchainState . We might also add a small number of \u201cglobal\u201d or \u201cintegral\u201d parameters to the ShardchainState, (e.g., the total balance of all accounts belonging to this shard, or the total number of messages in all output queues). However, (23) is a good first approximation of what the shardchain global state looks like, at least from a \u201clogical\u201d (\u201chigh-level\u201d) perspective. The formal description of algebraic types AccountState and ShardchainState can be done with the aid of a TL-scheme (cf. 2.2.5 ), to be provided elsewhere.","title":"2.5.1. Shardchain state as a collection of account-chain states."},{"location":"TON Blockchain/TON Whitepaper/#252-splitting-and-merging-shardchain-states","text":"Notice that the Infinite Sharding Paradigm description of the shardchain state (23) shows how this state should be processed when shards are split or merged. In fact, these state transformations turn out to be very simple operations with hashmaps.","title":"2.5.2. Splitting and merging shardchain states."},{"location":"TON Blockchain/TON Whitepaper/#253-account-chain-state","text":"The (virtual) account-chain state is just the state of one account, described by type AccountState. Usually it has all or some of the fields listed in 2.3.20 , depending on the specific constructor used.","title":"2.5.3. Account-chain state."},{"location":"TON Blockchain/TON Whitepaper/#254-global-workchain-state","text":"Similarly to (23), we may define the global workchain state by the same formula, but with account_id \u2019s allowed to take any values, not just those belonging to one shard. Remarks similar to those made in 2.5.1 apply in this case as well: we might want to split this hashmap into several hashmaps, and we might want to add some \u201cintegral\u201d parameters such as the total balance. Essentially, the global workchain state must be given by the same type ShardchainState as the shardchain state, because it is the shardchain state we would obtain if all existing shardchains of this workchain suddenly merged into one.","title":"2.5.4. Global workchain state."},{"location":"TON Blockchain/TON Whitepaper/#255-low-level-perspective-bag-of-cells","text":"There is a \u201clow-level\u201d description of the account-chain or shardchain state as well, complementary to the \u201chigh-level\u201d description given above. This description is quite important, because it turns out to be pretty universal, providing a common basis for representing, storing, serializing and transferring by network almost all data used by the TON Blockchain (blocks, shardchain states, smart-contract storage, Merkle proofs, etc.). At the same time, such a universal \u201clow-level\u201d description, once understood and implemented, allows us to concentrate our attention on the \u201chigh-level\u201d considerations only. Recall that the TVM represents values of arbitrary algebraic types (including, for instance, ShardchainState of (23)) by means of a tree of TVM cells, or cells for short (cf. 2.3.14 and 2.2.5 ). Any such cell consists of two descriptor bytes , defining certain flags and values 0 \u2264 b \u2264 128, the quantity of raw bytes, and 0 \u2264 c \u2264 4, the quantity of references to other cells. Then b raw bytes and c cell references follow.* The exact format of cell references depends on the implementation and on whether the cell is located in RAM, on disk, in a network packet, in a block, and so on. A useful abstract model consists in imagining that all cells are kept in content-addressable memory, with the address of a cell equal to its (sha256) hash. Recall that the (Merkle) hash of a cell is computed exactly by replacing the references to its child cells by their (recursively computed) hashes and hashing the resulting byte string. In this way, if we use cell hashes to reference cells (e.g., inside descriptions of other cells), the system simplifies somewhat, and the hash of a cell starts to coincide with the hash of the byte string representing it. Now we see that any object representable by TVM, the global shardchain state included , can be represented as a \u201cbag of cells\u201d \u2014i.e., a collection of cells along with a \u201croot\u201d reference to one of them (e.g., by hash). Notice that duplicate cells are removed from this description (the \u201cbag of cells\u201d is a set of cells, not a multiset of cells), so the abstract tree representation might actually become a directed acyclic graph (dag) representation. One might even keep this state on disk in a B- or B+ -tree, containing all cells in question (maybe with some additional data, such as subtree height or reference counter), indexed by cell hash. However, a naive implementation of this idea would result in the state of one smart contract being scattered among distant parts of the disk file, something we would rather avoid.** Now we are going to explain in some detail how almost all objects used by the TON Blockchain can be represented as \u201cbags of cells\u201d, thus demonstrating the universality of this approach. *One can show that, if Merkle proofs for all data stored in a tree of cells are needed equally often, one should use cells with b+ch \u2248 2(h+r) to minimize average Merkle proof size, where h = 32 is the hash size in bytes, and r \u2248 4 is the \u201cbyte size\u201d of a cell reference. In other words, a cell should contain either two references and a few raw bytes, or one reference and about 36 raw bytes, or no references at all with 72 raw bytes. **A better implementation would be to keep the state of the smart contract as a serialized string, if it is small, or in a separate B-tree, if it is large; then the top-level structure representing the state of a blockchain would be a B-tree, whose leaves are allowed to contain references to other B-trees.","title":"2.5.5. Low-level perspective: \u201cbag of cells\u201d."},{"location":"TON Blockchain/TON Whitepaper/#256-shardchain-block-as-a-bag-of-cells","text":"A shardchain block itself can be also described by an algebraic type, and stored as a \u201cbag of cells\u201d. Then a naive binary representation of the block may be obtained simply by concatenating the byte strings representing each of the cells in the \u201cbag of cells\u201d, in arbitrary order. This representation might be improved and optimized, for instance, by providing a list of offsets of all cells at the beginning of the block, and replacing hash references to other cells with 32-bit indices in this list whenever possible. However, one should imagine that a block is essentially a \u201cbag of cells\u201d, and all other technical details are just minor optimization and implementation issues.","title":"2.5.6. Shardchain block as a \u201cbag of cells\u201d."},{"location":"TON Blockchain/TON Whitepaper/#257-update-to-an-object-as-a-bag-of-cells","text":"Imagine that we have an old version of some object represented as a \u201cbag of cells\u201d, and that we want to represent a new version of the same object, supposedly not too different from the previous one. One might simply represent the new state as another \u201cbag of cells\u201d with its own root, a nd remove from it all cells occurring in the old version . The remaining \u201cbag of cells\u201d is essentially an update to the object. Everybody who has the old version of this object and the update can compute the new version, simply by uniting the two bags of cells, and removing the old root (decreasing its reference counter and de-allocating the cell if the reference counter becomes zero).","title":"2.5.7. Update to an object as a \u201cbag of cells\u201d."},{"location":"TON Blockchain/TON Whitepaper/#258-updates-to-the-state-of-an-account","text":"In particular, updates to the state of an account, or to the global state of a shardchain, or to any hashmap can be represented using the idea described in 2.5.7 . This means that when we receive a new shardchain block (which is a \u201cbag of cells\u201d), we interpret this \u201cbag of cells\u201d not just by itself, but by uniting it first with the \u201cbag of cells\u201d representing the previous state of the shardchain. In this sense each block may \u201ccontain\u201d the whole state of the blockchain.","title":"2.5.8. Updates to the state of an account."},{"location":"TON Blockchain/TON Whitepaper/#259-updates-to-a-block","text":"Recall that a block itself is a \u201cbag of cells\u201d, so, if it becomes necessary to edit a block, one can similarly define a \u201cblock update\u201d as a \u201cbag of cells\u201d, interpreted in the presence of the \u201cbag of cells\u201d which is the previous version of this block. This is roughly the idea behind the \u201cvertical blocks\u201d discussed in 2.1.17 .","title":"2.5.9. Updates to a block."},{"location":"TON Blockchain/TON Whitepaper/#2510-merkle-proof-as-a-bag-of-cells","text":"Notice that a (generalized) Merkle proof\u2014for example, one asserting that x[i] = y starting from a known value of Hash(x) = h (cf. 2.3.10 and 2.3.15)\u2014may also be represented as a \u201cbag of cells\u201d. Namely, one simply needs to provide a subset of cells corresponding to a path from the root of x : Hashmap(n, X) to its desired leaf with index i : 2^n and value y : X. References to children of these cells not lying on this path will be left \u201cunresolved\u201d in this proof, represented by cell hashes. One can also provide a simultaneous Merkle proof of, say, *x[i] = y* and *x[i'] = y'* , by including in the \u201cbag of cells\u201d the cells lying on the union of the two paths from the root of x to leaves corresponding to indices i and i' .","title":"2.5.10. Merkle proof as a \u201cbag of cells\u201d."},{"location":"TON Blockchain/TON Whitepaper/#2511-merkle-proofs-as-query-responses-from-full-nodes","text":"In essence, a full node with a complete copy of a shardchain (or account-chain) state can provide a Merkle proof when requested by a light node (e.g., a network node running a light version of the TON Blockchain client), enabling the receiver to perform some simple queries without external help, using only the cells provided in this Merkle proof. The light node can send its queries in a serialized format to the full node, and receive the correct answers with Merkle proofs\u2014or just the Merkle proofs, because the requester should be able to compute the answers using only the cells included in the Merkle proof. This Merkle proof would consist simply of a \u201cbag of cells\u201d, containing only those cells belonging to the shardchain\u2019s state that have been accessed by the full node while executing the light node\u2019s query. This approach can be used in particular for executing \u201cget queries\u201d of smart contracts (cf. 4.3.12 ).","title":"2.5.11. Merkle proofs as query responses from full nodes."},{"location":"TON Blockchain/TON Whitepaper/#2512-augmented-update-or-state-update-with-merkle-proof-of-validity","text":"Recall (cf. 2.5.7 ) that we can describe the changes in an object state from an old value x : X to a new value x' : X by means of an \u201cupdate\u201d, which is simply a \u201cbag of cells\u201d, containing those cells that lie in the subtree representing new value x', but not in the subtree representing old value x, because the receiver is assumed to have a copy of the old value x and all its cells. However, if the receiver does not have a full copy of x , but knows only its (Merkle) hash h = Hash(x) , it will not be able to check the validity of the update (i.e., that all \u201cdangling\u201d cell references in the update do refer to cells present in the tree of x). One would like to have \u201cverifiable\u201d updates, augmented by Merkle proofs of existence of all referred cells in the old state. Then anybody knowing only h = Hash(x) would be able to check the validity of the update and compute the new h'= Hash(x') by itself. Because our Merkle proofs are \u201cbags of cells\u201d themselves (cf. 2.5.10 ), one can construct such an augmented update as a \u201cbag of cells\u201d, containing the old root of x, some of its descendants along with paths from the root of x to them, and the new root of x' and all its descendants that are not part of x.","title":"2.5.12. Augmented update, or state update with Merkle proof of validity."},{"location":"TON Blockchain/TON Whitepaper/#2513-account-state-updates-in-a-shardchain-block","text":"In particular, account state updates in a shardchain block should be augmented as discussed in 2.5.12 . Otherwise, somebody might commit a block containing an invalid state update, referring to a cell absent in the old state; proving the invalidity of such a block would be problematic (how is the challenger to prove that a cell is not part of the previous state?). Now, if all state updates included in a block are augmented, their validity is easily checked, and their invalidity is also easily shown as a violation of the recursive defining property of (generalized) Merkle hashes.","title":"2.5.13. Account state updates in a shardchain block."},{"location":"TON Blockchain/TON Whitepaper/#2514-everything-is-a-bag-of-cells-philosophy","text":"Previous considerations show that everything we need to store or transfer, either in the TON Blockchain or in the network, is representable as a \u201cbag of cells\u201d. This is an important part of the TON Blockchain design philosophy. Once the \u201cbag of cells\u201d approach is explained and some \u201clow-level\u201d serializations of \u201cbags of cells\u201d are defined, one can simply define everything (block format, shardchain and account state, etc.) on the high level of abstract (dependent) algebraic data types. The unifying effect of the \u201ceverything is a bag of cells\u201d philosophy considerably simplifies the implementation of seemingly unrelated services; cf. 5.1.9 for an example involving payment channels.","title":"2.5.14. \u201cEverything is a bag of cells\u201d philosophy."},{"location":"TON Blockchain/TON Whitepaper/#2515-block-headers-for-ton-blockchains","text":"Usually, a block in a blockchain begins with a small header, containing the hash of the previous block, its creation time, the Merkle hash of the tree of all transactions contained in the block, and so on. Then the block hash is defined to be the hash of this small block header. Because the block header ultimately depends on all data included in the block, one cannot alter the block without changing its hash. In the \u201cbag of cells\u201d approach used by the blocks of TON blockchains, there is no designated block header. Instead, the block hash is defined as the (Merkle) hash of the root cell of the block. Therefore, the top (root) cell of the block might be considered a small \u201cheader\u201d of this block. However, the root cell might not contain all the data usually expected from such a header. Essentially, one wants the header to contain some of the fields defined in the Block datatype. Normally, these fields will be contained in several cells, including the root. These are the cells that together constitute a \u201cMerkle proof\u201d for the values of the fields in question. One might insist that a block contain these \u201cheader cells\u201d in the very beginning, before any other cells. Then one would need to download only the first several bytes of a block serialization in order to obtain all of the \u201cheader cells\u201d, and to learn all of the expected fields.","title":"2.5.15. Block \u201cheaders\u201d for TON blockchains."},{"location":"TON Blockchain/TON Whitepaper/#26-creating-and-validating-new-blocks","text":"The TON Blockchain ultimately consists of shardchain and masterchain blocks. These blocks must be created, validated and propagated through the network to all parties concerned, in order for the system to function smoothly and correctly.","title":"2.6 Creating and Validating New Blocks"},{"location":"TON Blockchain/TON Whitepaper/#261-validators","text":"New blocks are created and validated by special designated nodes, called validators . Essentially, any node wishing to become a validator may become one, provided it can deposit a sufficiently large stake (in TON coins, i.e., Grams; cf. Appendix A ) into the masterchain. Validators obtain some \u201crewards\u201d for good work, namely, the transaction, storage and gas fees from all transactions (messages) committed into newly generated blocks, and some newly minted coins, reflecting the \u201cgratitude\u201d of the whole community to the validators for keeping the TON Blockchain working. This income is distributed among all participating validators proportionally to their stakes. However, being a validator is a high responsibility. If a validator signs an invalid block, it can be punished by losing part or all of its stake, and by being temporarily or permanently excluded from the set of validators. If a validator does not participate in creating a block, it does not receive its share of the reward associated with that block. If a validator abstains from creating new blocks for a long time, it may lose part of its stake and be suspended or permanently excluded from the set of validators. All this means that the validator does not get its money \u201cfor nothing\u201d. Indeed, it must keep track of the states of all or some shardchains (each validator is responsible for validating and creating new blocks in a certain subset of shardchains), perform all computations requested by smart contracts in these shardchains, receive updates about other shardchains and so on. This activity requires considerable disk space, computing power and network bandwidth.","title":"2.6.1. Validators."},{"location":"TON Blockchain/TON Whitepaper/#262-validators-instead-of-miners","text":"Recall that the TON Blockchain uses the Proof-of-Stake approach, instead of the Proof-of-Work approach adopted by Bitcoin, the current version of Ethereum, and most other cryptocurrencies. This means that one cannot \u201cmine\u201d a new block by presenting some proof-ofwork (computing a lot of otherwise useless hashes) and obtain some new coins as a result. Instead, one must become a validator and spend one\u2019s computing resources to store and process TON Blockchain requests and data. In short, one must be a validator to mine new coins. In this respect, validators are the new miners. However, there are some other ways to earn coins apart from being a validator.","title":"2.6.2. Validators instead of miners."},{"location":"TON Blockchain/TON Whitepaper/#263-nominators-and-mining-pools","text":"To become a validator, one would normally need to buy and install several high-performance servers and acquire a good Internet connection for them. This is not so expensive as the ASIC equipment currently required to mine Bitcoins. However, one definitely cannot mine new TON coins on a home computer, let alone a smartphone. In the Bitcoin, Ethereum and other Proof-of-Work cryptocurrency mining communities there is a notion of mining pools, where a lot of nodes, having insufficient computing power to mine new blocks by themselves, combine their efforts and share the reward afterwards. A corresponding notion in the Proof-of-Stake world is that of a nominator. Essentially, this is a node lending its money to help a validator increase its stake; the validator then distributes the corresponding share of its reward (or some previously agreed fraction of it\u2014say, 50%) to the nominator. In this way, a nominator can also take part in the \u201cmining\u201d and obtain some reward proportional to the amount of money it is willing to deposit for this purpose. It receives only a fraction of the corresponding share of the validator\u2019s reward, because it provides only the \u201ccapital\u201d, but does not need to buy computing power, storage and network bandwidth. However, if the validator loses its stake because of invalid behavior, the nominator loses its share of the stake as well. In this sense the nominator shares the risk. It must choose its nominated validator wisely, otherwise it can lose money. In this sense, nominators make a weighted decision and \u201cvote\u201d for certain validators with their funds. On the other hand, this nominating or lending system enables one to become a validator without investing a large amount of money into Grams (TON coins) first. In other words, it prevents those keeping large amounts of Grams from monopolizing the supply of validators.","title":"2.6.3. Nominators and \u201cmining pools\u201d."},{"location":"TON Blockchain/TON Whitepaper/#264-fishermen-obtaining-money-by-pointing-out-others-mistakes","text":"Another way to obtain some rewards without being a validator is by becoming a fisherman. Essentially, any node can become a fisherman by making a small deposit in the masterchain. Then it can use special masterchain transactions to publish (Merkle) invalidity proofs of some (usually shardchain) blocks previously signed and published by validators. If other validators agree with this invalidity proof, the offending validators are punished (by losing part of their stake), and the fisherman obtains some reward (a fraction of coins confiscated from the offending validators). Afterwards, the invalid (shardchain) block must be corrected as outlined in 2.1.17 . Correcting invalid masterchain blocks may involve creating \u201cvertical\u201d blocks on top of previously committed masterchain blocks (cf. 2.1.17 ); there is no need to create a fork of the masterchain. Normally, a fisherman would need to become a full node for at least some shardchains, and spend some computing resources by running the code of at least some smart contracts. While a fisherman does not need to have as much computing power as a validator, we think that a natural candidate to become a fisherman is a would-be validator that is ready to process new blocks, but has not yet been elected as a validator (e.g., because of a failure to deposit a sufficiently large stake).","title":"2.6.4. Fishermen: obtaining money by pointing out others\u2019 mistakes."},{"location":"TON Blockchain/TON Whitepaper/#265-collators-obtaining-money-by-suggesting-new-blocks-to-validators","text":"Yet another way to obtain some rewards without being a validator is by becoming a collator . This is a node that prepares and suggests to a validator new shardchain block candidates, complemented (collated) with data taken from the state of this shardchain and from other (usually neighboring) shardchains, along with suitable Merkle proofs. (This is necessary, for example, when some messages need to be forwarded from neighboring shardchains.) Then a validator can easily check the proposed block candidate for validity, without having to download the complete state of this or other shardchains. Because a validator needs to submit new (collated) block candidates to obtain some (\u201cmining\u201d) rewards, it makes sense to pay some part of the reward to a collator willing to provide suitable block candidates. In this way, a validator may free itself from the necessity of watching the state of the neighboring shardchains, by outsourcing it to a collator. However, we expect that during the system\u2019s initial deployment phase there will be no separate designated collators, because all validators will be able to act as collators for themselves.","title":"2.6.5. Collators: obtaining money by suggesting new blocks to validators."},{"location":"TON Blockchain/TON Whitepaper/#266-collators-or-validators-obtaining-money-for-including-user-transactions","text":"Users can open micropayment channels to some collators or validators and pay small amounts of coins in exchange for the inclusion of their transactions in the shardchain","title":"2.6.6. Collators or validators: obtaining money for including user transactions."},{"location":"TON Blockchain/TON Whitepaper/#267-global-validator-set-election","text":"The \u201cglobal\u201d set of validators is elected once each month (actually, every 2^19 masterchain blocks). This set is determined and universally known one month in advance. In order to become a validator, a node must transfer some TON coins (Grams) into the masterchain, and then send them to a special smart contract as its suggested stake s. Another parameter, sent along with the stake, is l \u2265 1 , the maximum validating load this node is willing to accept relative to the minimal possible. There is also a global upper bound (another configurable parameter) L on l, equal to, say, 10. Then the global set of validators is elected by this smart contract, simply by selecting up to T candidates with maximal suggested stakes and publishing their identities. Originally, the total number of validators is T = 100; we expect it to grow to 1000 as the load increases. It is a configurable parameter (cf. 2.1.21 ). The actual stake of each validator is computed as follows: If the top T proposed stakes are s1 \u2265 s2 \u2265 \u00b7 \u00b7 \u00b7 \u2265 sT , the actual stake of i-th validator is set to s ' i := min(si , li \u00b7 sT ) . In this way, s'i /s'T \u2264 li , so the i-th validator does not obtain more than li \u2264 L times the load of the weakest validator (because the load is ultimately proportional to the stake). Then elected validators may withdraw the unused part of their stake, si\u2212s'i. Unsuccessful validator candidates may withdraw all of their proposed stake. Each validator publishes its public signing key, not necessarily equal to the public key of the account the stake came from.* \\The stakes of the validators are frozen until the end of the period for which they have been elected, and one month more, in case new disputes arise (i.e., an invalid block signed by one of these validators is found). After that, the stake is returned, along with the validator\u2019s share of coins minted and fees from transactions processed during this time. *It makes sense to generate and use a new key pair for every validator election.","title":"2.6.7. Global validator set election."},{"location":"TON Blockchain/TON Whitepaper/#268-election-of-validator-task-groups","text":"The whole global set of validators (where each validator is considered present with multiplicity equal to its stake\u2014otherwise a validator might be tempted to assume several identities and split its stake among them) is used only to validate new masterchain blocks. The shardchain blocks are validated only by specially selected subsets of validators, taken from the global set of validators chosen as described in 2.6.7 . These validator \u201csubsets\u201d or \u201ctask groups\u201d, defined for every shard, are rotated each hour (actually, every 2^10 masterchain blocks), and they are known one hour in advance, so that every validator knows which shards it will need to validate, and can prepare for that (e.g., by downloading missing shardchain data). The algorithm used to select validator task groups for each shard (w, s) is deterministic pseudorandom. It uses pseudorandom numbers embedded by validators into each masterchain block (generated by a consensus using threshold signatures) to create a random seed, and then computes for example Hash(code(w). code(s).validator_id.rand_seed) for each validator. Then validators are sorted by the value of this hash, and the first several are selected, so as to have at least 20/T of the total validator stakes and consist of at least 5 validators. This selection could be done by a special smart contract. In that case, the selection algorithm would easily be upgradable without hard forks by the voting mechanism mentioned in 2.1.21 . All other \u201cconstants\u201d mentioned so far (such as 2^19 , 2^10 , T, 20, and 5) are also configurable parameters.","title":"2.6.8. Election of validator \u201ctask groups\u201d."},{"location":"TON Blockchain/TON Whitepaper/#269-rotating-priority-order-on-each-task-group","text":"There is a certain \u201cpriority\u201d order imposed on the members of a shard task group, depending on the hash of the previous masterchain block and (shardchain) block sequence number. This order is determined by generating and sorting some hashes as described above. When a new shardchain block needs to be generated, the shard task group validator selected to create this block is normally the first one with respect to this rotating \u201cpriority\u201d order. If it fails to create the block, the second or third validator may do it. Essentially, all of them may suggest their block candidates, but the candidate suggested by the validator having the highest priority should win as the result of Byzantine Fault Tolerant (BFT) consensus protocol.","title":"2.6.9. Rotating priority order on each task group."},{"location":"TON Blockchain/TON Whitepaper/#2610-propagation-of-shardchain-block-candidates","text":"Because shardchain task group membership is known one hour in advance, their members can use that time to build a dedicated \u201cshard validators multicast overlay network\u201d, using the general mechanisms of the TON Network (cf. 3.3 ). When a new shardchain block needs to be generated\u2014normally one or two seconds after the most recent masterchain block has been propagated\u2014everybody knows who has the highest priority to generate the next block (cf. 2.6.9 ). This validator will create a new collated block candidate, either by itself or with the aid of a collator (cf. 2.6.5 ). The validator must check (validate) this block candidate (especially if it has been prepared by some collator) and sign it with its (validator) private key. Then the block candidate is propagated to the remainder of the task group using the prearranged multicast overlay network (the task group creates its own private overlay network as explained in 3.3 , and then uses a version of the streaming multicast protocol described in 3.3.15 to propagate block candidates). A truly BFT way of doing this would be to use a Byzantine multicast protocol, such as the one used in Honey Badger BFT [ 11 ]: encode the block candidate by an (N, 2N/3)-erasure code, send 1/N of the resulting data directly to each member of the group, and expect them to multicast directly their part of the data to all other members of the group. However, a faster and more straightforward way of doing this (cf. also 3.3.15 ) is to split the block candidate into a sequence of signed one-kilobyte blocks (\u201cchunks\u201d), augment their sequence by a Reed\u2013Solomon or a fountain code (such as the RaptorQ code [ 9 ] [ 14 ]), and start transmitting chunks to the neighbors in the \u201cmulticast mesh\u201d (i.e., the overlay network), expecting them to propagate these chunks further. Once a validator obtains enough chunks to reconstruct the block candidate from them, it signs a confirmation receipt and propagates it through its neighbors to the whole of the group. Then its neighbors stop sending new chunks to it, but may continue to send the (original) signatures of these chunks, believing that this node can generate the subsequent chunks by applying the Reed\u2013Solomon or fountain code by itself (having all data necessary), combine them with signatures, and propagate to its neighbors that are not yet ready. If the \u201cmulticast mesh\u201d (overlay network) remains connected after removing all \u201cbad\u201d nodes (recall that up to one-third of nodes are allowed to be bad in a Byzantine way, i.e., behave in arbitrary malicious fashion), this algorithm will propagate the block candidate as quickly as possible. Not only the designated high-priority block creator may multicast its block candidate to the whole of the group. The second and third validator by priority may start multicasting their block candidates, either immediately or after failing to receive a block candidate from the top priority validator. However, normally only the block candidate with maximal priority will be signed by all (actually, by at least two-thirds of the task group) validators and committed as a new shardchain block.","title":"2.6.10. Propagation of shardchain block candidates."},{"location":"TON Blockchain/TON Whitepaper/#2612-election-of-the-next-block-candidate","text":"Once a block candidate collects at least two-thirds (by stake) of the validity signatures of validators in the task group, it is eligible to be committed as the next shardchain block. A BFT protocol is run to achieve consensus on the block candidate chosen (there may be more than one proposed), with all \u201cgood\u201d validators preferring the block candidate with the highest priority for this round. As a result of running this protocol, the block is augmented by signatures of at least two-thirds of the validators (by stake). These signatures testify not only to the validity of the block in question, but also to its being elected by the BFT protocol. After that, the block (without collated data) is combined with these signatures, serialized in a deterministic way, and propagated through the network to all parties concerned.","title":"2.6.12. Election of the next block candidate."},{"location":"TON Blockchain/TON Whitepaper/#2615-generation-of-new-masterchain-blocks","text":"After all (or almost all) new shardchain blocks have been generated, a new masterchain block may be generated. The procedure is essentially the same as for shardchain blocks (cf. 2.6.12 ), with the difference that all validators (or at least two-thirds of them) must participate in this process. Because the headers and signatures of new shardchain blocks are propagated to all validators, hashes of the newest blocks in each shardchain can and must be included in the new masterchain block. Once these hashes are committed into the masterchain block, outside observers and other shardchains may consider the new shardchain blocks committed and immutable (cf. 2.1.13 ).","title":"2.6.15. Generation of new masterchain blocks."},{"location":"TON Blockchain/TON Whitepaper/#27-splitting-and-merging-shardchains","text":"","title":"2.7 Splitting and Merging Shardchains"},{"location":"TON Blockchain/TON Whitepaper/#276-determining-the-necessity-of-split-operations","text":"The split operation for a shardchain is triggered by certain formal conditions (e.g., if for 64 consecutive blocks the shardchain blocks are at least 90% full). These conditions are monitored by the shardchain task group. If they are met, first a \u201csplit preparation\u201d flag is included in the header of a new shardchain block (and propagated to the masterchain block referring to this shardchain block). Then, several blocks afterwards, the \u201csplit commit\u201d flag is included in the header of the shardchain block (and propagated to the next masterchain block).","title":"2.7.6. Determining the necessity of split operations."},{"location":"TON Blockchain/TON Whitepaper/#278-determining-the-necessity-of-merge-operations","text":"The necessity of shard merge operations is also detected by certain formal conditions (e.g., if for 64 consecutive blocks the sum of the sizes of the two blocks of sibling shardchains does not exceed 60% of maximal block size). These formal conditions should also take into account the total gas spent by these blocks and compare it to the current block gas limit, otherwise the blocks may happen to be small because there are some computation-intensive transactions that prevent the inclusion of more transactions. These conditions are monitored by validator task groups of both sibling shards (w, s.0) and (w, s.1). Notice that siblings are necessarily neighbors with respect to hypercube routing (cf. 2.4.19 ), so validators from the task group of any shard will be monitoring the sibling shard to some extent anyways. When these conditions are met, either one of the validator subgroups can suggest to the other that they merge by sending a special message. Then they combine into a provisional \u201cmerged task group\u201d, with combined membership, capable of running BFT consensus algorithms and of propagating block updates and block candidates if necessary. If they reach consensus on the necessity and readiness of merging, \u201cmerge prepare\u201d flags are committed into the headers of some blocks of each shardchain, along with the signatures of at least two-thirds of the validators of the sibling\u2019s task group (and are propagated to the next masterchain blocks, so that everybody can get ready for the imminent reconfiguration). However, they continue to create separate shardchain blocks for some predefined number of blocks.","title":"2.7.8. Determining the necessity of merge operations."},{"location":"TON Blockchain/TON Whitepaper/#28-classification-of-blockchain-projects","text":"","title":"2.8 Classification of Blockchain Projects"},{"location":"TON Blockchain/TON Whitepaper/#284-variants-of-proof-of-stake-dpos-vs-bft","text":"While Proof-of-Work algorithms are very similar to each other and differ mostly in the hash functions that must be computed for mining new blocks, there are more possibilities for Proof-of-Stake algorithms. They merit a sub-classification of their own. Essentially, one must answer the following questions about a Proof-ofStake algorithm: Who can produce (\u201cmine\u201d) a new block\u2014any full node, or only a member of a (relatively) small subset of validators? (Most PoS systems require new blocks to be generated and signed by one of several designated validators.) Do validators guarantee the validity of the blocks by their signatures, or are all full nodes expected to validate all blocks by themselves? (Scalable PoS systems must rely on validator signatures instead of requiring all nodes to validate all blocks of all blockchains.) Is there a designated producer for the next blockchain block, known in advance, such that nobody else can produce that block instead? Is a newly-created block originally signed by only one validator (its producer), or must it collect a majority of validator signatures from the very beginning? While there seem to be 2^4 possible classes of PoS algorithms depending on the answers to these questions, the distinction in practice boils down to two major approaches to PoS. In fact, most modern PoS algorithms, designed to be used in scalable multi-chain systems, answer the first two questions in the same fashion: only validators can produce new blocks, and they guarantee block validity without requiring all full nodes to check the validity of all blocks by themselves. As to the two last questions, their answers turn out to be highly correlated, leaving essentially only two basic options: Delegated Proof-of-Stake (DPOS): There is a universally known designated producer for every block; no one else can produce that block; the new block is originally signed only by its producing validator. Byzantine Fault Tolerant (BFT) PoS algorithms: There is a known subset of validators, any of which can suggest a new block; the choice of the actual next block among several suggested candidates, which must be validated and signed by a majority of validators before being released to the other nodes, is achieved by a version of Byzantine Fault Tolerant consensus protocol.","title":"2.8.4. Variants of Proof-of-Stake. DPOS vs. BFT."},{"location":"TON Blockchain/TON Whitepaper/#285-comparison-of-dpos-and-bft-pos","text":"The BFT approach has the advantage that a newly-produced block has from the very beginning the signatures of a majority of validators testifying to its validity. Another advantage is that, if a majority of validators executes the BFT consensus protocol correctly, no forks can appear at all. On the other hand, BFT algorithms tend to be quite convoluted and require more time for the subset of validators to reach consensus. Therefore, blocks cannot be generated too often. This is why we expect the TON Blockchain (which is a BFT project from the perspective of this classification) to produce a block only once every five seconds. In practice, this interval might be decreased to 2\u20133 seconds (though we do not promise this), but not further, if validators are spread across the globe. The DPOS algorithm has the advantage of being quite simple and straightforward. It can generate new blocks quite often\u2014say, once every two seconds, or maybe even once every second,* because of its reliance on designated block producers known in advance. However, DPOS requires all nodes\u2014or at least all validators\u2014to validate all blocks received, because a validator producing and signing a new block confirms not only the relative validity of this block, but also the validity of the previous block it refers to, and all the blocks further back in the chain (maybe up to the beginning of the period of responsibility of the current subset of validators). There is a predetermined order on the current subset of validators, so that for each block there is a designated producer (i.e., validator expected to generate that block); these designated producers are rotated in a round-robin fashion. In this way, a block is at first signed only by its producing validator; then, when the next block is mined, and its producer chooses to refer to this block and not to one of its predecessors (otherwise its block would lie in a shorter chain, which might lose the \u201clongest fork\u201d competition in the future), the signature of the next block is essentially an additional signature on the previous block as well. In this way, a new block gradually collects the signatures of more validators\u2014say, twenty signatures in the time needed to generate the next twenty blocks. A full node will either need to wait for these twenty signatures, or validate the block by itself, starting from a sufficiently confirmed block (say, twenty blocks back), which might be not so easy. The obvious disadvantage of the DPOS algorithm is that a new block (and transactions committed into it) achieves the same level of trust (\u201crecursive reliability\u201d as discussed in 2.6.28) only after twenty more blocks are mined, compared to the BFT algorithms, which deliver this level of trust (say, twenty signatures) immediately. Another disadvantage is that DPOS uses the \u201clongest fork wins\u201d approach for switching to other forks; this makes forks quite probable if at least some producers fail to produce subsequent blocks after the one we are interested in (or we fail to observe these blocks because of a network partition or a sophisticated attack). We believe that the BFT approach, while more sophisticated to implement and requiring longer time intervals between blocks than DPOS, is better adapted to \u201ctightly-coupled\u201d (cf. 2.8.14) multichain systems, because other blockchains can start acting almost immediately after seeing a committed transaction (e.g., generating a message intended for them) in a new block, without waiting for twenty confirmations of validity (i.e., the next twenty blocks), or waiting for the next six blocks to be sure that no forks appear and verifying the new block by themselves (verifying blocks of other blockchains may become prohibitive in a scalable multi-chain system). Thus they can achieve scalability while preserving high reliability and availability (cf. 2.8.12 ). On the other hand, DPOS might be a good choice for a \u201cloosely-coupled\u201d multi-chain system, where fast interaction between blockchains is not required \u2013 e.g., if each blockchain (\u201cworkchain\u201d) represents a separate distributed exchange, and inter-blockchain interaction is limited to rare transfers of tokens from one workchain into another (or, rather, trading one altcoin residing in one workchain for another at a rate approaching 1 : 1). This is what is actually done in the BitShares project, which uses DPOS quite successfully. To summarize, while DPOS can generate new blocks and include transactions into them faster (with smaller intervals between blocks), these transactions reach the level of trust required to use them in other blockchains and off-chain applications as \u201ccommitted\u201d and \u201cimmutable\u201d much more slowly than in the BFT systems\u2014say, in thirty seconds** instead of five. Faster transaction inclusion does not mean faster transaction commitment. This could become a huge problem if fast inter-blockchain interaction is required. In that case, one must abandon DPOS and opt for BFT PoS instead. *Some people even claim DPOS block generation times of half a second, which does not seem realistic if validators are scattered across several continents. **For instance, EOS, one of the best DPOS projects proposed up to this date, promises a 45-second confirmation and inter-blockchain interaction delay (cf. [ 5 ], \u201cTransaction Confirmation\u201d and \u201cLatency of Interchain Communication\u201d sections).","title":"2.8.5. Comparison of DPOS and BFT PoS."},{"location":"TON Blockchain/TON Whitepaper/#288-blockchain-types-homogeneous-and-heterogeneous-systems","text":"In a multi-chain system, all blockchains may be essentially of the same type and have the same rules (i.e., use the same format of transactions, the same virtual machine for executing smart-contract code, share the same cryptocurrency, and so on), and this similarity is explicitly exploited, but with different data in each blockchain. In this case, we say that the system is homogeneous . Otherwise, different blockchains (which will usually be called workchains inthis case) can have different \u201crules\u201d. Then we say that the system is heterogeneous .","title":"2.8.8. Blockchain types: homogeneous and heterogeneous systems."},{"location":"TON Blockchain/TON Whitepaper/#2810-heterogeneous-systems-with-several-workchains-having-the-same-rules-or-confederations","text":"In some cases, several blockchains (workchains) with the same rules can be present in a heterogeneous system, but the interaction between them is the same as between blockchains with different rules (i.e., their similarity is not exploited explicitly). Even if they appear to use \u201cthe same\u201d cryptocurrency, they in fact use different \u201caltcoins\u201d (independent incarnations of the cryptocurrency). Sometimes one can even have certain mechanisms to convert these altcoins at a rate near to 1 : 1. However, this does not make the system homogeneous in our view; it remains heterogeneous. We say that such a heterogeneous collection of workchains with the same rules is a confederation . While making a heterogeneous system that allows one to create several workchains with the same rules (i.e., a confederation) may seem a cheap way of building a scalable system, this approach has a lot of drawbacks, too. Essentially, if someone hosts a large project in many workchains with the same rules, she does not obtain a large project, but rather a lot of small instances of this project. This is like having a chat application (or a game) that allows having at most 50 members in any chat (or game) room, but \u201cscales\u201d by creating new rooms to accommodate more users when necessary. As a result, a lot of users can participate in the chats or in the game, but can we say that such a system is truly scalable?","title":"2.8.10. Heterogeneous systems with several workchains having the same rules, or confederations."},{"location":"TON Blockchain/TON Whitepaper/#2812-sharding-support","text":"Some blockchain projects (or systems) have native support for sharding, meaning that several (necessarily homogeneous; cf. 2.8.8 ) blockchains are thought of as shards of a single (from a high-level perspective) virtual blockchain. For example, one can create 256 shard blockchains (\u201cshardchains\u201d) with the same rules, and keep the state of an account in exactly one shard selected depending on the first byte of its account_id. Sharding is a natural approach to scaling blockchain systems, because, if it is properly implemented, users and smart contracts in the system need not be aware of the existence of sharding at all. In fact, one often wants to add sharding to an existing single-chain project (such as Ethereum) when the load becomes too high. An alternative approach to scaling would be to use a \u201cconfederation\u201d of heterogeneous workchains as described in 2.8.10 , allowing each user to keep her account in one or several workchains of her choice, and transfer funds from her account in one workchain to another workchain when necessary, essentially performing a 1 : 1 altcoin exchange operation. The drawbacks of this approach have already been discussed in 2.8.10 . However, sharding is not so easy to implement in a fast and reliable fashion, because it implies a lot of messages between different shardchains. For example, if accounts are evenly distributed between N shards, and the only transactions are simple fund transfers from one account to another, then only a small fraction (1/N) of all transactions will be performed within a single blockchain; almost all (1 \u2212 1/N) transactions will involve two blockchains, requiring inter-blockchain communication. If we want these transactions to be fast, we need a fast system for transferring messages between shardchains. In other words, the blockchain project needs to be \u201ctightly-coupled\u201d in the sense described in 2.8.14 .","title":"2.8.12. Sharding support."},{"location":"TON Blockchain/TON Whitepaper/#2813-dynamic-and-static-sharding","text":"Sharding might be dynamic (if additional shards are automatically created when necessary) or static (when there is a predefined number of shards, which is changeable only through a hard fork at best). Most sharding proposals are static; the TON Blockchain uses dynamic sharding (cf. 2.7 ).","title":"2.8.13. Dynamic and static sharding."},{"location":"TON Blockchain/TON Whitepaper/#2814-interaction-between-blockchains-loosely-coupled-and-tightly-coupled-systems","text":"Multi-blockchain projects can be classified according to the supported level of interaction between the constituent blockchains. The least level of support is the absence of any interaction between different blockchains whatsoever. We do not consider this case here, because we would rather say that these blockchains are not parts of one blockchain system, but just separate instances of the same blockchain protocol. The next level of support is the absence of any specific support for messaging between blockchains, making interaction possible in principle, but awkward. We call such systems \u201cloosely-coupled\u201d; in them one must send messages and transfer value between blockchains as if they had been blockchains belonging to completely separate blockchain projects (e.g., Bitcoin and Ethereum; imagine two parties want to exchange some Bitcoins, kept in the Bitcoin blockchain, into Ethers, kept in the Ethereum blockchain). In other words, one must include the outbound message (or its generating transaction) in a block of the source blockchain. Then she (or some other party) must wait for enough confirmations (e.g., a given number of subsequent blocks) to consider the originating transaction to be \u201ccommitted\u201d and \u201cimmutable\u201d, so as to be able to perform external actions based on its existence. Only then may a transaction relaying the message into the target blockchain (perhaps along with a reference and a Merkle proof of existence for the originating transaction) be committed. If one does not wait long enough before transferring the message, or if a fork happens anyway for some other reason, the joined state of the two blockchains turns out to be inconsistent: a message is delivered into the second blockchain that has never been generated in (the ultimately chosen fork of) the first blockchain. Sometimes partial support for messaging is added, by standardizing the format of messages and the location of input and output message queues in the blocks of all workchains (this is especially useful in heterogeneous systems). While this facilitates messaging to a certain extent, it is conceptually not too different from the previous case, so such systems are still \u201cloosely-coupled\u201d. By contrast, \u201ctightly-coupled\u201d systems include special mechanisms to provide fast messaging between all blockchains. The desired behavior is to be able to deliver a message into another workchain immediately after it has been generated in a block of the originating blockchain. On the other hand, \u201ctightly-coupled\u201d systems are also expected to maintain overall consistency in the case of forks. While these two requirements appear to be contradictory at first glance, we believe that the mechanisms used by the TON Blockchain (the inclusion of shardchain block hashes into masterchain blocks; the use of \u201cvertical\u201d blockchains for fixing invalid blocks, cf. 2.1.17 ; hypercube routing, cf. 2.4.19 ; Instant Hypercube Routing, cf. 2.4.20 ) enable it to be a \u201ctightly-coupled\u201d system, perhaps the only one so far. Of course, building a \u201cloosely-coupled\u201d system is much simpler; however, fast and efficient sharding (cf. 2.8.12 ) requires the system to be \u201ctightlycoupled\u201d.","title":"2.8.14. Interaction between blockchains: loosely-coupled and tightly-coupled systems."},{"location":"TON Blockchain/TON Whitepaper/#2816-complications-of-changing-the-genome-of-a-blockchain-project","text":"The above classification defines the \u201cgenome\u201d of a blockchain project. This genome is quite \u201crigid\u201d: it is almost impossible to change it once the project is deployed and is used by a lot of people. One would need a series of hard forks (which would require the approval of the majority of the community), and even then the changes would need to be very conservative in order to preserve backward compatibility (e.g., changing the semantics of the virtual machine might break existing smart contracts). An alternative would be to create new \u201csidechains\u201d with their different rules, and bind them somehow to the blockchain (or the blockchains) of the original project. One might use the blockchain of the existing single-blockchain project as an external masterchain for an essentially new and separate project. Our conclusion is that the genome of a project is very hard to change once it has been deployed. Even starting with PoW and planning to replace it with PoS in the future is quite complicated. Adding shards to a project originally designed without support for them seems almost impossible. In fact, adding support for smart contracts into a project (namely, Bitcoin) originally designed without support for such features has been deemed impossible (or at least undesirable by the majority of the Bitcoin community) and eventually led to the creation of a new blockchain project, Ethereum. *For example, the Plasma project plans to use the Ethereum blockchain as its (external) masterchain; it does not interact much with Ethereum otherwise, and it could have been suggested and implemented by a team unrelated to the Ethereum project. **As of 2017, Ethereum is still struggling to transition from PoW to a combined PoW+PoS system; we hope it will become a truly PoS system someday. ***There are sharding proposals for Ethereum dating back to 2015; it is unclear how they might be implemented and deployed without disrupting Ethereum or creating an essentially independent parallel project.","title":"2.8.16. Complications of changing the \u201cgenome\u201d of a blockchain project."},{"location":"TON Blockchain/TON Whitepaper/#29-comparsion-with-other-blockchain-projects","text":"","title":"2.9 Comparsion with other blockchain projects"},{"location":"TON Blockchain/TON Whitepaper/#297-eos-5httpseosio","text":"EOS (2018 or later) is a proposed heterogeneous multi-blockchain DPoS system with smart contract support and with some minimal support for messaging (still loosely-coupled in the sense described in 2.8.14). It is an attempt by the same team that has previously successfully created the BitShares and SteemIt projects, demonstrating the strong points of the DPoS consensus algorithm. Scalability will be achieved by creating specialized workchains for projects that need it (e.g., a distributed exchange might use a workchain supporting a special set of optimized transactions, similarly to what BitShares did) and by creating multiple workchains with the same rules (confederations in the sense described in 2.8.10). The drawbacks and limitations of this approach to scalability have been discussed in loc. cit. Cf. also 2.8.5, 2.8.12, and 2.8.14 for a more detailed discussion of DPoS, sharding, interaction between workchains and their implications for the scalability of a blockchain system. At the same time, even if one will not be able to \u201ccreate a Facebook inside a blockchain\u201d (cf. 2.9.13), EOS or otherwise, we think that EOS might become a convenient platform for some highly-specialized weakly interacting distributed applications, similar to BitShares (decentralized exchange) and SteemIt (decentralized blog platform).","title":"2.9.7. EOS [5];https://eos.io."},{"location":"TON Blockchain/TON Whitepaper/#298-polkadot-17-httpspolkadotio","text":"PolkaDot (2019 or later) is one of the best thought-out and most detailed proposed multichain Proofof-Stake projects; its development is led by one of the Ethereum co-founders. This project is one of the closest projects to the TON Blockchain on our map. (In fact, we are indebted for our terminology for \u201cfishermen\u201d and \u201cnominators\u201d to the PolkaDot project.) PolkaDot is a heterogeneous loosely-coupled multichain Proof-of-Stake project, with Byzantine Fault Tolerant (BFT) consensus for generation of new blocks and a masterchain (which might be external\u2014e.g., the Ethereum blockchain). It also uses hypercube routing, somewhat like (the slow version of) TON\u2019s as described in 2.4.19 . Its unique feature is its ability to create not only public, but also private blockchains. These private blockchains would also be able to interact with other public blockchains, PolkaDot or otherwise. As such, PolkaDot might become a platform for large-scale private blockchains, which might be used, for example, by bank consortiums to quickly transfer funds to each other, or for any other uses a large corporation might have for private blockchain technology. However, PolkaDot has no sharding support and is not tightly-coupled. This somewhat hampers its scalability, which is similar to that of EOS. (Perhaps a bit better, because PolkaDot uses BFT PoS instead of DPoS.)","title":"2.9.8. PolkaDot [17]; https://polkadot.io/."},{"location":"TON Blockchain/TON Whitepaper/#2913-is-it-possible-to-upload-facebook-into-a-blockchain","text":"Sometimes people claim that it will be possible to implement a social network on the scale of Facebook as a distributed application residing in a blockchain. Usually a favorite blockchain project is cited as a possible \u201chost\u201d for such an application. We cannot say that this is a technical impossibility. Of course, one needs a tightly-coupled blockchain project with true sharding (i.e., TON) in order for such a large application not to work too slowly (e.g., deliver messages and updates from users residing in one shardchain to their friends residing in another shardchain with reasonable delays). However, we think that this is not needed and will never be done, because the price would be prohibitive. Let us consider \u201cuploading Facebook into a blockchain\u201d as a thought experiment; any other project of similar scale might serve as an example as well. Once Facebook is uploaded into a blockchain, all operations currently done by Facebook\u2019s servers will be serialized as transactions in certain blockchains (e.g., TON\u2019s shardchains), and will be performed by all validators of these blockchains. Each operation will have to be performed, say, at least twenty times, if we expect every block to collect at least twenty validator signatures (immediately or eventually, as in DPOS systems). Similarly, all data kept by Facebook\u2019s servers on their disks will be kept on the disks of all validators for the corresponding shardchain (i.e., in at least twenty copies). Because the validators are essentially the same servers (or perhaps clusters of servers, but this does not affect the validity of this argument) as those currently used by Facebook, we see that the total hardware expenses associated with running Facebook in a blockchain are at least twenty times higher than if it were implemented in the conventional way. In fact, the expenses would be much higher still, because the blockchain\u2019s virtual machine is slower than the \u201cbare CPU\u201d running optimized compiled code, and its storage is not optimized for Facebook-specific problems. One might partially mitigate this problem by crafting a specific workchain with some special transactions adapted for Facebook; this is the approach of BitShares and EOS to achieving high performance, available in the TON Blockchain as well. However, the general blockchain design would still impose some additional restrictions by itself, such as the necessity to register all operations as transactions in a block, to organize these transactions in a Merkle tree, to compute and check their Merkle hashes, to propagate this block further, and so on. Therefore, a conservative estimate is that one would need 100 times more servers of the same performance as those used by Facebook now in order to validate a blockchain project hosting a social network of that scale. Somebody will have to pay for these servers, either the company owning the distributed application (imagine seeing 700 ads on each Facebook page instead of 7) or its users. Either way, this does not seem economically viable. We believe that it is not true that everything should be uploaded into the blockchain. For example, it is not necessary to keep user photographs in the blockchain; registering the hashes of these photographs in the blockchain and keeping the photographs in a distributed off-chain storage (such as FileCoin or TON Storage) would be a better idea. This is the reason why TON is not just a blockchain project, but a collection of several components (TON P2P Network, TON Storage, TON Services) centered around the TON Blockchain as outlined in Chapters 1 and 4 . \\3. TON Networking Under construction. First we add chapters we have to refer to from our product docs. Any blockchain project requires not only a specification of block format and blockchain validation rules, but also a network protocol used to propagate new blocks, send and collect transaction candidates and so on. In other words, a specialized peer-to-peer network must be set up by every blockchain project. This network must be peer-to-peer, because blockchain projects are normally expected to be decentralized, so one cannot rely on a centralized group of servers and use conventional client-server architecture, as, for instance, classical online banking applications do. Even light clients (e.g., light cryptocurrency wallet smartphone applications), which must connect to full nodes in a client-server\u2013like fashion, are actually free to connect to another full node if their previous peer goes down, provided the protocol used to connect to full nodes is standardized enough. While the networking demands of single-blockchain projects, such as Bitcoin or Ethereum, can be met quite easily (one essentially needs to construct a \u201crandom\u201d peer-to-peer overlay network, and propagate all new blocks and transaction candidates by a gossip protocol), multi-blockchain projects, such as the TON Blockchain, are much more demanding (e.g., one must be able to subscribe to updates of only some shardchains, not necessarily all of them). Therefore, the networking part of the TON Blockchain and the TON Project as a whole merits at least a brief discussion. On the other hand, once the more sophisticated network protocols needed to support the TON Blockchain are in place, it turns out that they can easily be used for purposes not necessarily related to the immediate demands of the TON Blockchain, thus providing more possibilities and flexibility for creating new services in the TON ecosystem.","title":"2.9.13. Is it possible to \u201cupload Facebook into a blockchain\u201d?"},{"location":"TON Blockchain/TON Whitepaper/#ton-networking","text":"","title":"TON Networking"},{"location":"TON Blockchain/TON Whitepaper/#31-abstract-datagram-network-layer","text":"The cornerstone in building the TON networking protocols is the (TON) Abstract (Datagram) Network Layer. It enables all nodes to assume certain \u201cnetwork identities\u201d, represented by 256-bit \u201cabstract network addresses\u201d, and communicate (send datagrams to each other, as a first step) using only these 256-bit network addresses to identify the sender and the receiver. In particular, one does not need to worry about IPv4 or IPv6 addresses, UDP port numbers, and the like; they are hidden by the Abstract Network Layer.","title":"3.1 Abstract Datagram Network Layer"},{"location":"TON Blockchain/TON Whitepaper/#311-abstract-network-addresses","text":"An abstract network address, or an abstract address, or just address for short, is a 256-bit integer, essentially equal to a 256-bit ECC public key. This public key can be generated arbitrarily, thus creating as many different network identities as the node likes. However, one must know the corresponding private key in order to receive (and decrypt) messages intended for such an address. In fact, the address is not the public key itself; instead, it is a 256-bit hash (Hash = sha256) of a serialized TL-object (cf. 2.2.5 ) that can describe several types of public keys and addresses depending on its constructor (first four bytes). In the simplest case, this serialized TL-object consists just of a 4-byte magic number and a 256-bit elliptic curve cryptography (ECC) public key; in this case, the address will equal the hash of this 36-byte structure. One might use, however, 2048-bit RSA keys, or any other scheme of publickey cryptography instead. When a node learns another node\u2019s abstract address, it must also receive its \u201cpreimage\u201d (i.e., the serialized TL-object, the hash of which equals that abstract address) or else it will not be able to encrypt and send datagrams to that address.","title":"3.1.1. Abstract network addresses."},{"location":"TON Blockchain/TON Whitepaper/#312-lower-level-networks","text":"UDP implementation. From the perspective of almost all TON Networking components, the only thing that exists is a network (the Abstract Datagram Networking Layer) able to (unreliably) send datagrams from one abstract address to another. In principle, the Abstract Datagram Networking Layer (ADNL) can be implemented over different existing network technologies. However, we are going to implement it over UDP in IPv4/IPv6 networks (such as the Internet or intranets), with an optional TCP fallback if UDP is not available.","title":"3.1.2. Lower-level networks."},{"location":"TON Blockchain/TON Whitepaper/#313-simplest-case-of-adnl-over-udp","text":"The simplest case of sending a datagram from a sender\u2019s abstract address to any other abstract address (with known preimage) can be implemented as follows. Suppose that the sender somehow knows the IP-address and the UDP port of the receiver who owns the destination abstract address, and that both the receiver and the sender use abstract addresses derived from 256-bit ECC public keys. In this case, the sender simply augments the datagram to be sent by its ECC signature (done with its private key) and its source address (or the preimage of the source address, if the receiver is not known to know that preimage yet). The result is encrypted with the recipient\u2019s public key, embedded into a UDP datagram and sent to the known IP and port of the recipient. Because the first 256 bits of the UDP datagram contain the recipient\u2019s abstract address, the recipient can identify which private key should be used to decrypt the remainder of the datagram. Only after that is the sender\u2019s identity revealed.","title":"3.1.3. Simplest case of ADNL over UDP."},{"location":"TON Blockchain/TON Whitepaper/#314-less-secure-way-with-the-senders-address-in-plaintext","text":"Sometimes a less secure scheme is sufficient, when the recipient\u2019s and the sender\u2019s addresses are kept in plaintext in the UDP datagram; the sender\u2019s private key and the recipient\u2019s public key are combined together using ECDH (Elliptic Curve Diffie\u2013Hellman) to generate a 256-bit shared secret, which is used afterwards, along with a random 256-bit nonce also included in the unencrypted part, to derive AES keys used for encryption. The integrity may be provided, for instance, by concatenating the hash of the original plaintext data to the plaintext before encryption. This approach has the advantage that, if more than one datagram is expected to be exchanged between the two addresses, the shared secret can be computed only once and then cached; then slower elliptic curve operations will no longer be required for encrypting or decrypting the next datagrams.","title":"3.1.4. Less secure way, with the sender\u2019s address in plaintext."},{"location":"TON Blockchain/TON Whitepaper/#315-channels-and-channel-identifiers","text":"In the simplest case, the first 256 bits of a UDP datagram carrying an embedded TON ADNL datagram will be equal to the recipient\u2019s address. However, in general they constitute a channel identifier. There are different types of channels. Some of them are point-to-point; they are created by two parties who wish to exchange a lot of data in the future and generate a shared secret by exchanging several packets encrypted as described in 3.1.3 or 3.1.4 , by running classical or elliptic curve Diffie\u2013Hellman (if extra security is required), or simply by one party generating a random shared secret and sending it to the other party. After that, a channel identifier is derived from the shared secret combined with some additional data (such as the sender\u2019s and recipient\u2019s addresses), for instance by hashing, and that identifier is used as the first 256 bits of UDP datagrams carrying data encrypted with the aid of that shared secret.","title":"3.1.5. Channels and channel identifiers."},{"location":"TON Blockchain/TON Whitepaper/#316-channel-as-a-tunnel-identifier","text":"In general, a \u201cchannel\u201d, or \u201cchannel identifier\u201d simply selects a way of processing an inbound UDP datagram, known to the receiver. If the channel is the receiver\u2019s abstract address, the processing is done as outlined in 3.1.3 or 3.1.4 ; if the channel is an estabished point-to-point channel discussed in 3.1.5 , the processing consists in decrypting the datagram with the aid of the shared secret as explained in loc. cit., and so on. In particular, a channel identifier can actually select a \u201ctunnel\u201d, when the immediate recipient simply forwards the received message to somebody else\u2014the actual recipient or another proxy. Some encryption or decryption steps (reminiscent of \u201conion routing\u201d [ 6 ] or even \u201cgarlic routing\u201d *) might be done along the way, and another channel identifier might be used for reencrypted forwarded packets (for example, a peer-to-peer channel could be employed to forward the packet to the next recipient on the path). In this way, some support for \u201ctunneling\u201d and \u201cproxying\u201d\u2014somewhat similar to that provided by the TOR or I2P projects\u2014can be added on the level of the TON Abstract Datagram Network Layer, without affecting the functionality of all higher-level TON network protocols, which would be agnostic of such an addition. This opportunity is exploited by the TON Proxy service (cf. 4.1.11 ). * https://geti2p.net/en/docs/how/garlic-routing","title":"3.1.6. Channel as a tunnel identifier."},{"location":"TON Blockchain/TON Whitepaper/#317-zero-channel-and-the-bootstrap-problem","text":"Normally, a TON ADNL node will have some \u201cneighbor table\u201d, containing information about other known nodes, such as their abstract addresses and their preimages (i.e., public keys) and their IP addresses and UDP ports. Then it will gradually extend this table by using information learned from these known nodes as answers to special queries, and sometimes prune obsolete records. However, when a TON ADNL node just starts up, it may happen that it does not know any other node, and can learn only the IP address and UDP port of a node, but not its abstract address. This happens, for example, if a light client is not able to access any of the previously cached nodes and any nodes hardcoded into the software, and must ask the user to enter an IP address or a DNS domain of a node, to be resolved through DNS. In this case, the node will send packets to a special \u201czero channel\u201d of the node in question. This does not require knowledge of the recipient\u2019s public key (but the message should still contain the sender\u2019s identity and signature), so the message is transferred without encryption. It should be normally used only to obtain an identity (maybe a one-time identity created especially for this purpose) of the receiver, and then to start communicating in a safer way. Once at least one node is known, it is easy to populate the \u201cneighbor table\u201d and \u201crouting table\u201d by more entries, learning them from answers to special queries sent to the already known nodes. Not all nodes are required to process datagrams sent to the zero channel, but those used to bootstrap light clients should support this feature.","title":"3.1.7. Zero channel and the bootstrap problem."},{"location":"TON Blockchain/TON Whitepaper/#318-tcp-like-stream-protocol-over-adnl","text":"The ADNL, being an unreliable (small-size) datagram protocol based on 256-bit abstract addresses, can be used as a base for more sophisticated network protocols. One can build, for example, a TCP-like stream protocol, using ADNL as an abstract replacement for IP. However, most components of the TON Project do not need such a stream protocol.","title":"3.1.8. TCP-like stream protocol over ADNL."},{"location":"TON Blockchain/TON Whitepaper/#319-rldp-or-reliable-large-datagram-protocol-over-adnl","text":"A reliable arbitrary-size datagram protocol built upon the ADNL, called RLDP, is used instead of a TCP-like protocol. This reliable datagram protocol can be employed, for instance, to send RPC queries to remote hosts and receive answers from them (cf. 4.1.5 ).","title":"3.1.9. RLDP, or Reliable Large Datagram Protocol over ADNL."},{"location":"TON Blockchain/TON Whitepaper/#32-ton-dht-kademlia-like-distributed-hash-table","text":"The TON Distributed Hash Table (DHT) plays a crucial role in the networking part of the TON Project, being used to locate other nodes in the network. For example, a client wanting to commit a transaction into a shardchain might want to find a validator or a collator of that shardchain, or at least some node that might relay the client\u2019s transaction to a collator. This can be done by looking up a special key in the TON DHT. Another important application of the TON DHT is that it can be used to quickly populate a new node\u2019s neighbor table (cf. 3.1.7 ), simply by looking up a random key, or the new node\u2019s address. If a node uses proxying and tunneling for its inbound datagrams, it publishes the tunnel identifier and its entry point (e.g., IP address and UDP port) in the TON DHT; then all nodes wishing to send datagrams to that node will obtain this contact information from the DHT first. The TON DHT is a member of the family of Kademlia-like distributed hash tables [ 10 ].","title":"3.2 TON DHT: Kademlia-like Distributed Hash Table"},{"location":"TON Blockchain/TON Whitepaper/#3210-distributed-torrent-trackers-and-network-interest-groups-in-ton-dht","text":"Yet another interesting case is when the value contains a list of nodes\u2014perhaps with their IP addresses and ports, or just with their abstract addresses\u2014and the \u201cupdate rule\u201d consists in including the requester in this list, provided she can confirm her identity. This mechanism might be used to create a distributed \u201ctorrent tracker\u201d, where all nodes interested in a certain \u201ctorrent\u201d (i.e., a certain file) can find other nodes that are interested in the same torrent, or already have a copy. TON Storage (cf. 4.1.8 ) uses this technology to find the nodes that have a copy of a required file (e.g., a snapshot of the state of a shardchain, or an old block). However, its more important use is to create \u201coverlay multicast subnetworks\u201d and \u201cnetwork interest groups\u201d (cf. 3.3 ). The idea is that only some nodes are interested in the updates of a specific shardchain. If the number of shardchains becomes very large, finding even one node interested in the same shard may become complicated. This \u201cdistributed torrent tracker\u201d provides a convenient way to find some of these nodes. Another option would be to request them from a validator, but this would not be a scalable approach, and validators might choose not to respond to such queries coming from arbitrary unknown nodes.","title":"3.2.10. Distributed \u201ctorrent trackers\u201d and \u201cnetwork interest groups\u201d in TON DHT."},{"location":"TON Blockchain/TON Whitepaper/#3212-locating-services","text":"Some services, located in the TON Network and available through the (higher-level protocols built upon the) TON ADNL described in 3.1 , may want to publish their abstract addresses somewhere, so that their clients would know where to find them. However, publishing the service\u2019s abstract address in the TON Blockchain may not be the best approach, because the abstract address might need to be changed quite often, and because it could make sense to provide several addresses, for reliability or load balancing purposes. An alternative is to publish a public key into the TON Blockchain, and use a special DHT key indicating that public key as its \u201cowner\u201d in the TL description string (cf. 2.2.5 ) to publish an up-to-date list of the service\u2019s abstract addresses. This is one of the approaches exploited by TON Services.","title":"3.2.12. Locating services."},{"location":"TON Blockchain/TON Whitepaper/#3214-locating-abstract-addresses","text":"Notice that the TON DHT, while being implemented over TON ADNL, is itself used by the TON ADNL for several purposes. The most important of them is to locate a node or its contact data starting from its 256-bit abstract address. This is necessary because the TON ADNL should be able to send datagrams to arbitrary 256-bit abstract addresses, even if no additional information is provided. To this end, the 256-bit abstract address is simply looked up as a key in the DHT. Either a node with this address (i.e., using this address as a public semi-persistent DHT address) is found, in which case its IP address and port can be learned; or, an input tunnel description may be retrieved as the value of the key in question, signed by the correct private key, in which case this tunnel description would be used to send ADNL datagrams to the intended recipient. Notice that in order to make an abstract address \u201cpublic\u201d (reachable from any nodes in the network), its owner must either use it as a semi-permanent DHT address, or publish (in the DHT key equal to the abstract address under consideration) an input tunnel description with another of its public abstract addresses (e.g., the semi-permanent address) as the tunnel\u2019s entry point. Another option would be to simply publish its IP address and UDP port.","title":"3.2.14. Locating abstract addresses."},{"location":"TON Blockchain/TON Whitepaper/#33-overlay-networks-and-multicasting","text":"Messages In a multi-blockchain system like the TON Blockchain, even full nodes would normally be interested in obtaining updates (i.e., new blocks) only about some shardchains. To this end, a special overlay (sub)network must be built inside the TON Network, on top of the ADNL protocol discussed in 3.1 , one for each shardchain. Therefore, the need to build arbitrary overlay subnetworks, open to any nodes willing to participate, arises. Special gossip protocols, built upon ADNL, will be run in these overlay networks. In particular, these gossip protocols may be used to propagate (broadcast) arbitrary data inside such a subnetwork.","title":"3.3 Overlay Networks and Multicasting"},{"location":"TON Blockchain/TON Whitepaper/#3310-ton-overlay-networks-are-optimized-for-lower-latency","text":"TON overlay networks optimize the \u201crandom\u201d network graph generated by the previous method as follows. Every node tries to retain at least three neighbors with the minimal round-trip time, changing this list of \u201cfast neighbors\u201d very rarely. At the same time, it also has at least three other \u201cslow neighbors\u201d that are chosen completely randomly, so that the overlay network graph would always contain a random subgraph. This is required to maintain connectivity and prevent splitting of the overlay network into several unconnected regional subnetworks. At least three \u201cintermediate neighbors\u201d, which have intermediate round-trip times, bounded by a certain constant (actually, a function of the round-trip times of the fast and the slow neighbors), are also chosen and retained. In this way, the graph of an overlay network still maintains enough randomness to be connected, but is optimized for lower latency and higher throughput.","title":"3.3.10. TON overlay networks are optimized for lower latency."},{"location":"TON Blockchain/TON Whitepaper/#3315-streaming-broadcast-protocol","text":"Finally, there is a streaming broadcast protocol for TON overlay networks, used, for example, to propagate block candidates among validators of some shardchain (\u201cshardchain task group\u201d), who, of course, create a private overlay network for that purpose. The same protocol can be used to propagate new shardchain blocks to all full nodes for that shardchain. This protocol has already been outlined in 2.6.10 : the new (large) broadcast message is split into, say, N one-kilobyte chunks; the sequence of these chunks is augmented to M \u2265 N chunks by means of an erasure code such as the Reed\u2013Solomon or a fountain code (e.g., the RaptorQ code [ 9 ] [ 14 ]), and these M chunks are streamed to all neighbors in ascending chunk number order. The participating nodes collect these chunks until they can recover the original large message (one would have to successfully receive at least N of the chunks for this), and then instruct their neighbors to stop sending new chunks of the stream, because now these nodes can generate the subsequent chunks on their own, having a copy of the original message. Such nodes continue to generate the subsequent chunks of the stream and send them to their neighbors, unless the neighbors in turn indicate that this is no longer necessary. In this way, a node does not need to download a large message in its entirety before propagating it further. This minimizes broadcast latency, especially when combined with the optimizations described in 3.3.10 . \\4. TON Services and Applications Under construction. First we add chapters we have to refer to from our product docs. e.","title":"3.3.15. Streaming broadcast protocol."},{"location":"TON Blockchain/TON Whitepaper/#ton-services-and-applications","text":"We have discussed the TON Blockchain and TON Networking technologies at some length. Now we explain some ways in which they can be combined to create a wide range of services and applications, and discuss some of the services that will be provided by the TON Project itself, either from the very beginning or at a later time.","title":"TON Services and Applications"},{"location":"TON Blockchain/TON Whitepaper/#41-ton-service-implementation-strategies","text":"We start with a discussion of how different blockchain and network-related applications and services may be implemented inside the TON ecosystem. First of all, a simple classification is in order:","title":"4.1 TON Service Implementation Strategies"},{"location":"TON Blockchain/TON Whitepaper/#411-applications-and-services","text":"We will use the words \u201capplication\u201d and \u201cservice\u201d interchangeably. However, there is a subtle and somewhat vague distinction: an application usually provides some services directly to human users, while a service is usually exploited by other applications and services. For example, TON Storage is a service, because it is designed to keep files on behalf of other applications and services, even though a human user might use it directly as well. A hypothetical \u201cFacebook in a blockchain\u201d (cf. 2.9.13 ) or Telegram messenger, if made available through the TON Network (i.e., implemented as a \u201cton-service\u201d; cf. 4.1.6 ), would rather be an application, even though some \u201cbots\u201d might access it automatically without human intervention.","title":"4.1.1. Applications and services."},{"location":"TON Blockchain/TON Whitepaper/#412-location-of-the-application-on-chain-off-chain-or-mixed","text":"A service or an application designed for the TON ecosystem needs to keep its data and process that data somewhere. This leads to the following classification of applications (and services): On-chain applications (cf. 4.1.4 ): All data and processing are in the TON Blockchain. Off-chain applications (cf. 4.1.5 ): All data and processing are outside the TON Blockchain, on servers available through the TON Network. Mixed applications (cf. 4.1.7 ): Some, but not all, data and processing are in the TON Blockchain; the rest are on off-chain servers available through the TON Network.","title":"4.1.2. Location of the application: on-chain, off-chain or mixed."},{"location":"TON Blockchain/TON Whitepaper/#413-centralization-centralized-and-decentralized-or-distributed-applications","text":"Another classification criterion is whether the application (or service) relies on a centralized server cluster, or is really \u201cdistributed\u201d (cf. 4.1.9 ). All on-chain applications are automatically decentralized and distributed. Off-chain and mixed applications may exhibit different degrees of centralization. Now let us consider the above possibilities in more detail.","title":"4.1.3. Centralization: centralized and decentralized, or distributed, applications."},{"location":"TON Blockchain/TON Whitepaper/#414-pure-on-chain-applications-distributed-applications-or-dapps-residing-in-the-blockchain","text":"One of the possible approaches, mentioned in 4.1.2 , is to deploy a \u201cdistributed application\u201d (commonly abbreviated as \u201cdapp\u201d) completely in the TON Blockchain, as one smart contract or a collection of smart contracts. All data will be kept as part of the permanent state of these smart contracts, and all interaction with the project will be done by means of (TON Blockchain) messages sent to or received from these smart contracts. We have already discussed in 2.9.13 that this approach has its drawbacks and limitations. It has its advantages, too: such a distributed application needs no servers to run on or to store its data (it runs \u201cin the blockchain\u201d\u2014 i.e., on the validators\u2019 hardware), and enjoys the blockchain\u2019s extremely high (Byzantine) reliability and accessibility. The developer of such a distributed application does not need to buy or rent any hardware; all she needs to do is develop some software (i.e., the code for the smart contracts). After that, she will effectively rent the computing power from the validators, and will pay for it in Grams, either herself or by putting this burden on the shoulders of her users.","title":"4.1.4. Pure \u201con-chain\u201d applications: distributed applications, or \u201cdapps\u201d, residing in the blockchain."},{"location":"TON Blockchain/TON Whitepaper/#415-pure-network-services-ton-sites-and-ton-services","text":"Another extreme option is to deploy the service on some servers and make it available to the users through the ADNL protocol described in 3.1 , and maybe some higher level protocol such as the RLDP discussed in 3.1.9 , which can be used to send RPC queries to the service in any custom format and obtain answers to these queries. In this way, the service will be totally off-chain, and will reside in the TON Network, almost without using the TON Blockchain. The TON Blockchain might be used only to locate the abstract address or addresses of the service, as outlined in 3.2.12 , perhaps with the aid of a service such as the TON DNS (cf. 4.3.1 ) to facilitate translation of domainlike human-readable strings into abstract addresses. To the extent the ADNL network (i.e., the TON Network) is similar to the Invisible Internet Project (I 2P), such (almost) purely network services are analogous to the so-called \u201ceep-services\u201d (i.e., services that have an I 2Paddress as their entry point, and are available to clients through the I 2P network). We will say that such purely network services residing in the TON Network are \u201cton-services\u201d. An \u201ceep-service\u201d may implement HTTP as its client-server protocol; in the TON Network context, a \u201cton-service\u201d might simply use RLDP (cf. 3.1.9 ) datagrams to transfer HTTP queries and responses to them. If it uses the TON DNS to allow its abstract address to be looked up by a human-readable domain name, the analogy to a web site becomes almost perfect. One might even write a specialized browser, or a special proxy (\u201cton-proxy\u201d) that is run locally on a user\u2019s machine, accepts arbitrary HTTP queries from an ordinary web browser the user employs (once the local IP address and the TCP port of the proxy are entered into the browser\u2019s configuration), and forwards these queries through the TON Network to the abstract address of the service. Then the user would have a browsing experience similar to that of the World Wide Web (WWW). In the I 2P ecosystem, such \u201ceep-services\u201d are called \u201ceep-sites\u201d. One can easily create \u201cton-sites\u201d in the TON ecosystem as well. This is facilitated somewhat by the existence of services such as the TON DNS, which exploit the TON Blockchain and the TON DHT to translate (TON) domain names into abstract addresses.","title":"4.1.5. Pure network services: \u201cton-sites\u201d and \u201cton-services\u201d."},{"location":"TON Blockchain/TON Whitepaper/#416-telegram-messenger-as-a-ton-service-mtproto-over-rldp","text":"We would like to mention in passing that the MTProto protocol, used by Telegram Messenger * for client-server interaction, can be easily embedded into the RLDP protocol discussed in 3.1.9 , thus effectively transforming Telegram into a ton-service. Because the TON Proxy technology can be switched on transparently for the end user of a ton-site or a ton-service, being implemented on a lower level than the RLDP and ADNL protocols (cf. 3.1.6 ), this would make Telegram effectively unblockable. Of course, other messaging and social networking services might benefit from this technology as well. * https://core.telegram.org/mtproto ** https://telegram.org/","title":"4.1.6. Telegram Messenger as a ton-service; MTProto over RLDP."},{"location":"TON Blockchain/TON Whitepaper/#417-mixed-services-partly-off-chain-partly-on-chain","text":"Some services might use a mixed approach: do most of the processing off-chain, but also have some on-chain part (for example, to register their obligations towards their users, and vice versa). In this way, part of the state would still be kept in the TON Blockchain (i.e., an immutable public ledger), and any misbehavior of the service or of its users could be punished by smart contracts.","title":"4.1.7. Mixed services: partly off-chain, partly on-chain."},{"location":"TON Blockchain/TON Whitepaper/#418-example-keeping-files-off-chain-ton-storage","text":"An example of such a service is given by TON Storage. In its simplest form, it allows users to store files off-chain, by keeping on-chain only a hash of the file to be stored, and possibly a smart contract where some other parties agree to keep the file in question for a given period of time for a pre-negotiated fee. In fact, the file may be subdivided into chunks of some small size (e.g., 1 kilobyte), augmented by an erasure code such as a Reed\u2013Solomon or a fountain code, a Merkle tree hash may be constructed for the augmented sequence of chunks, and this Merkle tree hash might be published in the smart contract instead of or along with the usual hash of the file. This is somewhat reminiscent of the way files are stored in a torrent. An even simpler form of storing files is completely off-chain: one might essentially create a \u201ctorrent\u201d for a new file, and use TON DHT as a \u201cdistributed torrent tracker\u201d for this torrent (cf. 3.2.10 ). This might actually work pretty well for popular files. However, one does not get any availability guarantees. For example, a hypothetical \u201cblockchain Facebook\u201d (cf. 2.9.13 ), which would opt to keep the profile photographs of its users completely off-chain in such \u201ctorrents\u201d, might risk losing photographs of ordinary (not especially popular) users, or at least risk being unable to present these photographs for prolonged periods. The TON Storage technology, which is mostly off-chain, but uses an on-chain smart contract to enforce availability of the stored files, might be a better match for this task.","title":"4.1.8. Example: keeping files off-chain; TON Storage."},{"location":"TON Blockchain/TON Whitepaper/#419-decentralized-mixed-services-or-fog-services","text":"So far, we have discussed centralized mixed services and applications. While their on-chain component is processed in a decentralized and distributed fashion, being located in the blockchain, their off-chain component relies on some servers controlled by the service provider in the usual centralized fashion. Instead of using some dedicated servers, computing power might be rented from a cloud computing service offered by one of the large companies. However, this would not lead to decentralization of the off-chain component of the service. A decentralized approach to implementing the off-chain component of a service consists in creating a market, where anybody possessing the required hardware and willing to rent their computing power or disk space would offer their services to those needing them. For example, there might exist a registry (which might also be called a \u201cmarket\u201d or an \u201cexchange\u201d) where all nodes interested in keeping files of other users publish their contact information, along with their available storage capacity, availability policy, and prices. Those needing these services might look them up there, and, if the other party agrees, create smart contracts in the blockchain and upload files for off-chain storage. In this way a service like TON Storage becomes truly decentralized, because it does not need to rely on any centralized cluster of servers for storing files.","title":"4.1.9. Decentralized mixed services, or \u201cfog services\u201d."},{"location":"TON Blockchain/TON Whitepaper/#4110-example-fog-computing-platforms-as-decentralized-mixed-services","text":"Another example of such a decentralized mixed application arises when one wants to perform some specific computations (e.g., 3D rendering or training neural networks), often requiring specific and expensive hardware. Then those having such equipment might offer their services through a similar \u201cexchange\u201d, and those needing such services would rent them, with the obligations of the sides registered by means of smart contracts. This is similar to what \u201cfog computing\u201d platforms, such as Golem ( https://golem.network/) or SONM ( https://sonm.io/), promise to deliver.","title":"4.1.10. Example: \u201cfog computing\u201d platforms as decentralized mixed services."},{"location":"TON Blockchain/TON Whitepaper/#4111-example-ton-proxy-is-a-fog-service","text":"TON Proxy provides yet another example of a fog service, where nodes wishing to offer their services (with or without compensation) as tunnels for ADNL network traffic might register, and those needing them might choose one of these nodes depending on the price, latency and bandwidth offered. Afterwards, one might use payment channels provided by TON Payments for processing micropayments for the services of those proxies, with payments collected, for instance, for every 128 KiB transferred.","title":"4.1.11. Example: TON Proxy is a fog service."},{"location":"TON Blockchain/TON Whitepaper/#4112-example-ton-payments-is-a-fog-service","text":"The TON Payments platform (cf. 5 ) is also an example of such a decentralized mixed application","title":"4.1.12. Example: TON Payments is a fog service."},{"location":"TON Blockchain/TON Whitepaper/#43-accessing-ton-services","text":"We have discussed in 4.1 the different approaches one might employ for creating new services and applications residing in the TON ecosystem. Now we discuss how these services might be accessed, and some of the \u201chelper services\u201d that will be provided by TON, including TON DNS and TON Storage.","title":"4.3 Accessing TON Services"},{"location":"TON Blockchain/TON Whitepaper/#431-ton-dns-a-mostly-on-chain-hierarchical-domain-name-service","text":"The TON DNS is a predefined service, which uses a collection of smart contracts to keep a map from human-readable domain names to (256-bit) addresses of ADNL network nodes and TON Blockchain accounts and smart contracts. While anybody might in principle implement such a service using the TON Blockchain, it is useful to have such a predefined service with a wellknown interface, to be used by default whenever an application or a service wants to translate human-readable identifiers into addresses.","title":"4.3.1. TON DNS: a mostly on-chain hierarchical domain name service."},{"location":"TON Blockchain/TON Whitepaper/#436-retrieving-data-from-a-dns-smart-contract","text":"In principle, any full node for the masterchain or shardchain containing a DNS smart contract might be able to look up any subdomain in the database of that smart contract, if the structure and the location of the hashmap inside the persistent storage of the smart contract are known. However, this approach would work only for certain DNS smart contracts. It would fail miserably if a non-standard DNS smart contract were used. Instead, an approach based on general smart contract interfaces and get methods (cf. 4.3.11 ) is used. Any DNS smart contract must define a \u201cget method\u201d with a \u201cknown signature\u201d, which is invoked to look up a key. Since this approach makes sense for other smart contracts as well, especially those providing on-chain and mixed services, we explain it in some detail in 4.3.11 .","title":"4.3.6. Retrieving data from a DNS smart contract."},{"location":"TON Blockchain/TON Whitepaper/#4311-get-methods-of-smart-contracts","text":"A better way would be to define some get methods in the smart contract, that is, some types of inbound messages that do not affect the state of the smart contract when delivered, but generate one or more output messages containing the \u201cresult\u201d of the get method. In this way, one can obtain data from a smart contract, knowing only that it implements a get method with a known signature (i.e., a known format of the inbound message to be sent and outbound messages to be received as a result). This way is much more elegant and in line with object oriented programming (OOP). However, it has an obvious defect so far: one must actually commit a transaction into the blockchain (sending the get message to the smart contract), wait until it is committed and processed by the validators, extract the answer from a new block, and pay for gas (i.e., for executing the get method on the validators\u2019 hardware). This is a waste of resources: get methods do not change the state of the smart contract anyways, so they need not be executed in the blockchain.","title":"4.3.11. \u201cGet methods\u201d of smart contracts."},{"location":"TON Blockchain/TON Whitepaper/#4312-tentative-execution-of-get-methods-of-smart-contracts","text":"We have already remarked (cf. 2.4.6 ) that any full node can tentatively execute any method of any smart contract (i.e., deliver any message to a smart contract), starting from a given state of the smart contract, without actually committing the corresponding transaction. The full node can simply load the code of the smart contract under consideration into the TON VM, initialize its persistent storage from the global state of the shardchain (known to all full nodes of the shardchain), and execute the smart-contract code with the inbound message as its input parameter. The output messages created will yield the result of this computation. In this way, any full node can evaluate arbitrary get methods of arbitrary smart contracts, provided their signature (i.e., the format of inbound and outbound messages) is known. The node may keep track of the cells of the shardchain state accessed during this evaluation, and create a Merkle proof of the validity of the computation performed, for the benefit of a light node that might have asked the full node to do so (cf. 2.5.11 ).","title":"4.3.12. Tentative execution of get methods of smart contracts."},{"location":"TON Blockchain/TON Whitepaper/#4314-public-interfaces-of-a-smart-contract","text":"Notice that a formalized smart-contract interface, either in form of a TL-scheme (represented as a TL source file; cf. 2.2.5 ) or in serialized form,* can be published\u2014for example, in a special field in the smart-contract account description, stored in the blockchain, or separately, if this interface will be referred to many times. In the latter case a hash of the supported public interface may be incorporated into the smart-contract description instead of the interface description itself. An example of such a public interface is that of a DNS smart contract, which is supposed to implement at least one standard get method for looking up subdomains (cf. 4.3.6 ). A standard method for registering new subdomains can be also included in the standard public interface of DNS smart contracts. *TL-schemes can be TL-serialized themselves; cf. https://core.telegram.org/mtproto/TL-tl","title":"4.3.14. Public interfaces of a smart contract."},{"location":"TON Blockchain/TON Whitepaper/#4317-locating-user-interfaces-via-ton-dns","text":"The TON DNS record containing an abstract address of a ton-service or a smart-contract account identifier might also contain an optional field describing the public (user) interface of that entity, or several supported interfaces. Then the client application (be it a wallet, a ton-browser or a ton-proxy) will be able to download the interface and interact with the entity in question (be it a smart contract or a ton-service) in a uniform way.","title":"4.3.17. Locating user interfaces via TON DNS."},{"location":"TON Blockchain/TON Whitepaper/#4319-a-light-wallet-and-ton-entity-explorer-can-be-built-into-telegram-messenger-clients","text":"An interesting opportunity arises at this point. A light wallet and TON entity explorer, implementing the above functionality, can be embedded into the Telegram Messenger smartphone client application, thus bringing the technology to more than 200 million people. Users would be able to send hyperlinks to TON entities and resources by including TON URIs (cf. 4.3.22 ) in messages; such hyperlinks, if selected, will be opened internally by the Telegram client application of the receiving party, and interaction with the chosen entity will begin.","title":"4.3.19. A light wallet and TON entity explorer can be built into Telegram Messenger clients."},{"location":"TON Blockchain/TON Whitepaper/#4322-hyperlink-urls-may-specify-some-parameters","text":"The hyperlink URLs may contain not only a (TON) DNS domain or an abstract address of the service in question, but also the name of the method to be invoked and some or all of its parameters. A possible URI scheme for this might look as follows: \u200b ton:// domain / method ? field1 = value 1 field2 =. . . When the user selects such a link in a ton-browser, either the action is performed immediately (especially if it is a get method of a smart contract,invoked anonymously), or a partially filled form is displayed, to be explicitly confirmed and submitted by the user (this may be required for payment forms).","title":"4.3.22. Hyperlink URLs may specify some parameters."},{"location":"TON Blockchain/TON Whitepaper/#4323-post-actions","text":"A ton-site may embed into the HTML pages it returns some usual-looking POST forms, with POST actions referring either to ton-sites, ton-services or smart contracts by means of suitable (TON) URLs. In that case, once the user fills and submits that custom form, the corresponding action is taken, either immediately or after an explicit confirmation.","title":"4.3.23. POST actions."},{"location":"TON Blockchain/TON Whitepaper/#4324-ton-www","text":"All of the above will lead to the creation of a whole web of cross-referencing entities, residing in the TON Network, which would be accessible to the end user through a ton-browser, providing the user with a WWW-like browsing experience. For end users, this will finally make blockchain applications fundamentally similar to the web sites they are already accustomed to.","title":"4.3.24. TON WWW."},{"location":"TON Blockchain/TON Whitepaper/#4325-advantages-of-ton-www","text":"This \u201cTON WWW\u201d of on-chain and off-chain services has some advantages over its conventional counterpart. For example, payments are inherently integrated in the system. User identity can be always presented to the services (by means of automatically generated signatures on the transactions and RPC requests generated), or hidden at will. Services would not need to check and re-check user credentials; these credentials can be published in the blockchain once and for all. User network anonymity can be easily preserved by means of TON Proxy, and all services will be effectively unblockable. Micropayments are also possible and easy, because ton-browsers can be integrated with the TON Payments system. ON Payments Under construction. First we add chapters we have to refer to from our product docs. The last component of the TON Project we will briefly discuss in this text is TON Payments, the platform for (micro)payment channels and \u201clightning network\u201d value transfers. It would enable \u201cinstant\u201d payments, without the need to commit all transactions into the blockchain, pay the associated transaction fees (e.g., for the gas consumed), and wait five seconds until the block containing the transactions in question is confirmed. The overall overhead of such instant payments is so small that one can use them for micropayments. For example, a TON file-storing service might charge the user for every 128 KiB of downloaded data, or a paid TON Proxy might require some tiny micropayment for every 128 KiB of traffic relayed. While TON Payments is likely to be released later than the core components of the TON Project, some considerations need to be made at the very beginning. For example, the TON Virtual Machine (TON VM; cf. 2.1.20 ), used to execute the code of TON Blockchain smart contracts, must support some special operations with Merkle proofs. If such support is not present in the original design, adding it at a later stage might become problematic (cf. 2.8.16 ). We will see, however, that the TON VM comes with natural support for \u201csmart\u201d payment channels (cf. 5.1.9) out of the box.","title":"4.3.25. Advantages of TON WWW."},{"location":"TON Blockchain/TON Whitepaper/#ton-payments","text":"","title":"TON Payments"},{"location":"TON Blockchain/TON Whitepaper/#51-payment-channels","text":"We start with a discussion of point-to-point payment channels, and how they can be implemented in the TON Blockchain.","title":"5.1 Payment Channels"},{"location":"TON Blockchain/TON Whitepaper/#511-the-idea-of-a-payment-channel","text":"Suppose two parties, A and B, know that they will need to make a lot of payments to each other in the future. Instead of committing each payment as a transaction in the blockchain, they create a shared \u201cmoney pool\u201d (or perhaps a small private bank with exactly two accounts), and contribute some funds to it: A contributes a coins, and B contributes b coins. This is achieved by creating a special smart contract in the blockchain, and sending the money to it. Before creating the \u201cmoney pool\u201d, the two sides agree to a certain protocol. They will keep track of the state of the pool\u2014that is, of their balances in the shared pool. Originally, the state is (a, b), meaning that a coins actually belong to A, and b coins belong to B. Then, if A wants to pay d coins to B, they can simply agree that the new state is (a', b' ) = (a \u2212 d, b + d). Afterwards, if, say, B wants to pay d 0 coins to A, the state will become (a '', b'') = (a' + d' , b' \u2212 d' ), and so on. All this updating of balances inside the pool is done completely off-chain. When the two parties decide to withdraw their due funds from the pool, they do so according to the final state of the pool. This is achieved by sending a special message to the smart contract, containing the agreed-upon final state (a \u2217 , b\u2217 ) along with the signatures of both A and B. Then the smart contract sends a \u2217 coins to A, b \u2217 coins to B and self-destructs. This smart contract, along with the network protocol used by A and B to update the state of the pool, is a simple payment channel between A and B. According to the classification described in 4.1.2 , it is a mixed service: part of its state resides in the blockchain (the smart contract), but most of its state updates are performed off-chain (by the network protocol). If everything goes well, the two parties will be able to perform as many payments to each other as they want (with the only restriction being that the \u201ccapacity\u201d of the channel is not overrun\u2014i.e., their balances in the payment channel both remain non-negative), committing only two transactions into the blockchain: one to open (create) the payment channel (smart contract), and another to close (destroy) it.","title":"5.1.1. The idea of a payment channel."},{"location":"TON Blockchain/TON Whitepaper/#518-challenges-for-the-sophisticated-payment-channel-smart-contracts","text":"Notice that, while the final state of a sophisticated payment channel is still small, and the \u201cclean\u201d finalization is simple (if the two sides have agreed on their amounts due, and both have signed their agreement, nothing else remains to be done), the unilateral finalization method and the method for punishing fraudulent behavior need to be more complex. Indeed, they must be able to accept Merkle proofs of misbehavior, and to check whether the more sophisticated transactions of the payment channel blockchain have been processed correctly. In other words, the payment channel smart contract must be able to work with Merkle proofs, to check their \u201chash validity\u201d, and must contain an implementation of ev_trans and ev_block functions (cf. 2.2.6) for the payment channel (virtual) blockchain.","title":"5.1.8. Challenges for the sophisticated payment channel smart contracts."},{"location":"TON Blockchain/TON Whitepaper/#519-ton-vm-support-for-smart-payment-channels","text":"The TON VM, used to run the code of TON Blockchain smart contracts, is up to the challenge of executing the smart contracts required for \u201csmart\u201d, or sophisticated, payment channels (cf. 5.1.8 ). At this point the \u201ceverything is a bag of cells\u201d paradigm (cf. 2.5.14) becomes extremely convenient. Since all blocks (including the blocks of the ephemeral payment channel blockchain) are represented as bags of cells (and described by some algebraic data types), and the same holds for messages and Merkle proofs as well, a Merkle proof can easily be embedded into aninbound message sent to the payment channel smart contract. The \u201chash condition\u201d of the Merkle proof will be checked automatically, and when the smart contract accesses the \u201cMerkle proof\u201d presented, it will work with it as if it were a value of the corresponding algebraic data type\u2014albeit incomplete, with some subtrees of the tree replaced by special nodes containing the Merkle hash of the omitted subtree. Then the smart contract will work with that value, which might represent, for instance, a block of the payment channel (virtual) blockchain along with its state, and will evaluate the ev_block function (cf. 2.2.6 ) of that blockchain on this block and the previous state. Then either the computation finishes, and the final state can be compared with that asserted in the block, or an \u201cabsent node\u201d exception is thrown while attempting to access an absent subtree, indicating that the Merkle proof is invalid. In this way, the implementation of the verification code for smart payment channel blockchains turns out to be quite straightforward using TON Blockchain smart contracts. One might say that the TON Virtual Machine comes with built-in support for checking the validity of other simple blockchains . The only limiting factor is the size of the Merkle proof to be incorporated into the inbound message to the smart contract (i.e., into the transaction).","title":"5.1.9. TON VM support for \u201csmart\u201d payment channels."},{"location":"TON Blockchain/TON Whitepaper/#appendix","text":"","title":"Appendix"},{"location":"TON Blockchain/TON Whitepaper/#references","text":"","title":"References"},{"location":"TON Blockchain/TON Whitepaper/#1-k-birman-reliable-distributed-systems-technologies-web-services","text":"","title":"[1] K. Birman, Reliable Distributed Systems: Technologies, Web Services"},{"location":"TON Blockchain/TON Whitepaper/#and-applications-springer-2005","text":"","title":"and Applications, Springer, 2005."},{"location":"TON Blockchain/TON Whitepaper/#2-v-buterin-ethereum-a-next-generation-smart-contract-and-decentralized-application-platform-httpsgithubcomethereumwiki","text":"","title":"[2] V. Buterin, Ethereum: A next-generation smart contract and decentralized application platform, https://github.com/ethereum/wiki/"},{"location":"TON Blockchain/TON Whitepaper/#wikiwhite-paper-2013","text":"","title":"wiki/White-Paper, 2013."},{"location":"TON Blockchain/TON Whitepaper/#3-m-ben-or-b-kelmer-t-rabin-asynchronous-secure-computations-with-optimal-resilience-in-proceedings-of-the-thirteenth-annual-acm","text":"","title":"[3] M. Ben-Or, B. Kelmer, T. Rabin, Asynchronous secure computations with optimal resilience, in Proceedings of the thirteenth annual ACM"},{"location":"TON Blockchain/TON Whitepaper/#symposium-on-principles-of-distributed-computing-p-183192-acm","text":"","title":"symposium on Principles of distributed computing, p. 183\u2013192. ACM,"},{"location":"TON Blockchain/TON Whitepaper/#1994","text":"","title":"1994."},{"location":"TON Blockchain/TON Whitepaper/#4-m-castro-b-liskov-et-al-practical-byzantine-fault-tolerance","text":"","title":"[4] M. Castro, B. Liskov, et al., Practical byzantine fault tolerance,"},{"location":"TON Blockchain/TON Whitepaper/#proceedings-of-the-third-symposium-on-operating-systems-design-and","text":"","title":"Proceedings of the Third Symposium on Operating Systems Design and"},{"location":"TON Blockchain/TON Whitepaper/#implementation-1999-p-173186-available-at-httppmgcsailmit","text":"","title":"Implementation (1999), p. 173\u2013186, available at http://pmg.csail.mit."},{"location":"TON Blockchain/TON Whitepaper/#edupapersosdi99pdf","text":"","title":"edu/papers/osdi99.pdf."},{"location":"TON Blockchain/TON Whitepaper/#5-eosio-eosio-technical-white-paper-httpsgithubcomeosio","text":"","title":"[5] EOS.IO, EOS.IO technical white paper, https://github.com/EOSIO/"},{"location":"TON Blockchain/TON Whitepaper/#documentationblobmastertechnicalwhitepapermd-2017","text":"","title":"Documentation/blob/master/TechnicalWhitePaper.md, 2017."},{"location":"TON Blockchain/TON Whitepaper/#6-d-goldschlag-m-reed-p-syverson-onion-routing-for-anonymous-and-private-internet-connections-communications-of-the-acm","text":"","title":"[6] D. Goldschlag, M. Reed, P. Syverson, Onion Routing for Anonymous and Private Internet Connections, Communications of the ACM,"},{"location":"TON Blockchain/TON Whitepaper/#42-num-2-1999-httpwwwonion-routernetpublications","text":"","title":"42, num. 2 (1999), http://www.onion-router.net/Publications/"},{"location":"TON Blockchain/TON Whitepaper/#cacm-1999pdf","text":"","title":"CACM-1999.pdf."},{"location":"TON Blockchain/TON Whitepaper/#7-l-lamport-r-shostak-m-pease-the-byzantine-generals-problem","text":"","title":"[7] L. Lamport, R. Shostak, M. Pease, The byzantine generals problem,"},{"location":"TON Blockchain/TON Whitepaper/#acm-transactions-on-programming-languages-and-systems-43-1982","text":"","title":"ACM Transactions on Programming Languages and Systems, 4/3 (1982),"},{"location":"TON Blockchain/TON Whitepaper/#p-382401","text":"","title":"p. 382\u2013401."},{"location":"TON Blockchain/TON Whitepaper/#8-s-larimer-the-history-of-bitshares-httpsdocsbitsharesorg","text":"","title":"[8] S. Larimer, The history of BitShares, https://docs.bitshares.org/"},{"location":"TON Blockchain/TON Whitepaper/#bitshareshistoryhtml-2013","text":"","title":"bitshares/history.html, 2013."},{"location":"TON Blockchain/TON Whitepaper/#9-m-luby-a-shokrollahi-et-al-raptorq-forward-error-correction","text":"","title":"[9] M. Luby, A. Shokrollahi, et al., RaptorQ forward error correction"},{"location":"TON Blockchain/TON Whitepaper/#scheme-for-object-delivery-ietf-rfc-6330-httpstoolsietforg","text":"","title":"scheme for object delivery, IETF RFC 6330, https://tools.ietf.org/"},{"location":"TON Blockchain/TON Whitepaper/#htmlrfc6330-2011","text":"","title":"html/rfc6330, 2011."},{"location":"TON Blockchain/TON Whitepaper/#10-p-maymounkov-d-mazieres-kademlia-a-peer-to-peer-information-system-based-on-the-xor-metric-in-iptps-01-revised-papers-from-the-first-international-workshop-on-peer-to-peer-systems-p-5365-available-at-httppdoscsailmitedupetarpapers","text":"","title":"[10] P. Maymounkov, D. Mazi\u00e8res, Kademlia: A peer-to-peer information system based on the XOR metric, in IPTPS \u201901 revised papers from the First International Workshop on Peer-to-Peer Systems, p. 53\u201365, available at http://pdos.csail.mit.edu/~petar/papers/"},{"location":"TON Blockchain/TON Whitepaper/#maymounkov-kademlia-lncspdf-2002","text":"","title":"maymounkov-kademlia-lncs.pdf, 2002."},{"location":"TON Blockchain/TON Whitepaper/#11-a-miller-yu-xia-et-al-the-honey-badger-of-bft-protocols","text":"","title":"[11] A. Miller, Yu Xia, et al., The honey badger of BFT protocols,"},{"location":"TON Blockchain/TON Whitepaper/#cryptology-e-print-archive-201699-httpseprintiacrorg2016","text":"","title":"Cryptology e-print archive 2016/99, https://eprint.iacr.org/2016/"},{"location":"TON Blockchain/TON Whitepaper/#199pdf-2016","text":"","title":"199.pdf, 2016."},{"location":"TON Blockchain/TON Whitepaper/#12-s-nakamoto-bitcoin-a-peer-to-peer-electronic-cash-system-https","text":"","title":"[12] S. Nakamoto, Bitcoin: A peer-to-peer electronic cash system, https:"},{"location":"TON Blockchain/TON Whitepaper/#bitcoinorgbitcoinpdf-2008","text":"","title":"//bitcoin.org/bitcoin.pdf, 2008."},{"location":"TON Blockchain/TON Whitepaper/#13-s-peyton-jones-implementing-lazy-functional-languages-on-stock","text":"","title":"[13] S. Peyton Jones, Implementing lazy functional languages on stock"},{"location":"TON Blockchain/TON Whitepaper/#hardware-the-spineless-tagless-g-machine-journal-of-functional-programming-2-2-p-127202-1992","text":"","title":"hardware: the Spineless Tagless G-machine, Journal of Functional Programming 2 (2), p. 127\u2013202, 1992."},{"location":"TON Blockchain/TON Whitepaper/#14-a-shokrollahi-m-luby-raptor-codes-ieee-transactions-on","text":"","title":"[14] A. Shokrollahi, M. Luby, Raptor Codes, IEEE Transactions on"},{"location":"TON Blockchain/TON Whitepaper/#information-theory-6-no-34-2006-p-212322","text":"","title":"Information Theory 6, no. 3\u20134 (2006), p. 212\u2013322."},{"location":"TON Blockchain/TON Whitepaper/#15-m-van-steen-a-tanenbaum-distributed-systems-3rd-ed-2017","text":"","title":"[15] M. van Steen, A. Tanenbaum, Distributed Systems, 3rd ed., 2017."},{"location":"TON Blockchain/TON Whitepaper/#16-the-univalent-foundations-program-homotopy-type-theory","text":"","title":"[16] The Univalent Foundations Program, Homotopy Type Theory:"},{"location":"TON Blockchain/TON Whitepaper/#univalent-foundations-of-mathematics-institute-for-advanced-study","text":"","title":"Univalent Foundations of Mathematics, Institute for Advanced Study,"},{"location":"TON Blockchain/TON Whitepaper/#2013-available-at-httpshomotopytypetheoryorgbook","text":"","title":"2013, available at https://homotopytypetheory.org/book."},{"location":"TON Blockchain/TON Whitepaper/#17-g-wood-polkadot-vision-for-a-heterogeneous-multi-chain-framework-draft-1-httpsgithubcomw3fpolkadot-white-paperraw","text":"","title":"[17] G. Wood, PolkaDot: vision for a heterogeneous multi-chain framework, draft 1, https://github.com/w3f/polkadot-white-paper/raw/"},{"location":"TON Blockchain/TON Whitepaper/#masterpolkadotpaperpdf-2016","text":"","title":"master/PolkaDotPaper.pdf, 2016."},{"location":"TON Blockchain/TVM Error Codes/","text":"TVM Error Codes 0 TVM terminated successfully 1 TVM terminated successfully: alternative code 2 Stack underflow 3 Stack overflow 4 Integer overflow 5 Range check error 6 Invalid opcode 7 Type check error 8 Cell overflow 9 Cell underflow 10 Dictionary error 11 Unknown error 12 Fatal error 13 Out of gas: the contract is either low on gas, or its limit is exceeded","title":"TVM Error Codes"},{"location":"TON Blockchain/TVM Error Codes/#tvm-error-codes","text":"0 TVM terminated successfully 1 TVM terminated successfully: alternative code 2 Stack underflow 3 Stack overflow 4 Integer overflow 5 Range check error 6 Invalid opcode 7 Type check error 8 Cell overflow 9 Cell underflow 10 Dictionary error 11 Unknown error 12 Fatal error 13 Out of gas: the contract is either low on gas, or its limit is exceeded","title":"TVM Error Codes"}]}